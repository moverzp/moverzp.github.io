<!DOCTYPE html>
<html>
<head><meta name="generator" content="Hexo 3.8.0">
  <meta charset="utf-8">
  
  <meta name="renderer" content="webkit">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <link rel="dns-prefetch" href="http://yoursite.com">
  <title>moverzp的博客</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta property="og:type" content="website">
<meta property="og:title" content="moverzp的博客">
<meta property="og:url" content="http://yoursite.com/index.html">
<meta property="og:site_name" content="moverzp的博客">
<meta property="og:locale" content="default">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="moverzp的博客">
  
    <link rel="alternative" href="/atom.xml" title="moverzp的博客" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" type="text/css" href="/./main.266c1c.css">
  <style type="text/css">
  
    #container.show {
      background: linear-gradient(200deg,#a0cfe4,#e8c37e);
    }
  </style>
  

  

</head>
</html>
<body>
  <div id="container" q-class="show:isCtnShow">
    <canvas id="anm-canvas" class="anm-canvas"></canvas>
    <div class="left-col" q-class="show:isShow">
      
<div class="overlay" style="background: #4d4d4d"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			<img src="http://markdown.moverzp.com/WechatIMG99.jpeg" class="js-avatar">
		</a>
		<hgroup>
		  <h1 class="header-author"><a href="/">moverzp</a></h1>
		</hgroup>
		
		<p class="header-subtitle">Inner Peace, Keep Moving</p>
		

		<p class="header-subtitle">访问次数</p>
		<div align="center"><a href="http://www.amazingcounters.com"><img border="0" src="http://cc.amazingcounters.com/counter.php?i=3216629&c=9650200" alt="AmazingCounters.com"></a></div>

		<nav class="header-menu">
			<ul>
			
				<li><a href="/">主页</a></li>
	        
				<li><a href="/archives">所有文章</a></li>
	        
			</ul>
		</nav>
		<nav class="header-smart-menu">
    		
    			
    			<a q-on="click: openSlider(e, 'friends')" href="javascript:void(0)">友链</a>
    			
            
    			
    			<a q-on="click: openSlider(e, 'aboutme')" href="javascript:void(0)">关于我</a>
    			
            
		</nav>
		<nav class="header-nav">
			<div class="social">
				
					<a class="github" target="_blank" href="https://github.com/moverzp/" title="github"><i class="icon-github"></i></a>
		        
					<a class="mail" target="_blank" href="mailto:moverzp@qq.com" title="mail"><i class="icon-mail"></i></a>
		        
			</div>
		</nav>
	</header>		
</div>

    </div>
    <div class="mid-col" q-class="show:isShow,hide:isShow|isFalse">
      
<nav id="mobile-nav">
  	<div class="overlay js-overlay" style="background: #4d4d4d"></div>
	<div class="btnctn js-mobile-btnctn">
  		<div class="slider-trigger list" q-on="click: openSlider(e)"><i class="icon icon-sort"></i></div>
	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
				<img src="http://markdown.moverzp.com/WechatIMG99.jpeg" class="js-avatar">
			</div>
			<hgroup>
			  <h1 class="header-author js-header-author">moverzp</h1>
			</hgroup>
			
			<p class="header-subtitle"><i class="icon icon-quo-left"></i>Inner Peace, Keep Moving<i class="icon icon-quo-right"></i></p>
			
			
			
				
			
				
			
			
			
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="https://github.com/moverzp/" title="github"><i class="icon-github"></i></a>
			        
						<a class="mail" target="_blank" href="mailto:moverzp@qq.com" title="mail"><i class="icon-mail"></i></a>
			        
				</div>
			</nav>

			<nav class="header-menu js-header-menu">
				<ul style="width: 50%">
				
				
					<li style="width: 50%"><a href="/">主页</a></li>
		        
					<li style="width: 50%"><a href="/archives">所有文章</a></li>
		        
				</ul>
			</nav>
		</header>				
	</div>
	<div class="mobile-mask" style="display:none" q-show="isShow"></div>
</nav>

      <div id="wrapper" class="body-wrap">
        <div class="menu-l">
          <div class="canvas-wrap">
            <canvas data-colors="#eaeaea" data-sectionHeight="100" data-contentId="js-content" id="myCanvas1" class="anm-canvas"></canvas>
          </div>
          <div id="js-content" class="content-ll">
            
  
    <article id="post-推荐系统发展概览" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2019/04/07/推荐系统发展概览/">推荐系统发展概览</a>
    </h1>
  

        
        <a href="/2019/04/07/推荐系统发展概览/" class="archive-article-date">
  	<time datetime="2019-04-07T14:19:37.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2019-04-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>搜索推荐隐藏在生活的各个角落里，比如抖音、快手的视频推荐，亚马逊的物品推荐，各种Feed推荐等等。推荐系统基于用户数据和物品数据，通过一定的架构和算法，为用户推荐符合需求的物品，以达到提高用户体验，CTR，CVR，GMV等目的。本文将从三个阶段简单介绍一下推荐系统。</p>
<h2 id="1-0阶段——规则驱动"><a href="#1-0阶段——规则驱动" class="headerlink" title="1.0阶段——规则驱动"></a>1.0阶段——规则驱动</h2><p>严格意义上这个阶段其实是不算推荐系统的。这个阶段主要依靠运营人员制定的规则去推荐物品，比如主推高销量的物品，新物品。这个阶段最大的问题就是每个人看到的内容都是一样的，多样性无，转化率低下。</p>
<p>一般在系统冷启动的时候可以短暂的使用这种方法。</p>
<h2 id="2-0阶段——算法驱动"><a href="#2-0阶段——算法驱动" class="headerlink" title="2.0阶段——算法驱动"></a>2.0阶段——算法驱动</h2><p>2.0阶段的算法主要指<strong>协同过滤</strong>或者<strong>关联规则</strong>。协同过滤有两种，一种是基于用户的协同过滤，一种是基于物品的协同过滤，前者适合物品数量比用户多，且比较多变的场景，如新闻，后者适合物品数量比较少，且比较固定的场景，如电商。</p>
<h3 id="UserCF和ItemCF的相似度计算公式对比"><a href="#UserCF和ItemCF的相似度计算公式对比" class="headerlink" title="UserCF和ItemCF的相似度计算公式对比"></a>UserCF和ItemCF的相似度计算公式对比</h3><p><img src="http://markdown.moverzp.com/20190414table.png" alt="公式渲染有问题，拿图来凑"></p>
<p>备注：实际使用中，相似度公式有大量调整和变形（比如降低高销量物品的权重）。</p>
<h3 id="UserCF和ItemCF的特点对比"><a href="#UserCF和ItemCF的特点对比" class="headerlink" title="UserCF和ItemCF的特点对比"></a>UserCF和ItemCF的特点对比</h3><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">算法</th>
<th>群体/个体</th>
<th>适用业务</th>
<th>适用场景</th>
<th>冷启动</th>
<th>可解释性</th>
<th>实时性</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">UserCF</td>
<td>更依赖与当前用户相似的用户群体的社会化行为</td>
<td>适用于用户量明显少于物品量的业务（资讯，新闻）</td>
<td>时效性强，用户个性化兴趣不太显著的场合</td>
<td>新加入的物品能很快的进入推荐列表中</td>
<td>弱</td>
<td>用户的新行为<strong>不一定</strong>导致推荐结果发生变化</td>
</tr>
<tr>
<td style="text-align:left">ItemCF</td>
<td>更侧重自身的个体行为</td>
<td>适用于物品量明显少于用户量的业务（电商，餐饮）</td>
<td>长尾物品丰富，用户个性化需求强烈的场合</td>
<td>新加入的用户能很快得到推荐</td>
<td>强</td>
<td>用户的新行为<strong>一定</strong>导致推荐结果发生变化</td>
</tr>
</tbody>
</table>
</div>
<p>协同过滤的优点</p>
<ul>
<li>利用群体智慧，无需依赖背景知识</li>
<li>通用性较好</li>
<li>使用很广</li>
<li>可解释性强</li>
</ul>
<p>协同过滤的缺点</p>
<ul>
<li>强依赖用户行为数据</li>
<li>数据稀疏</li>
</ul>
<p>方法与本质</p>
<ul>
<li>用户显式或者隐式地给物品进行评分</li>
<li>用户在过去有什么品味，未来也会有类似的品味</li>
</ul>
<h3 id="使用一张图来解释UserCF和ItemCF"><a href="#使用一张图来解释UserCF和ItemCF" class="headerlink" title="使用一张图来解释UserCF和ItemCF"></a>使用一张图来解释UserCF和ItemCF</h3><p><img src="http://markdown.moverzp.com/img1.png" alt="使用一张图来解释UserCF和ItemCF"></p>
<h3 id="架构图"><a href="#架构图" class="headerlink" title="架构图"></a>架构图</h3><p><img src="http://markdown.moverzp.com/20190414img2.png" alt="算法驱动架构图"></p>
<p><strong>Match</strong>：该层又常常被称为Recall层，可以实现粗粒度的物品推荐，一般情况下Match层输出的物品在200以下</p>
<ul>
<li><p>实时U2I，根据实时的行为进行推荐。从log中实时地抽出用户的行为，并给不同的行为打分，按照不同的权重进行用户到物品的推荐。比如浏览的权重较低，购买的权重比较高；浏览多的类目权重调高；权重按照时间进行指数衰减。实际例子：在某乎点击了火影相关问答后，返回首页就能看到好几个火影相关的问答</p>
</li>
<li><p>历史U2I，根据当天0点之前的数据进行推荐，可以离线计算。实际例子：在某乎经常浏览科技相关的问答，虽然在点击动漫相关后首页出现了动漫相关的问答，但是还有科技相关的问答</p>
</li>
<li><p>偏好U2I，根据用户的偏好属性进行推荐。实际例子：在某乎上面关注了几个话题，首页上会有这几个话题相关的问答</p>
</li>
<li><p>热门物品，最近时间窗口内的热销物品。实际例子：第一张黑洞照片刚出来的时候在某乎比较火，很多人都在看，可以在首页展示相关话题</p>
</li>
</ul>
<p><strong>Filter</strong>：过滤掉重复推荐，不符合当前用户需求的物品</p>
<h2 id="3-0阶段——架构通用化"><a href="#3-0阶段——架构通用化" class="headerlink" title="3.0阶段——架构通用化"></a>3.0阶段——架构通用化</h2><p>架构通用化是可以真正做到千人千面的推荐系统，2.0的推荐系统可以说是3.0推荐系统的子集，3.0阶段具体的架构如下所示：</p>
<p><img src="http://markdown.moverzp.com/20190414img3.jpg" alt="通用架构化架构图"><br><strong>Match</strong>：和2.0阶段基本一样，大多数都是协同过滤算法，但是也可以使用其他的算法进行Match，比如XGBoost也能做召回</p>
<p><strong>Filter</strong>：基本和2.0阶段一样，只不过多了一个“行为负反馈”，行为负反馈指的是推荐给用户以后，用户多次看到却没有点击的物品，表示用户其实这个物品不感兴趣</p>
<p><strong>Rank</strong>：根据不同的目标函数，有目标的建立和优化模型，Rank层是比较重要的一层，也是迭代优化的重点，大多数的推荐优化都是在Rank层做文章，因为一般用户点击的都是首页的前几个物品。Rank层结合了用户画像和物品画像，对物品进行<strong>精排序</strong>，在保证多样性的前提下，又突出了其他目标</p>
<ul>
<li>目标函数，CTR：点击率；CVR，转化率；GMV，客单价*CTR*CVR；其他：如客单价和上新</li>
<li>算法模型，LR(+GBDT)，FM/FFM，Wide&amp;Deep，DeepFM等等</li>
</ul>
<p><strong>Merge</strong>：实时，历史，偏好，热门物品是4个独立计算的结果，需要进行融合，类似于bagging，把多模型的结果融合，提高准确率</p>
<ul>
<li>可以根据埋点确定先放哪一层，哪个模型的埋点效果好就把其结果放在前面</li>
<li>可以训练模型，进行综合打分</li>
</ul>
<p><strong>Rerank</strong>：精排序之后的微调，如可以调高一些非偏好类目的权重，增加新奇性</p>
<p>在3.0的推荐架构里，最大的区别是多了画像数据和Rank层，在2.0粗推荐的基础上结合了用户画像和物品画像实现了精推荐，真正地实现了千人千面</p>
<ul>
<li>利用埋点数据和历史数据构建了精细的用户画像，如年龄，偏好，消费能力，地域特征等等</li>
<li>物品也有精确的画像，如品类，性价比系数，生命周期等等</li>
<li>在画像的基础上，又进行了若干特征工程，如Item2Vector（把物品映射成向量）</li>
<li>通过不同的算法模型和目标函数提高了业务指标</li>
<li>对推荐的结果进行埋点收集数据，把点击的物品记为正例，行为负反馈的物品记为负例，去训练Rank层的模型。模型一般1~2周就得训练一次，因为随着时间的推移，模型的准确率会衰减</li>
</ul>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><p>我们通过一些自问自答的形式进行小结。<br><strong>Q：为什么要进行Match，不能直接进行Rank吗？</strong><br>A：一般情况下，Rank层的特征和模型都比较复杂，对1个物品处理就会花费较长的时间（相对于200ms的用户体验来说），如果不进行Match层的粗筛选，直接向Rank层的模型输入上万甚至是上百万的物品，处理的时间会很长，会影响用户体验，所以到现在都没有一个端到端的推荐系统。一般都是在Match层筛选出200个以下的物品，然后在Rank层进行排序。为了避免提前过滤掉用户可能点击的物品，可以从多个维度进行Match。</p>
<p><strong>Q：如何从零搭建一个推荐系统？</strong><br>A：从零搭建推荐系统的一个大难题是冷启动问题。因为一开始没有任何直接的用户数据，所以肯定得从1.0阶段或者2.0阶段开启</p>
<ul>
<li>可以让运营或者PM制作一些list并打上标签，在用户注册或者登录的时候，引导用户在list列表中选择自己喜欢的label（1.0阶段的方法）</li>
<li>对于全新产品，可以通过爬虫获取相关的数据（有些网站会把与当前物品相似的物品列出来，可以用这些数据计算相似度矩阵，2.0阶段的方法）</li>
<li>如果产品已经上线一段时间了，之前没有推荐功能，现在要新上推荐功能，可以通过销量 or 某个时间窗口内的点击次数进行推荐（1.0阶段的方法），亦可以通过协同过滤进行推荐（2.0阶段的方法）</li>
<li>通过1.0阶段或者2.0阶段的推荐可以获取到用户的点击与消费行为（即可以采集到正负样本），这一段时间刚好可以建立用户画像，物品画像，然后就可以进入3.0阶段。3.0阶段rank算法上线必须经过A/B Test验证，在统计学上能够<strong>显著地</strong>提升指标的话才能推广到全量（A/B Test稍后会写一个blog）。这里想讲一个八卦，当年FB花了大半年的时间设计并开发了全新的首页，在A/B Test的时候发现各项指标都严重下滑，最后决定相信A/B Test的结果没有上线新版的首页，相当于很多人大半年的工作都白费了。结果刚好人人网看到了新版的首页，花了很短的时间就抄完然后推了全量，然后DAU就很严重的下滑，为后来的GG埋下了很大的伏笔。。</li>
<li>在大型的推荐系统里，用户画像和物品画像需要专门的组来做，Match部分和Rank部分亦是，甚至是Rerank部分都需要单独的组（比如某个商品违规，最快的方法是在这一层惩罚）</li>
</ul>
<p><strong>Q：推荐系统这么多部分，重点应该放在哪里？</strong></p>
<ul>
<li>一般情况下，如果推荐不是主要功能，在数据不够，用户不多的情况下，不要强上推荐系统，这个时候最重要的是提高DAU，收集用户的数据。这个是从产品的角度来考虑，而不是技术的的角度，做一件事要考虑成本和收益</li>
<li>在有一定的用户和数据以后，就可以做Match了，这一步相当于推荐系统从无到有，对用户体验影响很大，这个阶段Match比Rank重要</li>
<li>在Match稳定之后，就可以把精力花在Rank模块</li>
<li>如果非要给一个推荐系统划分比重的话，Match的重要性是5成，Rank的重要性是3成，Merge和Rerank各占1成，而且架构图从下到上的部分环环相扣，下面做的不好，上面大概率做不好</li>
</ul>
<p><strong>Q：对一个推荐算法工程师来说，最重要的壁垒能力是什么？</strong><br>A：这是一个闻者伤心，听者流泪的答案——对业务的理解能力。推荐相关的技术难度其实不是很大，业界有很多的paper可以学习，现在互联网上面的资料也很多。各种天花乱坠的模型相比于CV和NLP，真的不算难。推荐系统本来就扎根于业务场景，如果想不清楚业务目标，很可能会弄巧城拙。比如只看CTR，就可能造成标题党；只看GMV，就可能造成用户体验下降。还比如，在电商情境中，消费者买了裤子还推荐裤子就很影响体验，但是在餐饮情境中，消费者第一天吃了回锅肉盖饭，第二天再推荐回锅肉盖饭是比较合理的。</p>
<p><strong>Q：推荐系统有没有4.0阶段？</strong><br>A：个人认为是有的（其实这3个阶段的划分也是在参考资料[2]中学来的），那就是基于知识图谱的推荐系统，现在百度等大厂都有自己的知识图谱且已经在应用中，可以将搜索推荐的结果进一步提高。但是感觉建立知识图谱真的是一个体力活，以后有机会再聊😂。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] 项亮. 推荐系统实践[M]. 人民邮电出版社, 2012.<br>[2] <a href="https://www.zhihu.com/lives/users/7dce82d1f49ea92b780a8b668b03cbfc" target="_blank" rel="noopener">姚凯飞的知乎live</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2019/04/07/推荐系统发展概览/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-工作一年半的碎碎念" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/23/工作一年半的碎碎念/">工作一年半的碎碎念</a>
    </h1>
  

        
        <a href="/2018/11/23/工作一年半的碎碎念/" class="archive-article-date">
  	<time datetime="2018-11-22T17:56:56.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-11-23</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>按照常理来说，第一段大概又要写一些“光阴似箭，时光如梭”，“白驹过隙”，“逝者如斯夫，不舍昼夜”，“一眨眼就工作了一年半”之类的话罢，我的随笔总是这么几个套路，真是无奈又悲伤的感觉😂。</p>
<p>从找工作伊始，就陷入了一种整天“害怕”的状态：在学校的时候，害怕找不到工作；找到工作了，害怕不能按时毕业；按时毕业入职了，害怕不能转正；顺利转正了，害怕公司要倒闭（当时漫天的黑稿和倒闭的传闻）；公司澄清现金流很充裕了，害怕部门业务进展不顺，要被整体端掉；部门进展挺好的，也收购了别的公司，害怕自己整天做业务会废了……我工作前一整年总是胡思乱想，怕这怕那的，后来不知道怎么回事，突然就想通了，变豁达了，后半年专心于工作和学习，过得倒也挺好，对于工作和技术有了一些新的理解（但是个人内心实际上对于技术进步的速度还是很不满意）。</p>
<p>在网上前端工程师被戏称为切图boy，后端工程师被戏称为CRUD boy，算法/数据挖掘工程师被戏称为SQL boy，实际上这可能是大多数IT从业人员现状，因为一个商业公司的根本目标是盈利，而盈利主要依靠业务，技术服务于业务，大多数“低端的技术”可能就可以hold住业务了。如果不是技术驱动的业务，整天重复地写业务代码是再正常不过的现象，想要提升自己，就只能工作之余充充电了。其实还有些提升个人技能的好方法，就是造轮子和参与开源项目，然而前者在大多数公司是严格禁止的，后者对于普通人来说时间和精力都无法满足。</p>
<p>个人觉得自己还算一个热爱学习的人，这一年半来，学了很多东西，比如spark，TensorFlow，Keras，也学了不少课程，如Ng的《Deep Learning》，还花钱学习了Udacity的纳米学位课程《机器学习工程师（进阶版》，工作之余打了一个kaggle的比赛，如此等等。在这个过程中，慢慢地对算法工程师这个岗位有了一些理解，对自己职业生涯慢慢地有一些感悟和体会。</p>
<p>之前不知道在哪里看到一种分类方法，说技术工作大致可以分为3类，并且以MS office进行举例。第一类工作是根基，发明最基础的工具，发现最根本的原理，如CPU，操作系统，编程语言等。第二类工作是发明第三类工作中使用的工具，如Word，Excel。第三类工作是使用第二类工作中发明的工具去解决实际的问题，如使用Word写论文，用Excel进行数据分析。对于一个普通人来说，主要精力专注于其中的一类工作，如果精力足够，可以业余时间研究一下另外两类工作。</p>
<p>笔者想在机器学习方向进行类似的分类。第一类工作是进行最基础的算法研究，如发明SVM，CNN，RNN等。第二类工作是发明各种机器学习框架，如sklearn，TensorFlow等。第三类工作就是各个业务部门算法工程师进行的工作了，会去解决各种业务场景中的问题，比如搜索排序，OCR，人脸识别，客服机器人等等。这三类工作的比例基本是金字塔形，大多数人都专注于第三类工作，少数人专注于第二类工作，凤毛麟角的人专注于第一类工作。</p>
<p>作为一名算法工程师，必须给自己一个明确的定位，这样自己成长的路线才是清晰明确的，否则会走很多不必要的弯路，也会让自己变得很迷茫。比如如果想从事第一类工作，就应该尽量去大学，研究所或者少数互联网公司的AI Lab，因为这些地方能够有足够的时间去进行思考和研究，没有业务和应用的压力，第一类工作对从业者的算法或者“直觉”的要求较高。如果想从事第二类工作，可以去大型互联网公司的基础架构部门或者AI Lab的工程部门，可以实现论文中的算法，或者进行把单机算法改成分布式算法的操作，或者提高程序执行的效率，第二类人对工程能力要求最高。第三类工作就是最广大算法工程师的工作了，一般业务线的工程师都是这类人，也就是俗称的“调参狗”或者SQL boy。第三类工作对于算法或者数学要求其实并不高，只要能把业务场景抽象成具体的问题并进行适当的优化，对于业务有sense的话，应该在工作中能脱颖而出。</p>
<p>就拿我自己来说吧，在学校的时候特别想从事第一类工作，结果投简历的时候没有顶会paper，专业也不对口，基本石沉大海。然后思索着第二类工作好像也没啥意思，要求也蛮高的，估计也找不到，就直接找第三类的工作了。现在的工作就是解决各种场景的业务问题，根据业务场景建立一个目标函数，然后想办法去优化，找特征，不断地迭代，有时候会看看比较火爆的论文，看看能不能用在业务中。对于业务的依赖非常的严重，如果碰到坑爹项目，可能大半年都是荒废的状态，如果碰到好项目，短时间内都会提升很多。时而感觉工作很无聊，时而又感觉工作挺有意思的，时而担心自己慢慢的就废了，时而又自我感觉良好。</p>
<p>在这篇吐槽之前，觉得自己这一年半成长很慢，细细道来，其实比校招的时候好很多了。这应该就是“知道的越多，越知道自己无知”的感觉了吧。。。部门里面的老大对我还是比较看重的，而且现在遇到了一个好项目，希望能趁着这个机会快速地成长起来，非常地希望能够掌握后端工程方面的知识（消息队列，KV存储，负载均衡之类的），要不然做项目总是要别人帮忙开发工程相关的东西，心里不踏实。</p>
<p>依稀记得研究生毕业的时候，和高中舍友在微信上聊天，他说他在亚麻实习一年，工作一年，算是两年的工作经验了，但是现在每天下班依旧得学习到深夜，当时特别不理解，现在工作一年多了，表示非常理解。。互联网的技术更新换代太快，信息量大，真的只有保持不断学习的习惯，才能不会被抛弃。总之，加油吧，少年~</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color3">随笔</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/11/23/工作一年半的碎碎念/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-快速图像风格迁移（四）——对一张图像进行风格迁移" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/07/快速图像风格迁移（四）——对一张图像进行风格迁移/">快速图像风格迁移（四）——对一张图像进行风格迁移</a>
    </h1>
  

        
        <a href="/2018/11/07/快速图像风格迁移（四）——对一张图像进行风格迁移/" class="archive-article-date">
  	<time datetime="2018-11-06T17:57:09.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-11-07</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>训练完模型之后，就可以使用训练好的图像生成网络进行快速风格迁移。</p>
<h2 id="1-eval模块"><a href="#1-eval模块" class="headerlink" title="1. eval模块"></a>1. eval模块</h2><p>编写<code>eval.py</code>文件，实现快速风格迁移的功能。</p>
<p>首先导入必要的package.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> preprocessing_factory</span><br><span class="line"><span class="keyword">import</span> reader, model</span><br><span class="line"><span class="keyword">import</span> os, time</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>reader</code>模块的具体内容详见参考资料[5]</li>
</ul>
<p>使用命令行传入训练好的模型路径和待转换的图像路径等参数。tf中的<code>tf.app.flags</code>用于接受命令行传入的参数，使用的时候会定义参数的类型，参数名，参数默认值和参数的描述。这里我们传入4个参数：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">tf.app.flags.DEFINE_string(<span class="string">'loss_model'</span>, <span class="string">'vgg_16'</span>, <span class="string">'The name of the architecture to evaluate. '</span></span><br><span class="line">                           <span class="string">'You can view all the support models in nets/nets_factory.py'</span>)</span><br><span class="line">tf.app.flags.DEFINE_integer(<span class="string">'image_size'</span>, <span class="number">256</span>, <span class="string">'Image size to train.'</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">"model_file"</span>, <span class="string">"models.ckpt"</span>, <span class="string">""</span>)</span><br><span class="line">tf.app.flags.DEFINE_string(<span class="string">"image_file"</span>, <span class="string">"a.jpg"</span>, <span class="string">""</span>)</span><br><span class="line"></span><br><span class="line">FLAGS = tf.app.flags.FLAGS</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>tf.app.flags.DEFINE_XXX</code>中的<code>XXX</code>就是参数类型，括号中的三个参数分别表示传入的参数名，参数默认值和参数描述</li>
<li>第一个参数是string类型的参数，参数名是<code>&#39;loss_model&#39;</code>, 默认值是<code>&#39;vgg_16&#39;</code></li>
<li>第二个参数是int类型的参数，参数名是<code>&#39;image_size&#39;</code>，默认值是<code>&#39;256&#39;</code></li>
<li>第三个参数是string类型的参数，参数名是<code>&#39;model_file&#39;</code>，默认值是<code>&#39;models.ckpt&#39;</code></li>
<li>第四个参数是string类型的参数，参数名是<code>&#39;image_file&#39;</code>，默认值是<code>&#39;a.jpg&#39;</code></li>
</ul>
<p>定义直接运行<code>eval.py</code>函数，该函数的主要作用就两个</p>
<ul>
<li>设置记录日志的等级</li>
<li>运行<code>main()</code>函数，<code>tf.app.run()</code>会自动的运行当前文件的<code>main()</code>函数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">    tf.app.run()</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p>最后来编写<code>main()</code>函数，主要在注释中讲解。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(_)</span>:</span></span><br><span class="line">    <span class="comment"># 获取图片尺寸</span></span><br><span class="line">    height = <span class="number">0</span></span><br><span class="line">    width = <span class="number">0</span></span><br><span class="line">    <span class="keyword">with</span> open(FLAGS.image_file, <span class="string">'rb'</span>) <span class="keyword">as</span> img:</span><br><span class="line">        <span class="keyword">with</span> tf.Session().as_default() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="keyword">if</span> FLAGS.image_file.lower().endswith(<span class="string">'png'</span>):</span><br><span class="line">                image = sess.run(tf.image.decode_png(img.read()))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                image = sess.run(tf.image.decode_jpeg(img.read()))</span><br><span class="line">            height = image.shape[<span class="number">0</span>]</span><br><span class="line">            width = image.shape[<span class="number">1</span>]</span><br><span class="line">    tf.logging.info(<span class="string">'Image size: %dx%d'</span> % (height, width))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 载入图片</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            image_preprocessing_fn = preprocessing_factory.get_preprocessing(</span><br><span class="line">                FLAGS.loss_model,</span><br><span class="line">                is_training=<span class="literal">False</span>)</span><br><span class="line">            image = reader.get_image(FLAGS.image_file, height, width, image_preprocessing_fn)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 得到生成网络的生成图片，注意此时并未发生计算</span></span><br><span class="line">            image = tf.expand_dims(image, <span class="number">0</span>)</span><br><span class="line">            generated = model.net(image, training=<span class="literal">False</span>)</span><br><span class="line">            generated = tf.cast(generated, tf.uint8)</span><br><span class="line">            generated = tf.squeeze(generated, [<span class="number">0</span>])</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 从checkpoint文件中载入训练好的模型</span></span><br><span class="line">            saver = tf.train.Saver(tf.global_variables(), write_version=tf.train.SaverDef.V1)</span><br><span class="line">            sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])</span><br><span class="line"></span><br><span class="line">            FLAGS.model_file = os.path.abspath(FLAGS.model_file)</span><br><span class="line">            saver.restore(sess, FLAGS.model_file)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 检查文件路径</span></span><br><span class="line">            generated_file = <span class="string">'generated/res.jpg'</span></span><br><span class="line">            <span class="keyword">if</span> os.path.exists(<span class="string">'generated'</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">                os.makedirs(<span class="string">'generated'</span>)</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 开始计算</span></span><br><span class="line">            <span class="keyword">with</span> open(generated_file, <span class="string">'wb'</span>) <span class="keyword">as</span> img:</span><br><span class="line">                start_time = time.time()</span><br><span class="line">                img.write(sess.run(tf.image.encode_jpeg(generated)))</span><br><span class="line">                end_time = time.time()</span><br><span class="line"></span><br><span class="line">                tf.logging.info(<span class="string">'Elapsed time: %fs'</span> %(end_time - start_time))</span><br><span class="line">                tf.logging.info(<span class="string">'Done. Please check %s.'</span> % generated_file)</span><br></pre></td></tr></table></figure></p>
<p>在命令行中输入以下命令：<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">python eval.py --model_file models/wave/fast-style_model.ckpt<span class="number">-17000</span> --image_file img/test.jpg</span><br></pre></td></tr></table></figure></p>
<p>然后就可以在<code>generated/res.jpg</code>中查看风格迁移之后的图像了。<br>本文中提供风格的图像是《神奈川冲浪里》。<br><img src="http://markdown.moverzp.com/wave.jpg" alt="神奈川冲浪里"><br>本文中提供内容的图像是北京西站的一张图像。<br><img src="http://markdown.moverzp.com/timg.jpg" alt="北京西站原图"><br>经过风格转换后的图像如下所示。<br><img src="http://markdown.moverzp.com/res.jpg" alt="经过风格转换后的北京西站"><br>对示例图片进行快速风格迁移，一共耗时10秒钟，比基础版的图像风格迁移快了很多倍，实际应用中会使用GPU进行风格迁移，耗时会更少。</p>
<h2 id="2-小结"><a href="#2-小结" class="headerlink" title="2.小结"></a>2.小结</h2><ul>
<li>快速风格迁移之所以能做到快速，是因为训练了图像生成网络，风格迁移的时候进行一次前向计算即可；而原版的风格迁移，每进行一张图像的风格迁移就相当于训练一次模型</li>
<li>一个图像生成网络只能迁移一种风格</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] 何之源. 21个项目玩转深度学习[M]. 北京:电子工业出版社, 2018.<br>[2] <a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/." target="_blank" rel="noopener">moverzp. 【paper笔记】图像风格迁移[EB/OL].</a><br>[3] <a href="http://moverzp.com/2018/08/19/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C/." target="_blank" rel="noopener">moverzp. 快速图像风格迁移（一）——图像生成网络[EB/OL].</a><br>[4] <a href="http://moverzp.com/2018/08/30/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" target="_blank" rel="noopener">moverzp. 快速图像风格迁移（二）——损失函数[EB/OL].</a><br>[5] <a href="http://moverzp.com/2018/11/04/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%89%EF%BC%89%E2%80%94%E2%80%94%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83/" target="_blank" rel="noopener">moverzp. 快速图像风格迁移（三）——模型训练[EB/OL].</a><br>[6] Gatys L A, Ecker A S, Bethge M. A Neural Algorithm of Artistic Style[J]. Computer Science, 2016.<br>[7] Johnson J, Alahi A, Li F F. Perceptual Losses for Real-Time Style Transfer and Super-Resolution[C]// European Conference on Computer Vision. Springer, Cham, 2016:694-711.<br>[8] <a href="https://tensorflow.google.cn/tutorials/" target="_blank" rel="noopener">https://tensorflow.google.cn/tutorials/</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/11/07/快速图像风格迁移（四）——对一张图像进行风格迁移/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-快速图像风格迁移（三）——模型训练" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/11/04/快速图像风格迁移（三）——模型训练/">快速图像风格迁移（三）——模型训练</a>
    </h1>
  

        
        <a href="/2018/11/04/快速图像风格迁移（三）——模型训练/" class="archive-article-date">
  	<time datetime="2018-11-04T15:09:54.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-11-04</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前在<a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" target="_blank" rel="noopener">【paper笔记】图像风格迁移</a>博文中介绍了图像风格迁移的原理，在<a href="http://moverzp.com/2018/08/19/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">快速图像风格迁移（一）——图像生成网络</a>博文中搭建了图像生成网络，在<a href="http://moverzp.com/2018/08/30/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" target="_blank" rel="noopener">快速图像风格迁移（二）——损失函数</a>博文中实现了损失函数，在这些工作的基础之上就可以实现模型训练的代码。</p>
<p>首先需要载入搭建好的模型，然后使用VGG网络提取图像特征，设定优化器和损失函数，不断地载入<code>batch_size</code>张图像，喂给网络即可。训练集是微软的<a href="http://cocodataset.org/" target="_blank" rel="noopener">COCO数据集</a>。</p>
<h2 id="1-reader模块"><a href="#1-reader模块" class="headerlink" title="1. reader模块"></a>1. reader模块</h2><p>编写<code>reader.py</code>文件，实现图像读取函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> os <span class="keyword">import</span> listdir</span><br><span class="line"><span class="keyword">from</span> os.path <span class="keyword">import</span> isfile, join</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_image</span><span class="params">(path, height, width, preprocess_fn)</span>:</span></span><br><span class="line">    png = path.lower().endswith(<span class="string">'png'</span>)</span><br><span class="line">    img_bytes = tf.read_file(path)</span><br><span class="line">    image = tf.image.decode_png(img_bytes, channels=<span class="number">3</span>) <span class="keyword">if</span> png <span class="keyword">else</span> tf.image.decode_jpeg(img_bytes, channels=<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> preprocess_fn(image, height, width)</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>get_image()</code>可以按照给定的路径读取图像，并使用预训练模型的预处理函数对读入的图像进行处理<ul>
<li>首先载入图像文件，然后根据图像文件的格式进行解码</li>
<li>然后将图像使用预训练模型的预处理函数进行处理，返回处理后的图像</li>
</ul>
</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">image</span><span class="params">(batch_size, height, width, path, preprocessing_fn, epochs=<span class="number">2</span>, shuffle=True)</span>:</span></span><br><span class="line">    filenames = [join(path, f) <span class="keyword">for</span> f <span class="keyword">in</span> listdir(path) <span class="keyword">if</span> isfile(join(path, f))]</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span> shuffle:</span><br><span class="line">        filenames = sorted(filenames)</span><br><span class="line">        </span><br><span class="line">    png = filenames[<span class="number">0</span>].lower().endswith(<span class="string">'png'</span>)</span><br><span class="line">    </span><br><span class="line">    filename_queue = tf.train.string_input_producer(filenames, shuffle=shuffle, num_epochs=epochs)</span><br><span class="line">    reader = tf.WholeFileReader()</span><br><span class="line">    _, img_bytes = reader.read(filename_queue)</span><br><span class="line">    image = tf.image.decode_png(img_bytes, channels=<span class="number">3</span>) <span class="keyword">if</span> png <span class="keyword">else</span> tf.image.decode_jpeg(img_bytes, channels=<span class="number">3</span>)</span><br><span class="line">    </span><br><span class="line">    processed_image = preprocessing_fn(image, height, width)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> tf.train.batch([processed_image], batch_size, dynamic_pad=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>image()</code>使用队列载入图像，并使用训练模型的预处理函数对读入的图像进行处理，每次只会返回<code>batch_size</code>张图像的张量</li>
<li>首先载入图像文件，然后根据图像文件的格式进行解码，默认所有的图像和第一张图像的格式相同</li>
<li>使用TensorFlow的队列载入图像的好处是可以异步加载数据，模型获取下一个batch数据的时候可以直接获得，而<code>feed_dict</code>是同步加载数据，模型需要获取下一个batch数据的时候，需要先载入数据，再传递给模型。异步加载数据可以减少模型训练的时间</li>
</ul>
<h2 id="2-train模块"><a href="#2-train模块" class="headerlink" title="2.train模块"></a>2.train模块</h2><p>编写<code>train.py</code>文件，实现模型训练功能。<br>首先载入必要的模块。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> nets <span class="keyword">import</span> nets_factory</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> preprocessing_factory</span><br><span class="line"><span class="keyword">import</span> utils, reader, model, losses</span><br><span class="line"><span class="keyword">import</span> os, time, argparse</span><br></pre></td></tr></table></figure></p>
<p>然后定义一个参数解析模块。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">parse_args</span><span class="params">()</span>:</span></span><br><span class="line">    <span class="comment"># 参数解析，就一个参数：配置文件路径</span></span><br><span class="line">    parser = argparse.ArgumentParser()</span><br><span class="line">    parser.add_argument(<span class="string">'-c'</span>, <span class="string">'--conf'</span>, default=<span class="string">'conf/mosaic.yml'</span>, help=<span class="string">'the path of conf file'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> parser.parse_args()</span><br></pre></td></tr></table></figure></p>
<p>在<a href="http://moverzp.com/2018/08/30/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" target="_blank" rel="noopener">快速图像风格迁移（二）——损失函数</a>中定义过一个<code>read_conf_file(conf_file)</code>函数，我们传入解析的配置文件路径，返回含有各个配置参数的对象<code>FLAG</code>，然后将这个对象传递给主函数<code>main()</code>，<code>main()</code>函数中实现了模型训练的所有功能。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.logging.set_verbosity(tf.logging.INFO) <span class="comment"># 设定日志等级</span></span><br><span class="line">    args = parse_args()</span><br><span class="line">    FLAGS = utils.read_conf_file(args.conf)</span><br><span class="line">    main(FLAGS)</span><br></pre></td></tr></table></figure></p>
<p><code>main()</code>函数较长，主要在注释中进行解释。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">(FLAGS)</span>:</span></span><br><span class="line">    <span class="comment"># 获取style image的style feature</span></span><br><span class="line">    style_features_t = losses.get_style_features(FLAGS)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># check训练路径</span></span><br><span class="line">    training_path = os.path.join(FLAGS.model_path, FLAGS.naming)</span><br><span class="line">    <span class="keyword">if</span> <span class="keyword">not</span>(os.path.exists(training_path)):</span><br><span class="line">        os.makedirs(training_path)</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            <span class="string">"""构建网络"""</span></span><br><span class="line">            <span class="comment"># network_fn是损失网络函数，不需要对损失网络进行训练</span></span><br><span class="line">            network_fn = nets_factory.get_network_fn(</span><br><span class="line">                FLAGS.loss_model,</span><br><span class="line">                num_classes=<span class="number">1</span>,</span><br><span class="line">                is_training=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 损失网络中要用的图像的预处理函数</span></span><br><span class="line">            image_preprocessing_fn = preprocessing_factory.get_preprocessing(</span><br><span class="line">                FLAGS.loss_model,</span><br><span class="line">                is_training=<span class="literal">False</span>)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 读入原始训练图像，返回的是经过预处理的图像</span></span><br><span class="line">            processed_images = reader.image(</span><br><span class="line">                FLAGS.batch_size,</span><br><span class="line">                FLAGS.image_size,</span><br><span class="line">                FLAGS.image_size,</span><br><span class="line">                <span class="string">'train2014/'</span>,</span><br><span class="line">                image_preprocessing_fn, </span><br><span class="line">                epochs=FLAGS.epoch)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 使用图像生成网络，输入原始图像，输出生成图像</span></span><br><span class="line">            generated = model.net(processed_images, training=<span class="literal">True</span>)</span><br><span class="line">            <span class="comment"># 因为generated同样需要送到损失网络中计算loss，所以需要image_preprocessing_fn进行处理</span></span><br><span class="line">            processed_generated = [image_preprocessing_fn(image, FLAGS.image_size, FLAGS.image_size) <span class="keyword">for</span> image <span class="keyword">in</span> tf.unstack(generated, axis=<span class="number">0</span>, num=FLAGS.batch_size)]</span><br><span class="line">            <span class="comment"># 把图片list组成一个batch</span></span><br><span class="line">            processed_generated = tf.stack(processed_generated)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 将原始图像，生成图像送到损失网络中</span></span><br><span class="line">            _, endpoints_dict = network_fn(tf.concat([processed_generated, processed_images], <span class="number">0</span>), spatial_squeeze=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># log</span></span><br><span class="line">            tf.logging.info(<span class="string">'Loss network layers:'</span>)</span><br><span class="line">            <span class="keyword">for</span> key <span class="keyword">in</span> endpoints_dict:</span><br><span class="line">                tf.logging.info(key)</span><br><span class="line"></span><br><span class="line">            <span class="string">"""构建损失函数"""</span></span><br><span class="line">            content_loss = losses.content_loss(endpoints_dict, FLAGS.content_layers)</span><br><span class="line">            style_loss, style_loss_summary = losses.style_loss(endpoints_dict, style_features_t, FLAGS.style_layers)</span><br><span class="line">            </span><br><span class="line">            loss = FLAGS.style_weight * style_loss + FLAGS.content_weight * content_loss</span><br><span class="line">            </span><br><span class="line">            <span class="string">"""Summary"""</span></span><br><span class="line">            tf.summary.scalar(<span class="string">'losses/content_loss'</span>, content_loss)</span><br><span class="line">            tf.summary.scalar(<span class="string">'losses/style_loss'</span>, style_loss)</span><br><span class="line"></span><br><span class="line">            tf.summary.scalar(<span class="string">'weighted_losses/weighted_content_loss'</span>, content_loss * FLAGS.content_weight)</span><br><span class="line">            tf.summary.scalar(<span class="string">'weighted_losses/weighted_style_loss'</span>, style_loss * FLAGS.style_weight)</span><br><span class="line">            tf.summary.scalar(<span class="string">'total_loss'</span>, loss)</span><br><span class="line">            </span><br><span class="line">            <span class="keyword">for</span> layer <span class="keyword">in</span> FLAGS.style_layers:</span><br><span class="line">                tf.summary.scalar(<span class="string">'style_losses/'</span> + layer, style_loss_summary[layer])</span><br><span class="line">            tf.summary.image(<span class="string">'origin'</span>, tf.stack([</span><br><span class="line">                image <span class="keyword">for</span> image <span class="keyword">in</span> tf.unstack(processed_images, axis=<span class="number">0</span>, num=FLAGS.batch_size)</span><br><span class="line">            ]))</span><br><span class="line">            summary = tf.summary.merge_all()</span><br><span class="line">            writer = tf.summary.FileWriter(training_path)</span><br><span class="line">            </span><br><span class="line">            <span class="string">"""准备训练"""</span></span><br><span class="line">            global_step = tf.Variable(<span class="number">0</span>, name=<span class="string">'global_step'</span>, trainable=<span class="literal">False</span>)</span><br><span class="line">            <span class="comment"># 找出需要训练的变量，本项目中，只需要训练图像生成网络中的变量，不需要训练损失网络中的变量</span></span><br><span class="line">            variables_to_train = []</span><br><span class="line">            <span class="comment"># 使用tf.trainable_variables()找出所有可以训练的变量</span></span><br><span class="line">            <span class="keyword">for</span> variable <span class="keyword">in</span> tf.trainable_variables():</span><br><span class="line">                <span class="comment"># 如果不在损失网络中，把他们加入列表variables_to_train</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span>(variable.name.startswith(FLAGS.loss_model)):</span><br><span class="line">                    variables_to_train.append(variable)</span><br><span class="line">            train_op = tf.train.AdamOptimizer(<span class="number">1e-3</span>).minimize(loss, global_step=global_step, var_list=variables_to_train)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 找出需要保存的变量</span></span><br><span class="line">            variables_to_restore = []</span><br><span class="line">            <span class="keyword">for</span> variable <span class="keyword">in</span> tf.global_variables():</span><br><span class="line">                <span class="comment"># 如果不在损失网络中，把他们加入列表variable_to_restore</span></span><br><span class="line">                <span class="keyword">if</span> <span class="keyword">not</span>(variable.name.startswith(FLAGS.loss_model)):</span><br><span class="line">                    variables_to_restore.append(variable)</span><br><span class="line">            saver = tf.train.Saver(variables_to_restore, write_version=tf.train.SaverDef.V1)</span><br><span class="line">            </span><br><span class="line">            sess.run([tf.global_variables_initializer(), tf.local_variables_initializer()])</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 载入损失网络初始权重</span></span><br><span class="line">            init_func = utils._get_init_fn(FLAGS)</span><br><span class="line">            init_func(sess)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># 恢复变量</span></span><br><span class="line">            last_file = tf.train.latest_checkpoint(training_path)</span><br><span class="line">            <span class="keyword">if</span> last_file:</span><br><span class="line">                tf.logging.info(<span class="string">'Restoring model from &#123;&#125;'</span>.format(last_file))</span><br><span class="line">                saver.restore(sess, last_file)</span><br><span class="line">                </span><br><span class="line">            <span class="string">"""训练"""</span></span><br><span class="line">            coord = tf.train.Coordinator()</span><br><span class="line">            threads = tf.train.start_queue_runners(coord=coord)</span><br><span class="line">            start_time = time.time()</span><br><span class="line">            <span class="keyword">try</span>:</span><br><span class="line">                <span class="keyword">while</span> <span class="keyword">not</span> coord.should_stop():</span><br><span class="line">                    _, loss_t, step = sess.run([train_op, loss, global_step])</span><br><span class="line">                    elapsed_time = time.time() - start_time</span><br><span class="line">                    start_time = time.time()</span><br><span class="line">                    <span class="string">"""logging"""</span></span><br><span class="line">                    <span class="keyword">if</span> step % <span class="number">10</span> == <span class="number">0</span>:</span><br><span class="line">                        tf.logging.info(<span class="string">'step: %d, total loss %f, secs/step: %f'</span> % (step, loss_t, elapsed_time))</span><br><span class="line">                    <span class="string">"""summary"""</span></span><br><span class="line">                    <span class="keyword">if</span> step % <span class="number">25</span> == <span class="number">0</span>:</span><br><span class="line">                        tf.logging.info(<span class="string">'adding summary...'</span>)</span><br><span class="line">                        summary_str = sess.run(summary)</span><br><span class="line">                        writer.add_summary(summary_str, step)</span><br><span class="line">                        writer.flush()</span><br><span class="line">                    <span class="string">"""checkpoint，每500个step保存一次模型"""</span></span><br><span class="line">                    <span class="keyword">if</span> step % <span class="number">500</span> == <span class="number">0</span>:</span><br><span class="line">                        saver.save(sess, os.path.join(training_path, <span class="string">'fast-style_model.ckpt'</span>), global_step=step)</span><br><span class="line">            <span class="keyword">except</span> tf.errors.OutOfRangeError:</span><br><span class="line">                saver.save(sess, os.path.join(training_path, <span class="string">'fast-style-model.ckpt-done'</span>))</span><br><span class="line">                tf.logging.info(<span class="string">'Done training -- epoch limit reached'</span>)</span><br><span class="line">            <span class="keyword">finally</span>:</span><br><span class="line">                coord.request_stop()</span><br><span class="line">            coord.join(threads)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-训练"><a href="#3-训练" class="headerlink" title="3. 训练"></a>3. 训练</h2><p>在<code>train.py</code>文件中编写初始函数，开始模型的训练。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    tf.logging.set_verbosity(tf.logging.INFO)</span><br><span class="line">    args = parse_args()</span><br><span class="line">    FLAGS = utils.read_conf_file(args.conf)</span><br><span class="line">    main(FLAGS)</span><br></pre></td></tr></table></figure></p>
<p>该函数首先设置日志等级，然后解析传入的参数，然后把参数变换成FLAG对象，调用<code>main()</code>函数开始训练模型。</p>
<p>笔者使用Mac Pro15的CPU进行训练，一共训练了不到4天的时间，17K个steps，损失函数基本稳定（都是泪）。</p>
<p>使用tensorboard查看监控的张量。内容损失函数变化如下图所示。<br><img src="http://markdown.moverzp.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-31%2001.27.40.png" alt="内容损失函数"><br>风格损失函数变化如下图所示。<br><img src="http://markdown.moverzp.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-31%2001.28.11.png" alt="风格损失函数"><br>总损失函数变化如下图所示。<br><img src="http://markdown.moverzp.com/%E5%B1%8F%E5%B9%95%E5%BF%AB%E7%85%A7%202018-10-31%2001.28.50.png" alt="总损失函数"></p>
<h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><ul>
<li>图像风格迁移的训练就是训练图像生成网络，其中需要预训练模型抽取图像的内容特征和风格特征，预训练模型不需要训练</li>
<li>读取文件，抽取特征，损失函数和优化器，Summary和batch训练是一个神经网络训练时的基本组成部分</li>
<li>一定要注意随时保存模型，要不然某个时刻因为程序错误或者意外的原因，导致训练停止，很浪费时间</li>
<li>复现paper时，对于原理和结构一定要清清楚楚</li>
</ul>
<h2 id="5-参考资料"><a href="#5-参考资料" class="headerlink" title="5. 参考资料"></a>5. 参考资料</h2><p>[1] 何之源. 21个项目玩转深度学习[M]. 北京:电子工业出版社, 2018.<br>[2] <a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/." target="_blank" rel="noopener">moverzp. 【paper笔记】图像风格迁移[EB/OL].</a><br>[3] <a href="http://moverzp.com/2018/08/19/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C/." target="_blank" rel="noopener">moverzp. 快速图像风格迁移（一）——图像生成网络[EB/OL].</a><br>[4] <a href="http://moverzp.com/2018/08/30/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%BA%8C%EF%BC%89%E2%80%94%E2%80%94%E6%8D%9F%E5%A4%B1%E5%87%BD%E6%95%B0/" target="_blank" rel="noopener">moverzp. 快速图像风格迁移（二）——损失函数[EB/OL].</a><br>[5] Gatys L A, Ecker A S, Bethge M. A Neural Algorithm of Artistic Style[J]. Computer Science, 2016.<br>[6] Johnson J, Alahi A, Li F F. Perceptual Losses for Real-Time Style Transfer and Super-Resolution[C]// European Conference on Computer Vision. Springer, Cham, 2016:694-711.<br>[7] <a href="https://tensorflow.google.cn/tutorials/" target="_blank" rel="noopener">https://tensorflow.google.cn/tutorials/</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/11/04/快速图像风格迁移（三）——模型训练/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-快速图像风格迁移（二）——损失函数" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/30/快速图像风格迁移（二）——损失函数/">快速图像风格迁移（二）——损失函数</a>
    </h1>
  

        
        <a href="/2018/08/30/快速图像风格迁移（二）——损失函数/" class="archive-article-date">
  	<time datetime="2018-08-29T16:40:54.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-30</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前在<a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" target="_blank" rel="noopener">【paper笔记】图像风格迁移</a>博文中介绍了图像风格迁移的原理，在<a href="http://moverzp.com/2018/08/19/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C/" target="_blank" rel="noopener">快速图像风格迁移（一）——图像生成网络</a>博文中搭建了图像生成网络。</p>
<p>今天要实现的是损失函数，损失函数通过损失网络（论文中是VGG16）提取图像的content representation和style representation，然后使用content representation计算$L_{content}$，使用style representation计算$L_{style}$<br>，最后根据$L_{content}$和$L_{style}$得到$L_{total}$，使用的深度学习框架是TensorFlow（具体的损失函数公式详见<a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" target="_blank" rel="noopener">【paper笔记】图像风格迁移</a>）。</p>
<h2 id="1-准备工作"><a href="#1-准备工作" class="headerlink" title="1. 准备工作"></a>1. 准备工作</h2><p>TensorFlow提供预训练好的模型，比如VGG16，ResNet和MobileNet，但是这些模型并没有随着TensorFlow的安装而被下载，还需要我们自己去GitHub上下载模型。</p>
<p>首先使用下面的git命令clone代码到本地<code>git clone https://github.com/tensorflow/models.git</code>. Clone到本地之后，会发现文件夹里还有多个子文件夹，其中比较重要的文件夹及其功能如下所示</p>
<ul>
<li><code>/research/slim/nets</code>，定义了常见的网络结构，如VGG16，ResNet和MobileNet</li>
<li><code>/research/slim/preprocessing</code>，定义常见网络结构的预处理函数</li>
</ul>
<p>如果想要直接import下载下来的模块，还需要将代码所在路径加入到PYTHON路径中，比如笔者在<code>.bash_profile</code>文件中加入<code>export PYTHONPATH=$PYTHONPATH:/Users/moverzp/myapp/TensorFlowSlim/models/research/slim</code>即可。可以先打开一个Python解释器，然后<code>import nets</code>，如果能导入说明配置成功。</p>
<h2 id="2-utils模块"><a href="#2-utils模块" class="headerlink" title="2. utils模块"></a>2. utils模块</h2><p>编写<code>utils.py</code>文件，实现一些较为常见的工具类或函数。</p>
<h3 id="2-1-定义配置参数类Flag"><a href="#2-1-定义配置参数类Flag" class="headerlink" title="2.1 定义配置参数类Flag"></a>2.1 定义配置参数类<code>Flag</code></h3><p>较为复杂的项目一般都有若干个参数需要进行配置，如果直接将参数硬编码到源代码中，使用和修改起来比较麻烦，所以常常创建一个配置文件，每次程序从配置文件中载入配置参数，常见的配置文件有xml, yaml等格式。本文使用yaml格式，yaml的基本语法可以参考<a href="http://www.ruanyifeng.com/blog/2016/07/yaml.html" target="_blank" rel="noopener">YAML 语言教程</a>，本文的配置文件内容如下所示。<br><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><span class="line">## Basic configuration</span><br><span class="line">style_image: img/wave.jpg # targeted style image</span><br><span class="line">naming: &quot;wave&quot; # the name of this model. Determine the path to save checkpoint and events file.</span><br><span class="line">model_path: models  # root path to save checkpoint and events file. The final path would be &lt;model_path&gt;/&lt;naming&gt;</span><br><span class="line"></span><br><span class="line">## Weight of the loss</span><br><span class="line">content_weight: 1.0  # weight for content features loss</span><br><span class="line">style_weight: 220.0  # weight for style features loss</span><br><span class="line"></span><br><span class="line">## The size, the iter number to run</span><br><span class="line">image_size: 256</span><br><span class="line">batch_size: 4</span><br><span class="line">epoch: 2</span><br><span class="line"></span><br><span class="line">## Loss Network</span><br><span class="line">loss_model: &quot;vgg_16&quot;</span><br><span class="line">content_layers:  # use these layers for content loss</span><br><span class="line">  - &quot;vgg_16/conv3/conv3_3&quot;</span><br><span class="line">style_layers:  # use these layers for style loss</span><br><span class="line">  - &quot;vgg_16/conv1/conv1_2&quot;</span><br><span class="line">  - &quot;vgg_16/conv2/conv2_2&quot;</span><br><span class="line">  - &quot;vgg_16/conv3/conv3_3&quot;</span><br><span class="line">  - &quot;vgg_16/conv4/conv4_3&quot;</span><br><span class="line">checkpoint_exclude_scopes: &quot;vgg_16/fc&quot;  # we only use the convolution layers, so ignore fc layers.</span><br><span class="line">loss_model_file: &quot;pretrained/vgg_16.ckpt&quot;  # the path to the checkpoint</span><br></pre></td></tr></table></figure></p>
<ul>
<li>wave.jpg指的是<a href="http://markdown.moverzp.com/18-8-29/56652752.jpg" target="_blank" rel="noopener">这张图像</a>，文件路径是<code>./img/wave.jpg</code><br><img src="http://markdown.moverzp.com/18-8-29/56652752.jpg" alt><br>使用下面一段代码载入配置参数，<code>FLAFS</code>对象保存了所有的配置参数<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> yaml</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">Flag</span><span class="params">(object)</span>:</span></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, **entries)</span>:</span></span><br><span class="line">        self.__dict__.update(entries)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">read_conf_file</span><span class="params">(conf_file)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> open(conf_file) <span class="keyword">as</span> f:</span><br><span class="line">        FLAGS = Flag(**yaml.load(f))</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> FLAGS</span><br></pre></td></tr></table></figure>
</li>
</ul>
<h3 id="2-2-定义恢复变量函数"><a href="#2-2-定义恢复变量函数" class="headerlink" title="2.2 定义恢复变量函数"></a>2.2 定义恢复变量函数</h3><p>一般情况下，预训练模型都比较深，参数比较多，如果从保存文件中恢复所有的变量没有必要，只恢复我们要使用的变量就行，主要操作<code>slim.assign_from_checkpoint_fn()</code>函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">slim = tf.contrib.slim</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">_get_init_fn</span><span class="params">(FLAGS)</span>:</span></span><br><span class="line">    tf.logging.info(<span class="string">"Use pretrained model %s"</span> % FLAGS.loss_model_file)</span><br><span class="line">    <span class="comment"># 从配置文件中提取不要的网络层的名字</span></span><br><span class="line">    exclusions = []</span><br><span class="line">    <span class="keyword">if</span> FLAGS.checkpoint_exclude_scopes:</span><br><span class="line">        exclusions = [scope.strip() <span class="keyword">for</span> scope <span class="keyword">in</span> FLAGS.checkpoint_exclude_scopes.split(<span class="string">','</span>)]</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 筛选出需要保存的变量</span></span><br><span class="line">    variable_to_restore = []</span><br><span class="line">    <span class="keyword">for</span> var <span class="keyword">in</span> slim.get_model_variables():</span><br><span class="line">        excluded = <span class="literal">False</span></span><br><span class="line">        <span class="keyword">for</span> exclusion <span class="keyword">in</span> exclusions:</span><br><span class="line">            <span class="keyword">if</span> var.op.name.startswith(exclusion):</span><br><span class="line">                excluded = <span class="literal">True</span></span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line">        <span class="keyword">if</span> <span class="keyword">not</span> excluded:</span><br><span class="line">            variable_to_restore.append(var)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 返回一个参数为Session的函数，可以计算variables_to_restore中的变量</span></span><br><span class="line">    <span class="keyword">return</span> slim.assign_from_checkpoint_fn(</span><br><span class="line">        FLAGS.loss_model_file,</span><br><span class="line">        variable_to_restore,</span><br><span class="line">        ignore_missing_vars=<span class="literal">True</span>)</span><br></pre></td></tr></table></figure></p>
<h2 id="3-定义损失函数"><a href="#3-定义损失函数" class="headerlink" title="3. 定义损失函数"></a>3. 定义损失函数</h2><p>首先导入需要的模块。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> os</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"><span class="keyword">from</span> nets <span class="keyword">import</span> nets_factory</span><br><span class="line"><span class="keyword">from</span> preprocessing <span class="keyword">import</span> preprocessing_factory</span><br><span class="line"><span class="keyword">import</span> utils</span><br></pre></td></tr></table></figure></p>
<h2 id="3-1-内容损失函数"><a href="#3-1-内容损失函数" class="headerlink" title="3.1 内容损失函数"></a>3.1 内容损失函数</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">content_loss</span><span class="params">(endpoints_dict, content_layers)</span>:</span></span><br><span class="line">    content_loss = <span class="number">0</span></span><br><span class="line">    <span class="keyword">for</span> layer <span class="keyword">in</span> content_layers:</span><br><span class="line">        generated_images, content_images = tf.split(endpoints_dict[layer], <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">        size = tf.size(generated_images)</span><br><span class="line">        <span class="comment"># 内容损失函数：某layer生成图片与内容图片的L^2距离</span></span><br><span class="line">        content_loss += tf.nn.l2_loss(generated_images - content_images) * <span class="number">2</span> / tf.to_float(size)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> content_loss</span><br></pre></td></tr></table></figure>
<ul>
<li><code>endpoints_dict</code>是一个表示神经网络各层计算结果的字典，字典的<code>key</code>是神经网络层的名称，<code>value</code>是该层的输出张量</li>
<li><code>content_layers</code>是计算内容损失的神经网络层名称，一般都是最后一层卷积层</li>
<li>该函数实现的功能是传入一个神经网络各层计算结果的字典和指定计算内容损失的网络层名称，然后计算该层特征下的内容损失</li>
<li>内容损失是生成图片和原始内容图片在指定层特征的L2差值。把生成图像和原始内容图像拼接在一起之后，输入到损失网络中，这样只要进行一次前向计算，就可以得到生成图像和原始内容图像的content representation。因此这里需要使用<code>tf.split()</code>函数将张量平均切分，第一个张量是生成图像在指定层的特征，第二个张量是原始内容图像在指定层的特征</li>
</ul>
<h2 id="3-2-风格损失函数"><a href="#3-2-风格损失函数" class="headerlink" title="3.2 风格损失函数"></a>3.2 风格损失函数</h2><p>首先定义计算Gram矩阵的函数。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">gram</span><span class="params">(layer)</span>:</span></span><br><span class="line">    shape = tf.shape(layer)</span><br><span class="line">    num_images = shape[<span class="number">0</span>]</span><br><span class="line">    height = shape[<span class="number">1</span>]</span><br><span class="line">    width = shape[<span class="number">2</span>]</span><br><span class="line">    depth = shape[<span class="number">3</span>]</span><br><span class="line">    </span><br><span class="line">    F = tf.reshape(layer, tf.stack([num_images, <span class="number">-1</span>, depth]))</span><br><span class="line">    G = tf.matmul(F, F, transpose_a=<span class="literal">True</span>) / tf.to_float(width * height * depth)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> G</span><br></pre></td></tr></table></figure></p>
<ul>
<li><code>layer</code>表示图像在指定卷积层的特征</li>
<li>在paper解读的博文里解释过，计算卷积特征Gram矩阵的时候，需要先把每个通道中的二维矩阵压缩成一个列向量，本函数的reshape操作即为该过程</li>
</ul>
<p>这里说一些个人对Gram矩阵为什么能表示风格的理解。Gram矩阵的每一个元素是两两向量之间的内积，那么Gram矩阵其实就记录了每个向量和其他向量之间的某种关系，而这种关系表现出来恰好就是人类眼中的“风格”。个人对“风格”这个概念的理解，是一个类似“种群”那样的概念，一个生物无法构成种群，一个像素也没有“风格”，所以我们常常看到的原始风格图像大多都是艺术画那种有较为明显风格的图像，而不会使用一张“梨”图像去学习“苹果”图像的风格，这样风格迁移的图像才好看</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">style_loss</span><span class="params">(endpoints_dict, style_features_t, style_layers)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    style_layers: 需要计算style_loss的层，默认是conv1_2, conv2_2, conv3_3, conv4_3</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    style_loss = <span class="number">0</span></span><br><span class="line">    style_loss_summary = &#123;&#125;</span><br><span class="line">    <span class="keyword">for</span> style_gram, layer <span class="keyword">in</span> zip(style_features_t, style_layers):</span><br><span class="line">        <span class="comment"># 计算风格损失，只需要计算生成图片generated_images与目标风格style_features_t的差距</span></span><br><span class="line">        <span class="comment"># 因此不需要取出content_images</span></span><br><span class="line">        generated_images, _ = tf.split(endpoints_dict[layer], <span class="number">2</span>, <span class="number">0</span>)</span><br><span class="line">        size = tf.size(generated_images)</span><br><span class="line">        <span class="comment"># 风格损失函数：某layer生成图片的Gram矩阵和风格图片的Gram矩阵的L^2距离</span></span><br><span class="line">        layer_style_loss = tf.nn.l2_loss(gram(generated_images) - style_gram) * <span class="number">2</span> / tf.to_float(size)</span><br><span class="line">        style_loss_summary[layer] = layer_style_loss</span><br><span class="line">        style_loss += layer_style_loss</span><br><span class="line">        </span><br><span class="line">    <span class="keyword">return</span> style_loss, style_loss_summary</span><br></pre></td></tr></table></figure>
<ul>
<li><code>endpoints_dict</code>解释同上</li>
<li><code>style_layers</code>是计算风格损失的神经网络层名称，一般是多个卷积层</li>
<li><code>style_features_t</code>是原始风格图像在指定卷积层特征的Gram矩阵列表，有多个矩阵元素</li>
<li><code>style_loss_summary</code>记录了TensorBoard相关的张量，简单的理解为<code>style_loss_summary</code>记录了哪些张量，就可以画出哪些张量的变化趋势图</li>
</ul>
<h2 id="3-3-获取风格图像在指定层的风格特征"><a href="#3-3-获取风格图像在指定层的风格特征" class="headerlink" title="3.3 获取风格图像在指定层的风格特征"></a>3.3 获取风格图像在指定层的风格特征</h2><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_style_features</span><span class="params">(FLAGS)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    获取style image在指定卷积层的Gram特征</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">with</span> tf.Graph().as_default():</span><br><span class="line">        <span class="comment"># network_fn是损失网络函数</span></span><br><span class="line">        network_fn = nets_factory.get_network_fn(FLAGS.loss_model, num_classes=<span class="number">1</span>, is_training=<span class="literal">False</span>)</span><br><span class="line">        <span class="comment"># 损失网络函数要使用的图像预处理函数</span></span><br><span class="line">        image_preprocessing_fn = preprocessing_factory.get_preprocessing(</span><br><span class="line">            FLAGS.loss_model,</span><br><span class="line">            is_training=<span class="literal">False</span>)</span><br><span class="line">        </span><br><span class="line">        <span class="comment"># 载入style image</span></span><br><span class="line">        size = FLAGS.image_size</span><br><span class="line">        img_bytes = tf.read_file(FLAGS.style_image)</span><br><span class="line">        <span class="comment"># 根据图片格式进行解码</span></span><br><span class="line">        <span class="keyword">if</span> FLAGS.style_image.lower().endswith(<span class="string">'png'</span>):</span><br><span class="line">            image = tf.image.decode_png(img_bytes)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            image = tf.image.decode_jpeg(img_bytes)</span><br><span class="line">            </span><br><span class="line">        <span class="comment"># 预处理style image并增加batch dimension</span></span><br><span class="line">        images = tf.expand_dims(image_preprocessing_fn(image, size, size), <span class="number">0</span>)</span><br><span class="line">        </span><br><span class="line">        _, endpoints_dict = network_fn(images, spatial_squeeze=<span class="literal">False</span>)</span><br><span class="line">        features = [] <span class="comment"># 保存style image在预设定卷积层的结果</span></span><br><span class="line">        <span class="keyword">for</span> layer <span class="keyword">in</span> FLAGS.style_layers:</span><br><span class="line">            feature = endpoints_dict[layer]</span><br><span class="line">            feature = tf.squeeze(gram(feature), [<span class="number">0</span>]) <span class="comment"># 去除batch维度</span></span><br><span class="line">            features.append(feature)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">with</span> tf.Session() <span class="keyword">as</span> sess:</span><br><span class="line">            init_func = utils._get_init_fn(FLAGS)</span><br><span class="line">            init_func(sess)</span><br><span class="line">            </span><br><span class="line">            <span class="comment"># check文件路径</span></span><br><span class="line">            <span class="keyword">if</span> os.path.exists(<span class="string">'generated'</span>) <span class="keyword">is</span> <span class="literal">False</span>:</span><br><span class="line">                os.makedirs(<span class="string">'generated'</span>)</span><br><span class="line">            </span><br><span class="line">            save_file = <span class="string">'generated/target_style_'</span> + FLAGS.naming + <span class="string">'.jpg'</span></span><br><span class="line">            <span class="comment"># 把预处理的style image写到文件中</span></span><br><span class="line">            <span class="keyword">with</span> open(save_file, <span class="string">'wb'</span>) <span class="keyword">as</span> f:</span><br><span class="line">                target_image = images[<span class="number">0</span>, :]</span><br><span class="line">                value = tf.image.encode_jpeg(tf.cast(target_image, tf.uint8))</span><br><span class="line">                f.write(sess.run(value))</span><br><span class="line">                tf.logging.info(<span class="string">'Target style pattern is saved to: %s.'</span> % save_file)</span><br><span class="line">                </span><br><span class="line">            <span class="keyword">return</span> sess.run(features)</span><br></pre></td></tr></table></figure>
<ul>
<li><code>FLAGS</code>是一个对象，这个对象记录了所有的配置，比如<code>FLAGS.loss_model</code>表示损失网络使用哪个预训练模型；<code>FLAGS.size</code>表示图像的尺寸</li>
<li><code>get_network_fn()</code>有4个参数<ul>
<li><code>name</code>，欲载入的预训练模型的名称</li>
<li><code>num_classes</code>，模型想要分类的数目</li>
<li><code>weight_decay=0.0</code>，L2正则化系数</li>
<li><code>is_training=False</code>，是否需要训练模型</li>
<li>因为我们只是使用VGG16提取图像特征，因此分类数目随便设置一个数就行，此处取1，也不用训练模型，即<code>is_training=False</code></li>
</ul>
</li>
<li><code>image_preprocessing_fn</code>是预训练模型的图像预处理函数。不同的模型对输入的图像要求都各不相同，有的模型对输入图像尺寸有要求，有的模型需要将像素值压缩在$[-1, 1]$之间，有的模型需要给图像的每个像素值减去训练集的平均像素值，因此在使用预训练模型的时候，都要先调用对应模型的预处理函数处理一下输入的图像</li>
<li><code>tf.expand_dims()</code>函数给图像增加了一个表示第几张图像的维度，此处虽然只输入一张图片，但是依旧要增加这个维度，因为预训练模型的输入张量就是4个维度</li>
<li>将原始风格图片输入到预训练模型中，得到原始风格图片在每一层的特征的字典<code>endpoints_dict</code>，然后使用指定的神经网络层计算Gram矩阵，计算完矩阵以后，使用<code>tf.squeeze()</code>函数去除表示第几张图像的维度</li>
<li>创建一个Session之后，先初始化网络，然后把经过预处理的原始风格图像写入到指定路径中，方便之后和图像生成网络生成的图像进行对比，然后返回表示风格特征的列表</li>
</ul>
<h2 id="4-小结"><a href="#4-小结" class="headerlink" title="4. 小结"></a>4. 小结</h2><ul>
<li>本文中的损失函数都写在<code>losses.py</code>文件中</li>
<li>编写程序的时候始终以论文为依据，本文写这么多代码，总结起来就是一句话：使用损失网络中的预训练模型提取原始内容图像的content representation和原始风格图像的style representation，然后根据公式计算对应的损失</li>
<li>常见的深度学习习惯还是要清楚的，比如输入的图像都是4维张量，<code>endpoints_dict</code>是一个表示神经网络各层计算结果的字典</li>
<li>对于项目中比较常用的工具类函数，全部写在<code>utils.py</code>文件中，逻辑上和使用上更加清楚方便</li>
</ul>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] 何之源. 21个项目玩转深度学习[M]. 北京:电子工业出版社, 2018.<br>[2] <a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/." target="_blank" rel="noopener">moverzp. 【paper笔记】图像风格迁移[EB/OL].</a><br>[3] <a href="http://moverzp.com/2018/08/19/%E5%BF%AB%E9%80%9F%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB%EF%BC%88%E4%B8%80%EF%BC%89%E2%80%94%E2%80%94%E5%9B%BE%E5%83%8F%E7%94%9F%E6%88%90%E7%BD%91%E7%BB%9C/." target="_blank" rel="noopener">moverzp. 快速图像风格迁移（一）——图像生成网络[EB/OL].</a><br>[4] Gatys L A, Ecker A S, Bethge M. A Neural Algorithm of Artistic Style[J]. Computer Science, 2016.<br>[5] Johnson J, Alahi A, Li F F. Perceptual Losses for Real-Time Style Transfer and Super-Resolution[C]// European Conference on Computer Vision. Springer, Cham, 2016:694-711.<br>[6] <a href="https://tensorflow.google.cn/tutorials/" target="_blank" rel="noopener">https://tensorflow.google.cn/tutorials/</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/30/快速图像风格迁移（二）——损失函数/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-快速图像风格迁移（一）——图像生成网络" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/19/快速图像风格迁移（一）——图像生成网络/">快速图像风格迁移（一）——图像生成网络</a>
    </h1>
  

        
        <a href="/2018/08/19/快速图像风格迁移（一）——图像生成网络/" class="archive-article-date">
  	<time datetime="2018-08-18T18:12:02.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-19</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>之前在<a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" target="_blank" rel="noopener">【paper笔记】图像风格迁移</a>博文中大概介绍了图像风格迁移的原理。博主准备使用一个系列来讲解复现的过程，使用的深度学习框架是TensorFlow，首先实现的是图像生成网络模块。</p>
<h2 id="1-TensorFlow预备知识"><a href="#1-TensorFlow预备知识" class="headerlink" title="1.TensorFlow预备知识"></a>1.TensorFlow预备知识</h2><h4 id="1-1tf-pad-tensor-paddings-mode-39-CONSTANT-39-constant-values-0"><a href="#1-1tf-pad-tensor-paddings-mode-39-CONSTANT-39-constant-values-0" class="headerlink" title="1.1tf.pad(tensor, paddings, mode=&#39;CONSTANT&#39;, constant_values=0)"></a>1.1<code>tf.pad(tensor, paddings, mode=&#39;CONSTANT&#39;, constant_values=0)</code></h4><p>按照某种方式填充张量。我们以2维张量为例，在维度0前添加0个维度，维度0后添加1个维度；维度1前添加1个维度，维度1后添加2个维度。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line">x = tf.ones(shape=[<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># [[1. 1.]</span></span><br><span class="line"><span class="comment">#  [1. 1.]</span></span><br><span class="line"><span class="comment">#  [1. 1.]]</span></span><br><span class="line">x_padded = tf.pad(x, [[<span class="number">0</span>, <span class="number">1</span>], [<span class="number">1</span>, <span class="number">2</span>]])</span><br><span class="line"><span class="comment"># [[0. 1. 1. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 1. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 1. 1. 0. 0.]</span></span><br><span class="line"><span class="comment">#  [0. 0. 0. 0. 0.]]</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-2tf-where-condition-x-None-y-None"><a href="#1-2tf-where-condition-x-None-y-None" class="headerlink" title="1.2tf.where(condition, x=None, y=None)"></a>1.2<code>tf.where(condition, x=None, y=None)</code></h4><p>类似于<code>np.where()</code>，根据<code>condition</code>选择<code>x</code>或者<code>y</code>。比如可以用来将张量中的<code>nan</code>转化为<code>0</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line">x = tf.constant([<span class="number">1</span>, <span class="number">2</span>, np.nan])</span><br><span class="line">y = tf.where(tf.equal(x, x), x, tf.zeros_like(x)) <span class="comment">#nan和本身不相等</span></span><br><span class="line"><span class="comment"># [1, 2, 0]</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-3tf-nn-moments-x-axes-shift-None-name-None-keep-dims-False"><a href="#1-3tf-nn-moments-x-axes-shift-None-name-None-keep-dims-False" class="headerlink" title="1.3tf.nn.moments(x, axes, shift=None, name=None, keep_dims=False)"></a>1.3<code>tf.nn.moments(x, axes, shift=None, name=None, keep_dims=False)</code></h4><p>计算<code>x</code>的均值和方差。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant([<span class="number">1.</span>, <span class="number">2.</span>, <span class="number">3.</span>, <span class="number">4.</span>, <span class="number">5.</span>, <span class="number">6.</span>], shape=[<span class="number">3</span>, <span class="number">2</span>])</span><br><span class="line"><span class="comment"># [[1. 2.]</span></span><br><span class="line"><span class="comment">#  [3. 4.]</span></span><br><span class="line"><span class="comment">#  [5. 6.]]</span></span><br><span class="line">mean, var = tf.nn.moments(x, [<span class="number">0</span>, <span class="number">1</span>])</span><br><span class="line"><span class="comment"># mean, var = 3.5, 2.9166667</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-4tf-stack-values-axis-0"><a href="#1-4tf-stack-values-axis-0" class="headerlink" title="1.4tf.stack(values, axis=0)"></a>1.4<code>tf.stack(values, axis=0)</code></h4><p>把张量列表按照给定轴堆叠，堆叠张量会比元素张量多1个维度。设元素张量的尺寸为<code>(A, B, C)</code>，如果<code>axis == 0</code>，那么堆叠张量尺寸为<code>(N, A, B, C)</code>. 如果<code>axis == 1</code>，那么堆叠张量尺寸为<code>(A, N, B, C)</code> .<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 元素尺寸是(2,)，N=3</span></span><br><span class="line">x = tf.constant([<span class="number">1</span>, <span class="number">4</span>])</span><br><span class="line">y = tf.constant([<span class="number">2</span>, <span class="number">5</span>])</span><br><span class="line">z = tf.constant([<span class="number">3</span>, <span class="number">6</span>])</span><br><span class="line">stack0 = tf.stack([x, y, z], axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># [[1 4]</span></span><br><span class="line"><span class="comment">#  [2 5]</span></span><br><span class="line"><span class="comment">#  [3 6]]</span></span><br><span class="line">stack1 = tf.stack([x, y, z], axis=<span class="number">1</span>)</span><br><span class="line"><span class="comment"># [[1 2 3]</span></span><br><span class="line"><span class="comment">#  [4 5 6]]</span></span><br></pre></td></tr></table></figure></p>
<h4 id="1-5tf-slice-input-begin-size"><a href="#1-5tf-slice-input-begin-size" class="headerlink" title="1.5tf.slice(input_, begin, size)"></a>1.5<code>tf.slice(input_, begin, size)</code></h4><p>对张量进行切片操作。<code>input_</code>是待切片张量，<code>begin</code>是切片的起始位置，和<code>input_</code>的维度对应，<code>size</code>是切片的大小，三者的尺寸一致。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">x = tf.constant(np.arange(<span class="number">9</span>), shape=[<span class="number">3</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># [[0 1 2]</span></span><br><span class="line"><span class="comment">#  [3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8]]</span></span><br><span class="line">tf.slice(x, [<span class="number">1</span>, <span class="number">0</span>], [<span class="number">2</span>, <span class="number">3</span>])</span><br><span class="line"><span class="comment"># [[3 4 5]</span></span><br><span class="line"><span class="comment">#  [6 7 8]]</span></span><br></pre></td></tr></table></figure></p>
<h2 id="2-各层网络实现"><a href="#2-各层网络实现" class="headerlink" title="2.各层网络实现"></a>2.各层网络实现</h2><h3 id="2-1conv2d定义"><a href="#2-1conv2d定义" class="headerlink" title="2.1conv2d定义"></a>2.1<code>conv2d</code>定义</h3><p>为了较好的处理图像边界像素，使用<code>REFLECT</code>的方式进行像素填充。在神经网络中常常使用4维张量表示图像数据集，第一维表示第几张图像，第二维表示图像高度，第三维表示图像宽度，第四维表示图像的通道数，因此定义的卷积函数在填充时，只需填充第二维和第三维的数据。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">conv2d</span><span class="params">(x, input_depth, output_depth, ksize, strides, mode=<span class="string">'REFLECT'</span>)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv'</span>):</span><br><span class="line">        shape = [ksize, ksize, input_depth, output_depth] <span class="comment"># 正方形卷积核</span></span><br><span class="line">        weight = tf.Variable(tf.truncated_normal(shape, stddev=<span class="number">0.1</span>))</span><br><span class="line">        x_padded = tf.pad(x, [[<span class="number">0</span>, <span class="number">0</span>], [int(ksize / <span class="number">2</span>), int(ksize / <span class="number">2</span>)], [int(ksize / <span class="number">2</span>), int(ksize / <span class="number">2</span>)], [<span class="number">0</span>, <span class="number">0</span>]], mode=mode)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> tf.nn.conv2d(x_padded, weight, strides=[<span class="number">1</span>, strides, strides, <span class="number">1</span>], padding=<span class="string">'VALID'</span>, name=<span class="string">'conv'</span>)</span><br></pre></td></tr></table></figure></p>
<h3 id="2-2instance-norm定义"><a href="#2-2instance-norm定义" class="headerlink" title="2.2instance_norm定义"></a>2.2<code>instance_norm</code>定义</h3><p>InstanceNorm是将一个样本进行标准化（均值为0，标准差为1），类似于BatchNorm，这么做可以加快网络的收敛速度，提高非线性拟合的能力，而且可以有效地提高图像风格迁移的质量。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">instance_norm</span><span class="params">(x)</span>:</span></span><br><span class="line">    epsilon = <span class="number">1e-9</span></span><br><span class="line">    mean, var = tf.nn.moments(x, [<span class="number">1</span>, <span class="number">2</span>], keep_dims=<span class="literal">True</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">return</span> tf.div(tf.subtract(x, mean), tf.sqrt(tf.add(var, epsilon)))</span><br></pre></td></tr></table></figure></p>
<p>分母增加了一个微小的平滑因子，避免除以<code>0</code>.</p>
<h3 id="2-3relu定义"><a href="#2-3relu定义" class="headerlink" title="2.3relu定义"></a>2.3<code>relu</code>定义</h3><p>就是简单的包装了一下<code>tf.nn.relu()</code>，当某个数值是<code>nan</code>的时候，置为<code>0</code>.<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">relu</span><span class="params">(x)</span>:</span></span><br><span class="line">    relu = tf.nn.relu(x)</span><br><span class="line">    <span class="comment"># 把nan转化为0， nan和nan比较结果为False</span></span><br><span class="line">    <span class="keyword">return</span> tf.where(tf.equal(relu, relu), relu, tf.zeros_like(relu))</span><br></pre></td></tr></table></figure></p>
<h3 id="2-4residual定义"><a href="#2-4residual定义" class="headerlink" title="2.4residual定义"></a>2.4<code>residual</code>定义</h3><p>残差层如下图所示。<br><img src="http://markdown.moverzp.com/18-8-17/22386605.jpg" alt><br>残差网络是何凯明等人在2015年的ImageNet比赛中提出来的，其在数据集上准确率已经超越了人类。残差网络非常深，达到了152层之深，网络名称是<strong>ResNet</strong>，其中最重要的就是残差层。</p>
<p>如果权重变得特别的小，那么残差层学习的就是恒等函数($H(x)\approx x$)，这是比较容易的，而且网络的性能不受影响，因此ResNet不管层数有多少，训练误差都不会像没有残差块的网络那样越来越大。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">residual</span><span class="params">(x, input_depth, ksize, strides)</span>:</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'residual'</span>):</span><br><span class="line">        conv1 = conv2d(x, input_depth, input_depth, ksize, strides)</span><br><span class="line">        conv2 = conv2d(relu(conv1), input_depth, input_depth, ksize, strides)</span><br><span class="line">        residual = x + conv2</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> residual</span><br></pre></td></tr></table></figure></p>
<h3 id="2-5resize-conv2d定义"><a href="#2-5resize-conv2d定义" class="headerlink" title="2.5resize_conv2d定义"></a>2.5<code>resize_conv2d</code>定义</h3><p><code>resize_conv2d()</code>实现的是反卷积层的功能，反卷积(deconv)的名字其实有点迷惑性，因为它本质就是卷积。卷积有一个特点，就是不在边界填充数值的话，张量的尺寸会越来越小，因此卷积神经网络的结构一般也是越来越深，越来越窄。但是有时候需要扩大张量的尺寸，比如把深窄的张量还原成3层但是较大的张量，即图像。方法就是把提前把张量扩得超级大，然后进行卷积，这样卷积后的张量相比于卷积前的张量尺寸还是减小的，但是相比于扩大之前的张量，还是变大了。</p>
<p><img src="http://markdown.moverzp.com/18-8-17/14451114.jpg" alt><br><a href="http://markdown.moverzp.com/18-8-17/14451114.jpg" target="_blank" rel="noopener">点击查看反卷积动态示意图</a></p>
<p>关于反卷积可以查看博文<a href="https://blog.csdn.net/u014722627/article/details/60574260" target="_blank" rel="noopener">深度学习|反卷积/转置卷积 的理解 transposed conv/deconv</a>，讲得很不错。</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">resize_conv2d</span><span class="params">(x, input_depth, output_depth, ksize, strides, traning)</span>:</span></span><br><span class="line">    <span class="comment"># 先放大，再卷积</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv_transpose'</span>):</span><br><span class="line">        <span class="comment"># 源程序此处设定训练时的变量是数值，预测时的变量是tensor</span></span><br><span class="line">        height = x.get_shape()[<span class="number">1</span>].value</span><br><span class="line">        width = x.get_shape()[<span class="number">2</span>].value</span><br><span class="line">        </span><br><span class="line">        new_height = height * strides * <span class="number">2</span></span><br><span class="line">        new_width = width * strides * <span class="number">2</span></span><br><span class="line">        </span><br><span class="line">        x_resized = tf.image.resize_images(x, [new_height, new_width], tf.image.ResizeMethod.NEAREST_NEIGHBOR)</span><br><span class="line">        </span><br><span class="line">        <span class="keyword">return</span> conv2d(x_resized, input_depth, output_depth, ksize, strides)</span><br></pre></td></tr></table></figure>
<h2 id="3-图像生成网络搭建"><a href="#3-图像生成网络搭建" class="headerlink" title="3.图像生成网络搭建"></a>3.图像生成网络搭建</h2><p>拟搭建的网络结构如下图所示。<br><img src="http://markdown.moverzp.com/18-8-15/20225955.jpg" alt><br>简单而言，就是3个卷积层，5个残差层，3个反卷积层。</p>
<p>使用第二节定义的各层函数，按照上图的结构搭建图像生成网络。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">net</span><span class="params">(image, training)</span>:</span></span><br><span class="line">    <span class="comment"># 在图片的上下左右加一些边框，消除边缘效应</span></span><br><span class="line">    image = tf.pad(image, [[<span class="number">0</span>, <span class="number">0</span>], [<span class="number">10</span>, <span class="number">10</span>], [<span class="number">10</span>, <span class="number">10</span>], [<span class="number">0</span>, <span class="number">0</span>]], mode=<span class="string">'REFLECT'</span>)</span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 3个卷积层，深度变化：3--&gt;32--&gt;64--&gt;128</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv1'</span>):</span><br><span class="line">        conv1 = relu(instance_norm(conv2d(image, <span class="number">3</span>, <span class="number">32</span>, <span class="number">9</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv2'</span>):</span><br><span class="line">        conv2 = relu(instance_norm(conv2d(conv1, <span class="number">32</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>)))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'conv3'</span>):</span><br><span class="line">        conv3 = relu(instance_norm(conv2d(conv2, <span class="number">64</span>, <span class="number">128</span>, <span class="number">3</span>, <span class="number">2</span>)))</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 5个残差块</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'res1'</span>):</span><br><span class="line">        res1 = residual(conv3, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'res2'</span>):</span><br><span class="line">        res2 = residual(res1, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'res3'</span>):</span><br><span class="line">        res3 = residual(res2, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'res4'</span>):</span><br><span class="line">        res4 = residual(res3, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'res5'</span>):</span><br><span class="line">        res5 = residual(res4, <span class="number">128</span>, <span class="number">3</span>, <span class="number">1</span>)</span><br><span class="line">        </span><br><span class="line">    <span class="comment"># 使用反卷积重新生成图像</span></span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'deconv1'</span>):</span><br><span class="line">        deconv1 = relu(instance_norm(resize_conv2d(res5, <span class="number">128</span>, <span class="number">64</span>, <span class="number">3</span>, <span class="number">2</span>, training)))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'deconv2'</span>):</span><br><span class="line">        deconv2 = relu(instance_norm(resize_conv2d(deconv1, <span class="number">64</span>, <span class="number">32</span>, <span class="number">3</span>, <span class="number">2</span>, training)))</span><br><span class="line">    <span class="keyword">with</span> tf.variable_scope(<span class="string">'deconv3'</span>):</span><br><span class="line">        <span class="comment"># 因为到这一步生成的图像大小已经和原图像相同，故不再进行反卷积</span></span><br><span class="line">        deconv3 = tf.nn.tanh(instance_norm(conv2d(deconv2, <span class="number">32</span>, <span class="number">3</span>, <span class="number">9</span>, <span class="number">1</span>)))</span><br><span class="line">    <span class="comment"># deconv3的值域属于(-1, 1)，变换到[0, 255]</span></span><br><span class="line">    y = (deconv3 + <span class="number">1</span>) * <span class="number">127.5</span></span><br><span class="line">    </span><br><span class="line">    <span class="comment"># 去除一开始为了防止边缘效应而加入的“边框”</span></span><br><span class="line">    height = tf.shape(y)[<span class="number">1</span>]</span><br><span class="line">    width = tf.shape(y)[<span class="number">2</span>]</span><br><span class="line">    y = tf.slice(y, [<span class="number">0</span>, <span class="number">10</span>, <span class="number">10</span>, <span class="number">0</span>], tf.stack([<span class="number">-1</span>, height - <span class="number">20</span>, width - <span class="number">20</span>, <span class="number">-1</span>]))</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> y</span><br></pre></td></tr></table></figure></p>
<h2 id="4-参考资料"><a href="#4-参考资料" class="headerlink" title="4.参考资料"></a>4.参考资料</h2><p>[1] 何之源. 21个项目玩转深度学习[M]. 北京:电子工业出版社, 2018.<br>[2] jdefla. 深度学习 | 反卷积/转置卷积 的理解 transposed conv/deconv[EB/OL]. <a href="https://blog.csdn.net/u014722627/article/details/60574260" target="_blank" rel="noopener">https://blog.csdn.net/u014722627/article/details/60574260</a>.<br>[3] moverzp. 【paper笔记】图像风格迁移[EB/OL]. <a href="http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/" target="_blank" rel="noopener">http://moverzp.com/2018/08/10/%E3%80%90paper%E7%AC%94%E8%AE%B0%E3%80%91%E5%9B%BE%E5%83%8F%E9%A3%8E%E6%A0%BC%E8%BF%81%E7%A7%BB/</a>.<br>[4] Gatys L A, Ecker A S, Bethge M. A Neural Algorithm of Artistic Style[J]. Computer Science, 2016.<br>[5] Johnson J, Alahi A, Li F F. Perceptual Losses for Real-Time Style Transfer and Super-Resolution[C]// European Conference on Computer Vision. Springer, Cham, 2016:694-711.<br>[6] <a href="https://tensorflow.google.cn/tutorials/" target="_blank" rel="noopener">https://tensorflow.google.cn/tutorials/</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/19/快速图像风格迁移（一）——图像生成网络/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-【paper笔记】图像风格迁移" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/10/【paper笔记】图像风格迁移/">【paper笔记】图像风格迁移</a>
    </h1>
  

        
        <a href="/2018/08/10/【paper笔记】图像风格迁移/" class="archive-article-date">
  	<time datetime="2018-08-09T16:56:29.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-10</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p><img src="http://markdown.moverzp.com/18-8-5/44378925.jpg" alt><br>图像风格迁移是深度学习一个较为简单的应用，有一款名为Prisma的APP，就可以对用户的选择的图像进行风格转换。图像风格迁移一般是学习CNN人员都会了解的一个项目。图像风格迁移方面的基础知识看下面2篇paper就够了：</p>
<p>[1] Gatys L A, Ecker A S, Bethge M. A Neural Algorithm of Artistic Style[J]. Computer Science, 2016.<br>[2] Johnson J, Alahi A, Li F F. Perceptual Losses for Real-Time Style Transfer and Super-Resolution[C]// European Conference on Computer Vision. Springer, Cham, 2016:694-711.</p>
<h2 id="A-Neural-Algorithm-of-Artistic-Style"><a href="#A-Neural-Algorithm-of-Artistic-Style" class="headerlink" title="A Neural Algorithm of Artistic Style"></a>A Neural Algorithm of Artistic Style</h2><p>该paper首次提出了图像风格迁移的相关理论，要点记录如下</p>
<ul>
<li>CNN一般的结构是前面若干个卷积层，后面1~3个全连接层，因此可以把这些卷积层看做特征抽取的器，卷积层抽取出特征后，全连接层进行分类</li>
<li>CNN随着网络越来越深，图像的actual content越来越清晰，越来越不在意图像的细节，即pixel values. 【actual content可以理解为图像“本源”内容，不是我们肉眼直接看到的内容，比如我们人类可以认出各种各样的猫，虽然猫的各个品种相差很大，但是一定能认出是猫，这就是我们的大脑学习了猫的“本源”内容】</li>
<li>使用卷积后的特征进行图像重建，越浅层的卷积层结果重建出的图像越清晰，越深层的卷积层结果重建出的图像像素信息丢失的越严重，但是actual content越明显</li>
<li>将CNN深层的特征称为<strong>content representation</strong></li>
<li>将CNN的特征映射到风格空间中，可以得到style features，根据style features重建的图像更能表达出图像的风格，即<strong>style representation</strong></li>
<li><strong>一个图像的content representation和style representation是可以分离的，因此可以使用A图像content representation和B图像的style representation混合成一个新图像AB</strong>【风格迁移最关键的理论点】</li>
<li><p>事实上，content representation和style representation又不是完全分离的，因此在损失函数中有两项及其权重，一项表示content representation，一项表示style representation，如果content项的权重过大，生成的图像会明显偏向于提供content的图像，而没有提供style的图像的风格；如果style项的权重过大，生成的图像会明显偏向于提供style的图像，而没有提供content图像的内容<br><img src="http://markdown.moverzp.com/18-8-5/79535590.jpg" alt><br>(<em>每一列最上面的数字表示content项的权重和style项的权重的比值</em>)</p>
</li>
<li><p>该论文以VGG19作为基准模型</p>
</li>
<li>令$\vec p$表示原始图像，$\vec x$表示生成的图像，每一层每一个通道元素展开成一个向量，因此每一层的数据可以表示为<code>shape=(height*width, depth)</code>的二维矩阵，在第$l$层表示这两张图像的矩阵是$P^l, F^l$，则有损失函数<script type="math/tex; mode=display">L_{content}(\vec p, \vec x, l) = \dfrac {1}{2} \sum _{i,j} (F_{ij}^l-P_{ij}^l)^2</script>对$F^l$求导，则有<script type="math/tex; mode=display">\dfrac {\partial L_{content}}{\partial F_{ij}^l} = 
\begin{cases}
(F^l - P^l)_{ij}, &if\ F_{ij}^l > 0\\
0, &if\ F_{ij}^l < 0
\end{cases}</script></li>
<li>使用Gram矩阵描述风格，第$l$层的矩阵表示为$G^l, G^l \in R^{N_l\times N_l}$， 具体计算公式如下<script type="math/tex; mode=display">G_{ij}^l=\sum _{k}F_{ik}^lF_{jk}^l</script></li>
<li><p>换一个方式描述Gram矩阵可能会更清楚一些，设有矩阵$A=[\vec x_1, \vec x_2, \vec x_3]$，则关于$A$的Gram矩阵是</p>
<script type="math/tex; mode=display">
Gram(A)= \begin{bmatrix}
\vec x_1 \cdot \vec x_1 & \vec x_1 \cdot \vec x_2 & \vec x_1 \cdot \vec x_3 \\ 
\vec x_2 \cdot \vec x_1 & \vec x_2 \cdot \vec x_2 & \vec x_2 \cdot \vec x_3 \\
\vec x_3 \cdot \vec x_1 & \vec x_3 \cdot \vec x_2 & \vec x_3 \cdot \vec x_3 \\
\end{bmatrix}</script></li>
<li><p>令$\vec a$表示原始图像，$\vec x$表示生成的图像，在第$l$层表示这两张图像的Gram矩阵是$A^l, G^l$，卷积通道数是$N_l$，每一个通道的像素数是$M_l$，则第$l$层有损失</p>
<script type="math/tex; mode=display">E_l = \dfrac {1}{4N_l^2M_l^2} \sum _{i,j} ( G_{ij}^l - A_{ij}^l )^2</script><p>则所有层的损失按照一定的权重构成style损失函数</p>
<script type="math/tex; mode=display">L_{style}(\vec a, \vec x) = \sum _{l=0}^L w_lE_l</script><p>每一层的损失$E_l$对$F^l$求偏导数</p>
<script type="math/tex; mode=display">\dfrac {\partial E_{l}}{\partial F_{ij}^l} = 
\begin{cases}
\frac {1}{4N_l^2M_l^2}( (F^l)^T (G^l - A^l) )_{ji}, &if\ F_{ij}^l > 0\\
0, &if\ F_{ij}^l < 0
\end{cases}</script><p>$\frac {1}{4N_l^2M_l^2}$就是一个调整系数，防止content损失和style损失数量级上有差距</p>
</li>
<li><p>content损失和style损失组合起来就是最终的损失函数</p>
<ul>
<li>$\dfrac {\alpha} {\beta}$取值一般在0.01~0.02左右</li>
<li>content损失是根据某一层来算的，一般是最后一个卷积层</li>
<li>style损失是根据多个卷积层来计算的 <script type="math/tex; mode=display">
L_{total}(\vec p, \vec a, \vec x) = \alpha L_{content} + \beta L_{style}</script></li>
</ul>
</li>
<li><p>随机产生一张图像，然后使用梯度下降法优化损失函数，最终将随机产生的这张图像收敛到目标图像。因此原始的得到风格迁移图像的方法非常慢，每一次的风格迁移都相当于一次模型训练，无法做到实时风格迁移</p>
</li>
</ul>
<h2 id="Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution"><a href="#Perceptual-Losses-for-Real-Time-Style-Transfer-and-Super-Resolution" class="headerlink" title="Perceptual Losses for Real-Time Style Transfer and Super-Resolution"></a>Perceptual Losses for Real-Time Style Transfer and Super-Resolution</h2><p>该论文解决了上篇论文中无法实时风格迁移的问题，而这个解决方法很简单，即使用一个神经网络去进行图像风格迁移，该网络被称为生成网络。生成网络会学习某张图像image1的风格，然后输入一张图像image2，输出一张带有图像image1风格，image2内容的图像。对于已经训练好的生成网络，获得风格迁移的图像只需要进行一次前馈计算，因此可以做到实时风格迁移。</p>
<p>实时风格迁移的网络结构如下图所示：<br><img src="http://markdown.moverzp.com/18-8-9/59327236.jpg" alt></p>
<ul>
<li>上图有两个神经网络，一个是图像生成网络，一个是损失网络</li>
<li>损失网络就是VGG网络，主要用来提取图像的特征，不过上一篇paper的VGG是VGG19，本篇paper的VGG是VGG16</li>
<li>$x$表示输入的图像，$\hat y$表示图像生成网络生成的图像，$y_c$表示目标内容图像，$y_s$表示目标风格图像，一般情况下，输入图像$x$就是$y_c$</li>
<li>$y_c$使用损失网络的relu3_3层提取出content representation</li>
<li>$y_s$使用损失网络的relu1_2, relu2_2, relu3_3, relu4_3层提取出style representation</li>
<li>使用content representation计算$L_{content}$，使用style representation计算$L_{style}$</li>
<li>根据$L_{content}$和$L_{style}$得到$L_{total}$</li>
<li>图像生成网络的损失函数就是$L_{total}$，使用梯度下降法不断地减小损失函数即可</li>
<li>训练集是Microsoft COCO dataset，把所有的图片resize为<code>256*256</code>大小，令<code>batch_size=4</code>，迭代<code>40000</code>次，优化器是<code>Adam</code>，学习率是<code>0.0001</code>，不使用weight decay和dropout，在GTX Titan X GPU上大约训练了4小时达到收敛状态</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color1">paper</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/10/【paper笔记】图像风格迁移/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-树模型串烧" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/08/05/树模型串烧/">树模型串烧</a>
    </h1>
  

        
        <a href="/2018/08/05/树模型串烧/" class="archive-article-date">
  	<time datetime="2018-08-05T11:58:33.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-08-05</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>业界最常用的两类算法模型是树模型和神经网络模型。工作一年多来，和别的组，别的公司的同学朋友都聊了聊，只要在应用场景中能上神经网络模型，基本都会上神经网络模型，一是效果确实有较为显著的提升，二是不用再绞尽脑汁地去构造特征。但是由于树模型有较强的可解释性，而且对于数据量的要求没有神经网络模型那么高，因此树模型虽然日渐式微，但是也无法被完全取代。在kaggle等竞赛中，由于数据量比较小，XGBoost和LightGBM仍旧是比赛的首选模型。在某次交流分享中，阿里的双十一推荐负责人说他们推荐主要是神经网络模型，但是为了应付产品和运营总是问为什么，所以又搞了一套树模型（逃……</p>
<p>树模型相对于神经网络模型确实要简单一些，因此花了一些时间，总结了一些常见树模型（ID3\C4.5\CART决策树，GBDT，RF，XGBoost，LightGBM）的要点，采用问答的方式，写一个串烧博文。</p>
<h3 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h3><p><strong>决策树有哪些种类，如何区分？</strong><br>ID3决策树使用<strong>信息增益</strong>进行特征选择，C4.5决策树先使用信息增益选择平均值以上的特征，然后使用<strong>信息增益率</strong>进行特征选择，CART使用<strong>Gini指数</strong>进行分类时的特征选择，回归使用<strong>平方误差最小化</strong>。</p>
<p><strong>决策树中都有哪些信息论的概念？</strong><br>熵，熵越大表示信息越多</p>
<script type="math/tex; mode=display">H(p)=-\sum _{i=1}^n p_i \log _2p_i</script><p>信息增益/互信息</p>
<script type="math/tex; mode=display">gain(D,A)=H(D)-H(D|A)</script><p>数据集D的经验熵</p>
<script type="math/tex; mode=display">H(D)=-\sum _{k=1}^K \dfrac {|D_k|}{|D|} \log _2 \dfrac {|D_k|}{|D|}</script><p>数据集D关于A的经验条件熵</p>
<script type="math/tex; mode=display">H(D|A)=\sum _{i=1}^n \dfrac {|D_i|}{|D|}H(D_i)=-\sum _{i=1}^n \dfrac {|D_i|}{|D|}\sum _{k=1}^K\dfrac {|D_{ik}|}{|D_i|}\log _2 \dfrac {|D_{ik}|}{|D_i|}</script><p>信息增益比</p>
<script type="math/tex; mode=display">gain_R(D,A)=\dfrac {gain(D, A)}{H_A(D)}</script><p>数据集D关于特征A的熵</p>
<script type="math/tex; mode=display">H_A(D)=-\sum_{i=1}^n \dfrac {|D_i|} {|D|} \log_2 \dfrac {|D_i|}{|D|}</script><p>基尼指数</p>
<script type="math/tex; mode=display">Gini(p)=1-\sum _{i=1}^np_i^2</script><p>在特征A的条件下，集合D的基尼指数定义为(CART是二叉树)</p>
<script type="math/tex; mode=display">Gini(D,A)=\dfrac {|D_1|}{|D|} Gini(D_1)+\dfrac {|D_2|}{|D|} Gini(D_2)</script><p><strong>决策树的损失函数是什么？</strong><br>设树$T$的叶节点个数是$|T|$，$t$是$T$的叶节点，该叶节点有$N_t$个样本点，其中$k$类的样本点有$N_{tk}$个，$H_t(T)$是叶节点$t$上的经验熵，损失函数如下所示</p>
<script type="math/tex; mode=display">C_\alpha(T)=\sum _{t=1}^{|T|}N_tH_t(T)+\alpha |T|</script><p>常常简单表示为</p>
<script type="math/tex; mode=display">C_\alpha(T) = C(T)+\alpha |T|</script><p>ID3，C4.5中$\alpha$是手动输入的，CART中$\alpha$是自动选择的。</p>
<p><strong>决策树损失函数各项的意义是什么？</strong><br>$C(T)$描述的是模型训练的误差，$\alpha |T|$描述的是模型的复杂度。决策树生成只考虑了对训练集进行更好的拟合，即尽可能的降低$C(T)$，决策树的剪枝则降低了模型的复杂度，换一句话说，决策树的生成学习局部模型，决策树的剪枝学习整体模型。</p>
<p><strong>决策树如何处理连续值？</strong><br>主要处理方法是连续属性离散化。对于连续属性$a$，从小到大排序，然后取分界点$t$将数据集$D$分成$D_t^+, D_t^-$，分界点公式如下所示</p>
<script type="math/tex; mode=display">T_a=\left\{  \dfrac {a_i + a_{i+1}} {2} | 1 \leq i \leq n-1  \right \}</script><p>然后根据二分后的信息增益确定最佳边界。</p>
<script type="math/tex; mode=display">\begin{aligned}
Gain(D,a)&=\max _{t \in {T_a}} Gain(D, a, t)\\
&=\max _{t \in {T_a}} \left (H(D) - \sum _{\lambda \in \{-,+\} } \dfrac {|D_t^{\lambda }|}{|D|} H(D_t^{\lambda })\right )
\end{aligned}</script><p>连续值属性在后代结点划分中可以继续使用，因为后代结点划分并不和父结点冲突。</p>
<p><strong>决策树如何处理缺失值？</strong><br>设有数据集$D$，属性$a$，令$\tilde D$表示属性$a$上无缺失值，设$a$有$V$个值，$\tilde {D^v}$表示$a$上取值为$a^v$的样本子集，$\tilde {D_k}$表示$\tilde D$中属于第$k$类的样本子集，显然有$\tilde D=U_{k=1}^K \tilde {D_k}=U_{v=1}^V \tilde {D^v}$，每个样本都有一个权重$w_{\vec x}$，初始化为1，且定义</p>
<script type="math/tex; mode=display">\begin {aligned}
\rho &=\dfrac {\sum _{x \in \tilde D}w_{\vec x}} {\sum _{x \in D}w_{\vec x}}\\
\tilde p_k &= \dfrac {\sum_{x \in \tilde {D_k}} w_{\vec x}} {\sum_{x \in \tilde {D}} w_{\vec x}}\\
\tilde {r}_v &= \dfrac {\sum _{x \in \tilde {D^v}} w_{\vec x}} {\sum _{x \in \tilde {D}} w_{\vec x}}
\end {aligned}</script><p>对信息增益公式进行推广</p>
<script type="math/tex; mode=display">Gain(D, a) = \rho \cdot Gain(\tilde D, a) = \rho [H(\tilde D) - \sum _{v=1}^V \tilde {r_v}H(\tilde D^v)]</script><p>又</p>
<script type="math/tex; mode=display">H(\tilde D) = -\sum _{k=1}^K \tilde {p_k} \log \tilde {p_k}</script><p>若样本$x$在属性$a$上有缺失值，则将$x$划入所有的子节点中，不过每个$a^v$子节点中$x$相应的权重系数$w_{\vec x}$变化为$\tilde r_v w_{\vec x}$，即表示样本$x$以不同的概率值划分到不同的子节点中。</p>
<p><strong>如何防止决策树过拟合？</strong><br>预剪枝或者后剪枝，一般情况下，后剪枝会保留更多的分支，欠拟合风险更小，泛化性能更优，不过训练开销会更大一些。在剪枝的时候，采取奥卡姆剃刀原则，即剪枝和不剪枝损失函数相等的时候，进行剪枝。</p>
<h3 id="提升树"><a href="#提升树" class="headerlink" title="提升树"></a>提升树</h3><p><strong>什么是提升树模型？</strong><br>提升树模型可以理解为基于前向分步算法的决策树加法模型：</p>
<script type="math/tex; mode=display">f_M(x) = \sum _{m=1}^M T(x;\theta _m)</script><p>前向分步算法：</p>
<script type="math/tex; mode=display">f_m(x) = f_{m-1}(x) + T(x;\theta_m)</script><p>在前向分步算法第m步中，需求解</p>
<script type="math/tex; mode=display">\hat \theta _m = \arg \min _{\theta _m} \sum _{i=1}^N L(y_i, f_{m-1}(x)+T(x_i;\theta _m))</script><p><strong>如何理解提升树中的残差概念？</strong><br>如果定义损失函数是平方误差损失函数，则有</p>
<script type="math/tex; mode=display">\begin {aligned}
&L(y, f_{m-1}(x) + T(x;\theta _m))\\
&=[y-f_{m-1}(x) - T(x;\theta _m)]^2\\
&=[r - T(x;\theta _m)]^2
\end {aligned}</script><p>$r=y-f_{m-1}(x) $即为残差，提升树模型不断地去拟合残差生成下一个树模型。</p>
<p><strong>梯度提升树(GBDT)和提升树的异同？</strong><br>不断地拟合残差生成下一个树模型非常的方便，但是大部分的损失函数都不好优化，因此使用<strong>损失函数的负梯度</strong>作为残差的近似值</p>
<script type="math/tex; mode=display">\hat r=-\left [  \dfrac {\partial L(y, f(x_i))}{\partial f(x_i)}  \right ]_{f(x)=f_{m-1}(x)}</script><p>不断地去拟合残差近似值生成下一个树模型。如果误差损失函数依旧是平方误差损失函数，那么损失函数的负梯度就是残差。</p>
<h3 id="RF"><a href="#RF" class="headerlink" title="RF"></a>RF</h3><p><strong>什么是随机森林？</strong><br>随机森林(Random Forest)是一种典型的bagging模型。在随机森林中，只随机选择一部分特征来构建树（而不是子采样实例），以减少了树之间的相关性，即减少模型的方差。假设数据集在某次分裂之前的特征数为$d$，随机抽取的特征数为$k$，则一般情况下$k = \log _2 d$，如果取$k = d$，那么生成的每一颗树都会一模一样。</p>
<p>在RF训练的时候，使用<code>min_samples_leaf</code>（叶节点的样本的最小数量）来控制树大小和过拟合程度。</p>
<p><strong>随机森林可以用来筛选特征吗？为什么？</strong><br>可以。在决策树中，更重要的特征可能更接近树的顶部。通过计算它在森林中所有树上出现的平均深度，我们可以得到一个特征对于随机森林的重要性。（不过现在很少这么做了）</p>
<h3 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h3><p><strong>XGBoost和GBDT有什么区别</strong></p>
<ul>
<li>XGBoost是在GBDT的基础上发展出来的，GBDT使用Taylor的一阶展开去拟合下一个树，XGBoost使用Taylor二阶展开去拟合下一个树</li>
<li>XGBoost在代价函数里加入了正则项，用于控制模型的复杂度，降低了过拟合风险，效果优于GBDT</li>
<li>XGBoost在特征选择时进行了并行处理</li>
</ul>
<p><strong>XGBoost的目标函数是什么？</strong><br>由于xgb也是前向加法模型，即$\hat y_i^{(t)} = \hat y_i^{(t-1)} + f_t(x_i)$，$f_t(x_i)$就是在第t轮训练中需要训练的模型。所以第t轮的目标函数是</p>
<script type="math/tex; mode=display">\begin {aligned}
Obj^{(t)} &= \sum _{i=1}^n l(y_i, \hat y_i^{(t)}) + \sum _{i=1}^t\Omega (f_i)\\
&= \sum _{i=1}^n l(y_i, \hat y_i^{(t-1)} + f_t(x_i)) + \Omega (f_t) + constant
\end {aligned}</script><p>但是这样的目标函数不好优化，所以在$\hat y^t$维度上进行Taylor二阶展开</p>
<script type="math/tex; mode=display">\begin {aligned}
f(x+\delta x) &= f(x) + f'(x)\delta x + \frac {1}{2} f''(x) \delta x^2 \\
g_i &= \partial _{\hat y ^{t-1}} l(y_i, \hat y_i^{(t-1)}) \\
h_i &= \partial ^2_{\hat y^{(t-1)}} l(y_i, \hat y_i^{(t-1)}) \\
\end {aligned}</script><p>则有</p>
<script type="math/tex; mode=display">
Obj^{(t)} = \sum _{i=1}^n [l(y_i, \hat y_i^{(t-1)}) + g_if_t(x_i) + \frac {1}{2} h_if_t^2(x_i)  ] + \Omega (f_t) + constant</script><p>代入$\Omega (f_t)$并去除$constant$</p>
<script type="math/tex; mode=display">\begin {aligned}
Obj^{(t)} &= \sum _{i=1}^n [g_if_t(x_i) + \frac {1}{2} h_if_t^2(x_i) ] + \Omega (f_t) \\
&=  \sum _{j=1}^T [G_jw_j + \frac {1}{2}(H_j + \lambda )w_j^2] + \gamma T
\end {aligned}</script><p><strong>XGB的复杂度项是什么？</strong><br>并不唯一，陈天奇的PPT中定义为</p>
<script type="math/tex; mode=display">\Omega (f_t)=\gamma T + \dfrac {1}{2} \lambda \sum _{j=1}^Tw_j^2</script><p>第一项是叶节点的数目，第二项是叶节点分数的L2正则。</p>
<p><strong>XGB中子节点是如何分裂的？</strong><br>利用目标函数去计算增益，如果目标函数值降低了，则进行划分，叶节点的最佳分数及其对应的目标函数都可以通过公式直接求出</p>
<script type="math/tex; mode=display">
argmin_x Gx + \frac {1}{2}Hx^2 = -\frac {G}{H}, H>0\quad min_x  Gx + \frac {1}{2}Hx^2 = -\frac {1}{2} \frac {G^2}{H}</script><p>所以叶节点的分数及其目标函数如下所示</p>
<script type="math/tex; mode=display">
w_j = -\frac {G_j}{H_j + \lambda }, \quad Obj = -\frac {1}{2} \sum _{j=1}^T \frac {G_j^2}{H_j + \lambda} + \gamma T</script><p>定义增益为分类前的目标函数减去分类后的目标函数，遍历所有特征，然后选择增益最大的特征分割点</p>
<script type="math/tex; mode=display">
Gain = \frac {1}{2} [\frac {G_L^2}{H_L + \lambda} + \frac {G_R^2}{H_L + \lambda} - \frac {(G_L + G_R)^2}{H_L+H_R+\lambda}] - \gamma</script><p><strong>XGB训练算法的复杂度是多少？</strong><br>在特征选择前首先要进行排序，如果要生成深度为$K$，特征数为$d$的树，则时间复杂度为$O(Kdn\log n)$.</p>
<p><strong>为什么说XGB是并行的？</strong><br>XGB在树粒度上依旧是串行的，并行是在分裂节点的时候进行，同时计算多个属性的分裂特征点，然后选择收益最大的特征及其分裂特征点。</p>
<p><strong>XGB有什么缺点？</strong></p>
<ul>
<li>level-wise 建树方式对当前层的所有叶子节点一视同仁，有些叶子节点分裂收益非常小，对结果没影响，但还是要分裂，加重了计算代价</li>
<li>预排序方法空间消耗比较大，不仅要保存特征值，也要保存特征的排序索引</li>
</ul>
<h3 id="LGBM"><a href="#LGBM" class="headerlink" title="LGBM"></a>LGBM</h3><p><strong>LGBM在速度和内存上进行了哪些优化？</strong><br>LGBM使用了histogram算法，通过将连续特征分段为discrete bins来加快训练的速度并减少内存的使用。</p>
<ul>
<li>减少分割增益的计算量<ul>
<li>pre-sorted算法需要<code>#data</code>次的计算</li>
<li>histogram算法需要<code>#bins</code>次的计算，且<code>#bins</code>远小于<code>#data</code><ul>
<li>构建直方图时仍需要<code>#data</code>次计算</li>
</ul>
</li>
</ul>
</li>
<li>通过直方图的相减来进行进一步的加速<ul>
<li>在二叉树中，可以通过叶节点的父结点和相邻结点的直方图相减来获得该叶节点的直方图，且代价很小</li>
</ul>
</li>
<li>减少内存的使用<ul>
<li>因为将连续值替换为discrete bins，如果<code>#bins</code>较小，可以利用较小的数据类型来存储数据，如uint8</li>
<li>无需为 pre-sorted 特征值存储额外的信息</li>
</ul>
</li>
<li>减少并行学习的通信代价</li>
<li>带有深度限制的Leaf-wise的叶子生长策略，每次从当前所有的叶子中，找到分裂增益最大的一个叶子，然后分裂。因此同Level-wise相比，在分裂次数相同的情况下，Leaf-wise可以降低更多的误差，得到更好的精度<ul>
<li>这么做的缺点是容易过拟合，因此一般会加上一个最大深度限制，防止过拟合</li>
</ul>
</li>
</ul>
<p><strong>LGBM有什么缺点？</strong><br>LGBM使用histogram算法，histogram算法不能找到很精确的分界点，训练误差理论上应该比pre-sorted差，但是实际上效果差不多，甚至效果更佳，有可能决策树对于分割点的精确程度并不太敏感，而且较“粗”的分割点也自带正则化的效果。</p>
<h2 id="参考资料"><a href="#参考资料" class="headerlink" title="参考资料"></a>参考资料</h2><p>[1] 李航. 统计学习方法[M]. 清华大学出版社, 2012.<br>[2]周志华. 机器学习 : = Machine learning[M]. 清华大学出版社, 2016.<br>[3] Introduction to Boosted Trees[EB/OL]. <a href="http://xgboost.readthedocs.io/en/latest/tutorials/model.html" target="_blank" rel="noopener">http://xgboost.readthedocs.io/en/latest/tutorials/model.html</a>.</p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/08/05/树模型串烧/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Kaggle-DonorsChoose-org-Application-Screening【Top-10-】" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/07/13/Kaggle-DonorsChoose-org-Application-Screening【Top-10-】/">Kaggle DonorsChoose.org Application Screening【Top 10%】</a>
    </h1>
  

        
        <a href="/2018/07/13/Kaggle-DonorsChoose-org-Application-Screening【Top-10-】/" class="archive-article-date">
  	<time datetime="2018-07-12T16:46:43.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-07-13</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <h2 id="0-习惯的碎碎念"><a href="#0-习惯的碎碎念" class="headerlink" title="0. 习惯的碎碎念"></a>0. 习惯的碎碎念</h2><p>距离上一篇博文已经过去4个月，闯斯还在微信上问我为何不写博客了（囧）。一方面是自从开年以来，感觉时间特别得紧，主R了一个项目，倒也不难，但是特别的费精力，改了好几次需求，所以下班以后只有input的时间和精力，没时间output，笔记里面攒了好多好多的想法和实践；另一方面也是学得越多，越觉得自己水，不太愿意写博文。现在时间稍微多了一些，而且觉得写博文主要就是自我总结，然后说不定能帮助到其他人，所以把写博文又提上了Todo List.</p>
<p>工作一年多了，现在还处在每天大量吸收知识的状态，也不知道是好还是不好😂。</p>
<p>今天想要分享的是在2018-04~2018-05利用业余时间参加的一个kaggle比赛，取得的成绩是Public Leaderboard Top 4%, Private Leaderboard Top 10%.</p>
<h2 id="1-题目解析"><a href="#1-题目解析" class="headerlink" title="1. 题目解析"></a>1. 题目解析</h2><p>原题地址：<a href="https://www.kaggle.com/c/donorschoose-application-screening" target="_blank" rel="noopener">DonorsChoose.org Application Screening</a></p>
<p>DonorsChoose.org是一个教学资助机构，美国的教师可以向该机构申请教学基金和物品。越来越多的教师向该机构发起申请，现在每年大概有50W+的申请数量，过多的申请数量导致了3个问题</p>
<ul>
<li>如何调整当前人工审核的流程，才能高效且快速地得出基金是否发放的结果</li>
<li>如何统一不同审核人员对于同一个项目的看法</li>
<li>如何让审核人员的精力花费在有意义的项目审核上</li>
</ul>
<p>本次比赛的目标就是预测一个申请被批准的概率，审核人员会优先审核预测通过率较高的项目。</p>
<p><strong>评价函数：AUC</strong></p>
<h3 id="数据集"><a href="#数据集" class="headerlink" title="数据集"></a>数据集</h3><p><code>train.csv</code>和<code>test.csv</code>文件字段及说明如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">id</td>
<td>申请id</td>
</tr>
<tr>
<td style="text-align:left">teacher_id</td>
<td>申请教师id</td>
</tr>
<tr>
<td style="text-align:left">teacher_prefix</td>
<td>教师名称前缀(Ms., Mr., etc.)</td>
</tr>
<tr>
<td style="text-align:left">school_state</td>
<td>学校所在州</td>
</tr>
<tr>
<td style="text-align:left">project_submitted_datetime</td>
<td>申请时间戳</td>
</tr>
<tr>
<td style="text-align:left">project_grade_category</td>
<td>所在年级(PreK-2, 3-5, 6-8, and 9-12)</td>
</tr>
<tr>
<td style="text-align:left">project_subject_categories</td>
<td>主题(e.g., “Music &amp; The Arts”)</td>
</tr>
<tr>
<td style="text-align:left">project_subject_subcategories</td>
<td>子主题(e.g., “Visual Arts”)</td>
</tr>
<tr>
<td style="text-align:left">project_title</td>
<td>申请题目</td>
</tr>
<tr>
<td style="text-align:left">project_essay_1</td>
<td>第1份材料，主要讲述学生</td>
</tr>
<tr>
<td style="text-align:left">project_essay_2</td>
<td>第2份材料，主要讲述资金和物品用途</td>
</tr>
<tr>
<td style="text-align:left">project_resource_summary</td>
<td>所需资金和物品总结</td>
</tr>
<tr>
<td style="text-align:left">teacher_number_of_previously_posted_projects</td>
<td>该教师之前提交过的次数</td>
</tr>
<tr>
<td style="text-align:left">project_is_approved</td>
<td>申请是否通过</td>
</tr>
</tbody>
</table>
</div>
<p><strong>注</strong>：<em>其实还有project_essay_3和project_essay_4，经过处理后可以和project_essay_1和project_essay_2合并，为了书写方便，直接就从合并后开始讲</em></p>
<p><code>resource.csv</code>文件字段及说明如下表所示：</p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">名称</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">id</td>
<td>申请id</td>
</tr>
<tr>
<td style="text-align:left">description</td>
<td>申请物品描述</td>
</tr>
<tr>
<td style="text-align:left">quantity</td>
<td>申请物品数量</td>
</tr>
<tr>
<td style="text-align:left">price</td>
<td>申请物品价格</td>
</tr>
</tbody>
</table>
</div>
<h2 id="2-数据清洗和特征工程"><a href="#2-数据清洗和特征工程" class="headerlink" title="2. 数据清洗和特征工程"></a>2. 数据清洗和特征工程</h2><p>本次比赛提供了诸多特征，有数值特征，类别特征和文本特征。</p>
<h3 id="2-1-resource-csv特征处理"><a href="#2-1-resource-csv特征处理" class="headerlink" title="2.1 resource.csv特征处理"></a>2.1 resource.csv特征处理</h3><ul>
<li>根据<code>quantity</code>和<code>price</code>计算每一项物品的申请总价<code>price_all</code></li>
<li>根据<code>id</code>进行groupby操作，计算本次申请所需要的物品种类数<code>items</code>，物品总申请数<code>quantity</code>，单价和<code>price_sum</code>，总价和<code>price_all_sum</code>，平均价<code>price_avg</code>，产出5个统计特征</li>
<li>把max(), min(), mean()作用于<code>quantity</code>, <code>price</code>, <code>price_all</code>，产出9个统计特征</li>
<li>根据<code>id</code>进行groupby操作，把属于同一个<code>id</code>的所有申请物品描述使用空格连接起来，特征类型是文本</li>
</ul>
<p>把处理后的resource数据通过<code>id</code>特征与train/test进行join.</p>
<h3 id="2-2-统计特征处理"><a href="#2-2-统计特征处理" class="headerlink" title="2.2 统计特征处理"></a>2.2 统计特征处理</h3><ul>
<li>根据<code>teacher_prefix</code>推断申请教师的性别<code>teacher_gender</code></li>
<li>统计<code>teacher_id</code>，<code>teacher_gender</code>，<code>school_state</code>，<code>project_grade_category</code>，<code>project_grade_category</code>，<code>project_subject_categories</code>，<code>teacher_number_of_previously_posted_projects</code>特征每一个数值的占比</li>
</ul>
<p>举个例子，一个list=[‘a’, ‘a’, ‘b’, ‘c’]，则’a’的衍生特征为0.50，’b’的衍生特征为0.25，’c’的衍生特征为0.25</p>
<h3 id="2-3-情感特征处理"><a href="#2-3-情感特征处理" class="headerlink" title="2.3 情感特征处理"></a>2.3 情感特征处理</h3><h4 id="2-3-1-情感分析知识补充"><a href="#2-3-1-情感分析知识补充" class="headerlink" title="2.3.1 情感分析知识补充"></a>2.3.1 情感分析知识补充</h4><p>文本一般情况下都有自己的情感倾向，一般分为褒义和贬义两种。使用<code>textblob</code>可以进行简单的情感分析，<code>TextBlob(string).sentiment</code>返回一个元组<code>(polarity, subjectivity)</code></p>
<ul>
<li>第一个元素<code>polarity</code>是区间[-1, 1]内的一个浮点数，表示消极情感（负数）或积极情感（正数）的程度</li>
<li>第二个元素<code>subjectivity</code>是区间[0, 1]内的一个浮点数，表示主客观程度，0表示客观，1表示主观</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> textblob <span class="keyword">import</span> TextBlob</span><br><span class="line"></span><br><span class="line">sent1 = TextBlob(<span class="string">'There is nothing more enjoyable than reading.'</span>).sentiment</span><br><span class="line">sent2 = TextBlob(<span class="string">"Can you stop watching such a boring movie?"</span>).sentiment</span><br><span class="line">print(sent1)</span><br><span class="line">print(sent2)</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># Sentiment(polarity=0.5, subjectivity=0.55)</span></span><br><span class="line"><span class="comment"># Sentiment(polarity=-0.5, subjectivity=0.75)</span></span><br></pre></td></tr></table></figure>
<h4 id="2-3-2-情感特征处理"><a href="#2-3-2-情感特征处理" class="headerlink" title="2.3.2 情感特征处理"></a>2.3.2 情感特征处理</h4><p>一般情况下，文本的情感倾向是一个较为重要的特征。文本特征中的标点符号，另类表达方式，I或者we，甚至是段落的划分都有可能影响阅读者的情感，具体怎么划分褒贬现在并没有一个统一的方法。</p>
<ul>
<li>本文使用textblob包进行情感分析，调用该包提供的情感分析方法去判断每一个文本特征(<code>project_title</code>, <code>project_essay_1</code>, <code>project_essay_2</code>, <code>project_resource_summary</code>, <code>description</code>)的情感倾向，并将其作为新特征，表示对应特征的褒贬特性及可信度</li>
<li>由于符号和常用表达短语也可能影响阅读者的体验，所以还需要统计这些符号和常用表达短语在每一个文本特征中出现的次数，作为新的特征</li>
<li>文本的长度也会影响阅读者的体验，所以每个文本特征又可以衍生出其长度的特征</li>
<li>重复出现的词汇数量也会影响阅读者的体验，所以两两文本特征之间可以衍生出共有词汇数量的特征</li>
</ul>
<p>统计的特殊字符如下列所示：<br>KeyChars = [‘!’, ‘\?’, ‘@’, ‘#’, ‘$‘, ‘%’, ‘&amp;’, ‘*‘, ‘(‘, ‘[‘, ‘\{‘, ‘|‘, ‘-‘, ‘_’, ‘=’, ‘+‘,  ‘.‘, ‘:’, ‘;’, ‘,’, ‘/‘, ‘\\\\r’, ‘\\\\t’, ‘\\”‘, ‘...‘, ‘etc’, ‘http’, ‘poor’, ‘military’, ‘traditional’, ‘charter’, ‘head start’, ‘magnet’, ‘year-round’, ‘alternative’, ‘art’, ‘book’, ‘basics’, ‘computer’, ‘laptop’, ‘tablet’, ‘kit’, ‘game’, ‘seat’, ‘food’, ‘cloth’, ‘hygiene’, ‘instraction’, ‘technolog’, ‘lab’, ‘equipment’, ‘music’, ‘instrument’, ‘nook’, ‘desk’, ‘storage’, ‘sport’, ‘exercise’, ‘trip’, ‘visitor’, ‘my students’, ‘our students’, ‘my class’, ‘our class’]</p>
<p>经过以上特征处理之后，可以明显的发现感叹号较多的申请被拒绝的次数更多。<br><img src="http://markdown.moverzp.com/18-7-11/33748016.jpg" alt></p>
<h3 id="2-4-时间特征"><a href="#2-4-时间特征" class="headerlink" title="2.4 时间特征"></a>2.4 时间特征</h3><ul>
<li>根据申请时间戳<code>project_submitted_datetime</code>生成<code>year</code>, <code>month</code>, <code>day</code>, <code>dayofweek</code>, <code>hour</code>, <code>days</code>等特征</li>
<li>生成时间特征的统计特征</li>
</ul>
<h3 id="2-5-组合特征"><a href="#2-5-组合特征" class="headerlink" title="2.5 组合特征"></a>2.5 组合特征</h3><ul>
<li>类似于FM，两两数值特征之间进行相乘组合，有可能会产生更有用的特征，使用pearson相关系数筛选组合后的特征，保留与目标值相似性较高的组合特征。</li>
</ul>
<p>比如<code>max_price</code>与<code>mean_price</code>组合的特征和目标值相似度就比单独的特征高<br><img src="http://markdown.moverzp.com/18-7-11/32251762.jpg" alt><br><img src="http://markdown.moverzp.com/18-7-11/6735806.jpg" alt><br><img src="http://markdown.moverzp.com/18-7-11/67700094.jpg" alt></p>
<h3 id="2-6-类别特征"><a href="#2-6-类别特征" class="headerlink" title="2.6 类别特征"></a>2.6 类别特征</h3><p>由于类别特征多为文本类特征，因此使用词向量的方式。</p>
<h4 id="2-6-1-词向量知识补充"><a href="#2-6-1-词向量知识补充" class="headerlink" title="2.6.1 词向量知识补充"></a>2.6.1 词向量知识补充</h4><p>词向量是处理文本一种常见的方式。词向量的<strong>维度数</strong>等于<strong>所有文本中不重复的单词数</strong>，每个位置对应一个单词，单词对应位置的数值表示单词在该文本中出现的频数。在sklearn中可以使用<code>CountVectorizer</code>进行词向量转化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> CountVectorizer</span><br><span class="line"></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">'This is the first document.'</span>,</span><br><span class="line">    <span class="string">'This is the second second document.'</span>,</span><br><span class="line">    <span class="string">'And the third one.'</span>,</span><br><span class="line">    <span class="string">'Is this the first document?'</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">count_vectorizer = CountVectorizer()</span><br><span class="line">X = count_vectorizer.fit_transform(corpus)</span><br><span class="line">print(count_vectorizer.get_feature_names())</span><br><span class="line">print(X.toarray())</span><br><span class="line"><span class="comment"># output:</span></span><br><span class="line"><span class="comment"># ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']</span></span><br><span class="line"><span class="comment"># [[0 1 1 1 0 0 1 0 1]</span></span><br><span class="line"><span class="comment">#  [0 1 0 1 0 2 1 0 1]</span></span><br><span class="line"><span class="comment">#  [1 0 0 0 1 0 1 1 0]</span></span><br><span class="line"><span class="comment">#  [0 1 1 1 0 0 1 0 1]]</span></span><br></pre></td></tr></table></figure></p>
<h4 id="2-6-2-类别特征转化为词向量"><a href="#2-6-2-类别特征转化为词向量" class="headerlink" title="2.6.2 类别特征转化为词向量"></a>2.6.2 类别特征转化为词向量</h4><ul>
<li>使用原始特征<code>teacher_prefix</code>, <code>school_state</code>, <code>project_grade_category</code>, <code>project_subject_categories</code>, <code>project_subject_subcategories</code>计算词向量</li>
</ul>
<h3 id="2-7-文本特征"><a href="#2-7-文本特征" class="headerlink" title="2.7 文本特征"></a>2.7 文本特征</h3><p>这一部分的文本特征主要是指长文本特征，即<code>project_title</code>，<code>project_essay_1</code>，<code>project_essay_2</code>，<code>project_resource_summary</code>，<code>description</code></p>
<ul>
<li>清除单词时态，单复数变化等</li>
<li>使用词向量的方式处理长文本特征</li>
<li>使用TF-IDF的方式处理长文本特征</li>
<li>使用word2vec的方式处理长文本特征</li>
</ul>
<h4 id="2-7-1-TF-IDF知识补充"><a href="#2-7-1-TF-IDF知识补充" class="headerlink" title="2.7.1 TF-IDF知识补充"></a>2.7.1 TF-IDF知识补充</h4><p>TF-IDF(term frequency–inverse document frequency)是一种用于信息检索与文本挖掘的常用加权技术。tf-idf是一种统计方法，用以评估一字词对于一个文件集或一个语料库中的其中一份文件的重要程度。<a href="https://zh.wikipedia.org/wiki/Tf-idf" target="_blank" rel="noopener">维基百科TF-IDF</a>中的定义较为常见</p>
<p><img src="http://markdown.moverzp.com/18-7-13/92759988.jpg" alt><br><em>此处公式总是渲染不对，所以直接用截图代替了</em></p>
<p>维基百科举了一个很通俗易懂的例子，具体如下图所示<br><img src="http://markdown.moverzp.com/18-7-11/74757990.jpg" alt></p>
<p>在sklearn中可以使用<code>TfidfVectorizer</code>进行词向量转化，不过sklearn中的算法进行了些许改动，<a href="http://scikit-learn.org/stable/modules/feature_extraction.html#tfidf-term-weighting" target="_blank" rel="noopener">具体可以看文档</a></p>
<ul>
<li>使用频数作为分子，而不是频率</li>
<li>计算idf的时候，分子分母同时加1</li>
<li>计算idf的时候，取对数以e为底，并且最后加1</li>
<li>为了避免某文档中某个词的频数过高，计算出所有次的tf-idf后，进行了L2标准化</li>
</ul>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> sklearn.feature_extraction.text <span class="keyword">import</span> TfidfVectorizer</span><br><span class="line"></span><br><span class="line">corpus = [</span><br><span class="line">    <span class="string">'This is the first document.'</span>,</span><br><span class="line">    <span class="string">'This is the second second document.'</span>,</span><br><span class="line">    <span class="string">'And the third one.'</span>,</span><br><span class="line">    <span class="string">'Is this the first document?'</span></span><br><span class="line">]</span><br><span class="line"></span><br><span class="line">tfidf_vectorizer = TfidfVectorizer()</span><br><span class="line">X = tfidf_vectorizer.fit_transform(corpus)</span><br><span class="line"></span><br><span class="line">print(tfidf_vectorizer.get_feature_names())</span><br><span class="line"><span class="comment"># ['and', 'document', 'first', 'is', 'one', 'second', 'the', 'third', 'this']</span></span><br><span class="line">print(X)<span class="comment"># 此处X是稀疏矩阵</span></span><br></pre></td></tr></table></figure>
<h4 id="2-7-2-word2vec知识补充"><a href="#2-7-2-word2vec知识补充" class="headerlink" title="2.7.2 word2vec知识补充"></a>2.7.2 word2vec知识补充</h4><p>word2vec也是常见的文本处理方式，可以使用固定维数的向量表示文本，具体可以参考<a href="https://zhuanlan.zhihu.com/p/26306795" target="_blank" rel="noopener">[NLP] 秒懂词向量Word2vec的本质</a>. </p>
<p>词向量的训练需要花费大量的时间，所以一般情况下，如果不是特别专业的方向，都是使用各大研究所或者互联网公司训练好的词向量。本文使用的是Facebook公开的fastText预训练词向量数据集，fastText词向量的语料是维基百科或者网络上爬取的文本，一共有三个版本，本文使用的是最大的预训练词向量数据集<a href="https://fasttext.cc/docs/en/english-vectors.html" target="_blank" rel="noopener">crawl-300d-2M.vec.zip</a>.</p>
<h2 id="3-单模型训练"><a href="#3-单模型训练" class="headerlink" title="3. 单模型训练"></a>3. 单模型训练</h2><h3 id="3-1-XGBoost"><a href="#3-1-XGBoost" class="headerlink" title="3.1 XGBoost"></a>3.1 XGBoost</h3><p>XGBoost自从被天奇大佬发明以后，风靡各个数据挖掘竞赛，相比于传统的机器学习算法，准确率高，速度快，但是在微软亚研院的LightGBM出现以后，风头开始降低。</p>
<p>XGBoost主要的调整参数有：</p>
<ul>
<li>objective，训练目标</li>
<li>eta，更新权重的步长，越小训练越慢</li>
<li>num_round，迭代次数</li>
<li>subsample，训练数据的抽样比例</li>
<li>colsample_bytree，训练特征的抽样比例</li>
<li>max_depth，最大树深</li>
<li>eval_metric，评价标准</li>
<li>early_stopping_rounds，及早停止的训练次数</li>
</ul>
<p>调参的基本套路：</p>
<ul>
<li>根据实际情况设置正确的objective和eval_metric</li>
<li>eta设置的大一些，如0.1~0.2，num_round设置的小一些，如300~500，使用GridSearch方法对其他参数进行搜索</li>
<li>逐步降低eta，找到最佳值，这个时候训练时间会越来越长</li>
<li>如果出现了过拟合现象，调低max_depth，early_stoppoing_rounds</li>
</ul>
<p><strong>XGBoost单模型的提交分数是0.81005.</strong></p>
<h3 id="3-2-LightGBM"><a href="#3-2-LightGBM" class="headerlink" title="3.2 LightGBM"></a>3.2 LightGBM</h3><p>LightGBM是微软亚洲研究院在2016年10开源的boosting模型，相比于XGBoost，<strong>内存占用减小至1/6~1/5，训练速度提升至5~10倍，但是精度没有影响</strong>，甚至还略有提升，所以在各大数据挖掘竞赛中露脸的频率越来越多，毕竟时间就是生命。LightGBM相比于传统的GBDT算法，主要是使用了直方图算法，大大减少了训练的时间。</p>
<p>主要的调整参数有：</p>
<ul>
<li>boosting_type, 决策树类型，缺省值为gbdt</li>
<li>objective, 训练目标</li>
<li>metric, 评价函数</li>
<li>max_depth, 最大深度</li>
<li>learning_rate, 学习率</li>
<li>feature_fraction, 随机选择特征数，[0,1]之间</li>
<li>bagging_fraction, 类似于 feature_fraction, 但是它将在不进行重采样的情况下随机选择部分数据</li>
</ul>
<p>调参的套路和XGBoost差不多。<strong>LightGBM单模型的提交得分是0.81322.</strong></p>
<h3 id="3-3-Capsule-Network"><a href="#3-3-Capsule-Network" class="headerlink" title="3.3 Capsule Network"></a>3.3 Capsule Network</h3><p>Capsule Network是Hinton大佬在2017年10月提出的新型神经网络结构。Capsule Network和以往的神经网络最大的不同就是每一个节点不再是标量，而是矢量，即<strong>vector in vector out</strong>。Capsule在论文中就是最基本的向量单元。</p>
<p>Capsule Network的提出主要是为了解决CNN忽略结构信息的问题，如下图所示，更改了眼睛和嘴唇的位置，CNN还是把图像识别为人类，如果把图片旋转180度，CNN就不能识别出人类了，因此为了避免这种情况，训练CNN之前需要进行数据增强等操作。<br><img src="http://markdown.moverzp.com/18-7-12/15315353.jpg" alt></p>
<p>Capsule Network论文关键词主要有动态路由算法，压缩函数，耦合系数，Capsule Network具体内容详见参考资料[4]和[5]。</p>
<p><strong>Capsule Network单模型的提交得分是0.81800.</strong></p>
<h2 id="4-模型融合"><a href="#4-模型融合" class="headerlink" title="4. 模型融合"></a>4. 模型融合</h2><p>模型融合就是把之前的单模型进行堆叠，或者说是组合，是一种bagging的思想。最简单的模型融合就是直接取平均数（回归）或者投票（分类）。当然，简单的代价就是精度的牺牲，kaggle比赛到后期千分位级别分数的提升都能前进好几名，因此大家一般都是使用稍微复杂一点的stacking方法进行模型融合，即<strong>使用模型去进行模型融合</strong>。</p>
<h3 id="4-1-有CV的stacking"><a href="#4-1-有CV的stacking" class="headerlink" title="4.1 有CV的stacking"></a>4.1 有CV的stacking</h3><p><img src="http://markdown.moverzp.com/18-7-12/1540463.jpg" alt><br>一般情况下都是5折交叉验证，使用训练集其中的4份数据训练模型，然后将剩下的1份数据和测试集代入模型，得到对应的预测值，这样最终可以得到某个模型在整个训练集上的预测值和5份测试集的预测值，将训练集上的预测值拼接在一起，作为第二层训练集的一列特征；将5份测试集的预测值求一个平均数，作为第二层测试集的一列特征。</p>
<p>对于所有单模型进行这样的操作，每个单模型都可以产出一列数据，将各个列的数据拼接起来，最终可以得到第二层的训练集和测试集。</p>
<p>这里使用交叉验证的方式训练模型并得到第二层的数据集是非常关键的一步，这么做的目的是避免数据集污染。</p>
<p><img src="http://markdown.moverzp.com/18-7-12/83081258.jpg" alt><br>以上图为例，是一个2层的stacking，第1层一共训练了3个模型，然后将这3个模型预测的结果在水平方向进行堆叠，得到第二层的数据集，第二层使用XGB进行5折交叉验证训练，得到最终的预测结果。</p>
<p><strong>使用该方法堆叠本文训练的3个模型，提交得分为0.82278.</strong></p>
<h3 id="4-2-无CV的stacking"><a href="#4-2-无CV的stacking" class="headerlink" title="4.2 无CV的stacking"></a>4.2 无CV的stacking</h3><p>无CV的stacking其实有点无聊，并且有刷公榜的嫌疑（笔者无聊至极，靠着这个方法刷到过公榜Top 2%）。Kaggle参赛者分享的kernel中都有模型预测的测试集结果，可以直接下载。这个时候没有训练集对应的标签，可以做一个简易版的stacking，不过一般精度都不如有CV的stacking。</p>
<p>以本文为例，Kaggle上有众多kernel，挑选得分0.78以上预测结果下载，作为融合的准备数据（选取别的模型预测结果的时候，可以使用pearson相关系数来筛选）</p>
<ul>
<li>载入若干个模型预测的结果y[i]及其分数score[i]，均为矢量</li>
<li>设置参数power，多为4，8，16，32，64等</li>
<li>计算权重weight[i] = score[i] ** power</li>
<li>使用logit函数将y[i]展开到[-∞, +∞]</li>
<li>根据weight[i]求加权平均数</li>
<li>将求得平均数再使用sigmoid函数压缩到[0, 1]之间，得到最终结果</li>
</ul>
<p><img src="http://markdown.moverzp.com/18-7-12/93055165.jpg" alt><br>logit函数</p>
<p><img src="http://markdown.moverzp.com/18-7-12/72013636.jpg" alt><br>sigmoid函数</p>
<p>本质就是一种bagging的思想，得分越高，占的权重就越大，<strong>提交得分为0.82633</strong>，该方法由于没有CV验证，所以很容易过拟合，private score也证实确实发生了过拟合。</p>
<h2 id="5-经验和心得"><a href="#5-经验和心得" class="headerlink" title="5. 经验和心得"></a>5. 经验和心得</h2><ul>
<li>留出1~2月的业余时间比较合理，尤其是比赛截止最后几天，会杀出很多程咬金，public leaderboard变化非常频繁，我最后就掉以轻心了从12th掉到22th</li>
<li>一个有效的CV非常重要，一般情况下，CV比public leaderboard上面的分数更加接近private score，尤其是public score和CV score相差较大时，以CV score为准</li>
<li>特征非常的重要，大概需要花费整个比赛的2/3~3/4的时间与精力</li>
<li>大概在public leaderboard排到Top 10%的位置的时候，就可以进行模型融合了，现在的比赛异常激烈，基本上到最后就是疯狂地stacking，进行若干层stacking，即stacking of stacking of stacking of stacking…</li>
<li>多看看比赛的kernel和评论区，即使是边边角角的评论也不要放过，很可能就有大神的讨论</li>
</ul>
<h2 id="6-参考资料"><a href="#6-参考资料" class="headerlink" title="6.参考资料"></a>6.参考资料</h2><p>[1].<a href="https://www.kaggle.com/safavieh/ultimate-feature-engineering-xgb-lgb-nn/notebook" target="_blank" rel="noopener">https://www.kaggle.com/safavieh/ultimate-feature-engineering-xgb-lgb-nn/notebook</a><br>[2].<a href="http://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters" target="_blank" rel="noopener">http://xgboost.readthedocs.io/en/latest/parameter.html#general-parameters</a><br>[3].<a href="http://lightgbm.apachecn.org/cn/latest/Parameters.html" target="_blank" rel="noopener">http://lightgbm.apachecn.org/cn/latest/Parameters.html</a><br>[4].<a href="https://arxiv.org/abs/1710.09829" target="_blank" rel="noopener">DSabour S, Frosst N, Hinton G E. Dynamic Routing Between Capsules[J]. 2017.</a><br>[5].<a href="https://kexue.fm/archives/4819" target="_blank" rel="noopener">https://kexue.fm/archives/4819</a></p>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">机器学习</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/07/13/Kaggle-DonorsChoose-org-Application-Screening【Top-10-】/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
    <article id="post-Pandas和PySpark中的DataFrame比较" class="article article-type-post  article-index" itemscope itemprop="blogPost">
  <div class="article-inner">
    
      <header class="article-header">
        
  
    <h1 itemprop="name">
      <a class="article-title" href="/2018/03/17/Pandas和PySpark中的DataFrame比较/">Pandas和PySpark中的DataFrame比较</a>
    </h1>
  

        
        <a href="/2018/03/17/Pandas和PySpark中的DataFrame比较/" class="archive-article-date">
  	<time datetime="2018-03-17T13:47:10.000Z" itemprop="datePublished"><i class="icon-calendar icon"></i>2018-03-17</time>
</a>
        
      </header>
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>在数据清洗时，常常使用DataFrame类型的对象来装载结构化数据，单机操作使用Pandas就够了，分布式操作常常使用PySpark，这两种情况下都有DataFrame类型，为了更好的掌握这两个包中的DataFrame，很有必要做一次对比分析。</p>
<p>Pandas和PySpark中DataFrame类型常见操作的异同均列在下表中。<br><em>说明：表格中的引号在后台都是半角，前端都变成了全角，可能是博客框架的问题</em></p>
<div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:left">项目</th>
<th>Pandas</th>
<th>PySpark</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:left">基本操作</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:left">创建DataFrame</td>
<td>pd.DataFrame()</td>
<td>SparkSession.createDataFrame()</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pd.read_sql()</td>
<td>SparkSession.sql()</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pd.read_csv()</td>
<td>SparkSession.read.json()</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>spark_df.toPandas()</td>
<td>SparkSession.createDataFrame(pandas_df)</td>
</tr>
<tr>
<td style="text-align:left">查看数据类型</td>
<td>pandas_df.dtypes</td>
<td>spark_df.dtypes</td>
</tr>
<tr>
<td style="text-align:left">统计</td>
<td>统计每一列或行的非空数目，pandas_df.count(), axis=0统计列(default)，axis=1统计行</td>
<td>统计总行数，spark_df.count()</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>统计学描述，pandas_df.describe()</td>
<td>统计学描述，spark_df.describe()</td>
</tr>
<tr>
<td style="text-align:left">列选取</td>
<td>pandas_df[‘col’]，返回Series</td>
<td>spark_df[‘col’]，返回Column</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pandas_df[[‘col1’, ‘col2’]]返回DataFrame</td>
<td>spark_df.select(‘col1’, ‘col2’)，返回DataFrame</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td></td>
<td>应用SQL函数并选取列，spark_df.selectExpr(‘col1 * 2’, ‘abs(col2)’)</td>
</tr>
<tr>
<td style="text-align:left">选取列并行简单运算</td>
<td>pandas_df[‘age’]+1</td>
<td>spark_df.select(spark_df[‘name’], spark_df[‘age’]+1)</td>
</tr>
<tr>
<td style="text-align:left">行选取</td>
<td>使用切片，pandas_df[:2]</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>使用bool数组，pandas_df[pandas_df[‘age’] &gt;20]</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>选取首/尾行，pandas_df.head(), pandas_df.tail()</td>
<td>选取首行，spark_df.head(), spark_df.take()</td>
</tr>
<tr>
<td style="text-align:left">选取多行多列</td>
<td>pandas_df.ix[:2, 0:2]</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">数据规整化</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:left">添加列</td>
<td>添加简单的列，pandas_df[‘new_col’]=1</td>
<td>添加简单的列，spark_df.withColumn(‘new_col’, functions.lit(1))，如果是新列名就是添加列，如果是旧列名就是替换列</td>
</tr>
<tr>
<td style="text-align:left">函数应用于列</td>
<td>使用函数处理某列，结果作为新的列，pandas_df[‘new_col’] = pandas_df[‘old_col’].apply(f)，也可以一次处理多列并添加多列，pandas_df[[‘new_col1’, ‘new_col2’]] = pandas_df[[‘old_col1’, ‘old_col2’]].apply(f)，可以使用lambda表达式定义f</td>
<td>使用函数处理某列，结果作为新的列，需要包装一下Python函数，udf_upper = F.udf(str.upper, StringType()), spark_df= spark_df.withColumn(‘upper_name’, udf_upper(spark_df[‘name’])</td>
</tr>
<tr>
<td style="text-align:left">应用函数于行</td>
<td>pandas_df.apply(f, axis=1)</td>
<td>spark_df.foreach(f)</td>
</tr>
<tr>
<td style="text-align:left">删除列</td>
<td>pandas_df.drop(‘col’, axis=1)</td>
<td>spark_df.drop(‘col’)，返回一个新的删除列的对象</td>
</tr>
<tr>
<td style="text-align:left">过滤</td>
<td>使用bool数组选取需要的行，pandas_df1 = pandas_df[pandas_df[‘age’] &gt; 20 &amp; pandas[‘age’] &lt; 22]</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>使用query()方法选取需要的行，pandas_df.query(‘age &gt; 20 &amp; age &lt; 22’)</td>
<td>使用where()方法选取需要的行，参数就是SQL的WHERE语句，filter()是where()的同名函数，spark_df.where(‘age &gt; 20 and age &lt; 22’)</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pandas_df.isin(values)，values可以是列表，词典和pandas.DataFrame对象</td>
<td>spark_df[‘col’].isin([‘Tom’, ‘Jack’])，返回一个Column</td>
</tr>
<tr>
<td style="text-align:left">排序</td>
<td>按照索引排序，pandas_df.sort_index()</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>按照某列排序，pandas_df.sort_values(by=’col’)，也可以按照多列排序，pandas_df.sort_values(by=[‘col1’, ‘col2’], ascending=[0, 1])，ascending默认为True</td>
<td>按照某列排序，spark_df.orderBy(‘col’)，也可以按照多列排序，spark_df.orderBy([‘col1’, ‘col2’], ascending=[0, 1])，ascending默认为True</td>
</tr>
<tr>
<td style="text-align:left">缺失值处理</td>
<td>检测缺失值，Series.isnull()</td>
<td>检测缺失值，spark_df.select(F.isnull(‘col1’).alias(‘r1’))</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>过滤缺失值，pandas_df.dropna()，默认滤除所有含有缺失值的行，传入how=’all’丢弃所有值为nan的行，传入axis=1，过滤列</td>
<td>过滤缺失值，spark_df.dropna()，默认滤除所有含有缺失值的行，传入how=’all’丢弃所有值为nan的行</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>填充缺失值，pandas_df.fillna(value)，将所有缺失值填充为value，可以传入一个字典，实现对不同的列填充不同的值，pandas_df.fillna({1: 0.5, 3: -1})，fillna()默认返回新对象，可以设置inplace参数</td>
<td>填充缺失值，spark_df.fillna(value)，将所有缺失值填充为value，可以传入一个字典，实现对不同的列填充不同的值，pandas_df.fillna({‘col1’: 0.5, ‘col3’: -1})</td>
</tr>
<tr>
<td style="text-align:left">拼接</td>
<td>在轴方向上拼接DataFrame，pd.concat([pandas_df1, pandas_df2])，可以通过ignore_index=True重置轴名称</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>在行方向上拼接DataFrame，pandas_df1.append(pandas_df2, ignore_index=True)，可以传入字典只添加一行，但是效率较低</td>
<td>在行方向上拼接DataFrame，spark_df1.union(spark_df2)，version 2.0之前是unionAll()</td>
</tr>
<tr>
<td style="text-align:left">联结</td>
<td>pandas_df1.merge(pandas_df2)，默认how=’inner’，默认按照同名列联结，可以明确指出联结列，也可以按照索引联结</td>
<td>spark_df1.join(spark_df2, ‘name’)，默认how=’inner’，联结条件可以是字符串或者Column表达式(列表)，如果是字符串，则两边的df必须有该列。使用字符串会合并联结列，使用Column表达式不会合并联结列。常常搭配select()使用。</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pandas_df1.join(pandas_df2)，始终按照pandas_df2的索引联结，pandas_df1可以指定联结列，不如pd.merge()好用</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">数据聚合和分组运算</td>
<td></td>
<td></td>
</tr>
<tr>
<td style="text-align:left">分组</td>
<td>pandas_df.groupby(pandas_df[‘key’])，常常会分组后选取特定列去分析，pandas_df.groupby([‘key1’, ‘key2’])[[‘data1’, ‘data2’]]，也可以根据字典，数组，Series和函数进行分组</td>
<td>spark_df.groupBy(‘key’)</td>
</tr>
<tr>
<td style="text-align:left">聚合</td>
<td>分组后的GroupBy对象可以直接调用mean(), count(), max(), min()等函数，也可以自定义聚合函数，通过agg()调用</td>
<td>分组后的GroupedData可以直接调用mean(), count()等函数，也可以通过agg()调用聚合函数作用于某列</td>
</tr>
<tr>
<td style="text-align:left">分组级运算</td>
<td>pandas_df.groupby(‘key’).transform(np.mean)，会将一个函数应用到各分组，如果各分组产生的是标量值，则该值就会被广播出去。该函数要求计算结果要么是标量值，要么是大小一样的向量。</td>
<td></td>
</tr>
<tr>
<td style="text-align:left"></td>
<td>pandas_df.groupby(‘key’).apply(f, arg1=arg1)，apply()是分组级运算的一般化函数，会将待处理的对象拆分成多个片段，然后对各个片段调用传入的函数，最后尝试将各个片段组合起来。</td>
<td></td>
</tr>
<tr>
<td style="text-align:left">其他</td>
<td></td>
<td>注册SQL函数sqlContext.registerFunction(“stringLengthString”, lambda x: len(x))</td>
</tr>
<tr>
<td style="text-align:left"></td>
<td></td>
<td>实现类似于hive中的row_number()功能，spark_df.withColumn(‘row_number’, F.row_number().over(Window.partitionBy([‘col1’, ‘col2’]).orderBy(F.desc(‘col3’))))</td>
</tr>
</tbody>
</table>
</div>
<p>有一些十分重要的操作在下面通过实例的方式进行说明。</p>
<h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><p>先导入一些需要的包，并做一些必要的初始化。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> pandas <span class="keyword">as</span> pd</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> pyspark <span class="keyword">import</span> SparkContext</span><br><span class="line"><span class="keyword">from</span> pyspark.sql <span class="keyword">import</span> HiveContext, Window</span><br><span class="line"><span class="keyword">import</span> pyspark.sql.functions <span class="keyword">as</span> F</span><br><span class="line"><span class="keyword">from</span> pyspark.sql.types <span class="keyword">import</span> StringType, IntegerType, BooleanType, StructType, StructField</span><br><span class="line"></span><br><span class="line">sc = SparkContext()</span><br><span class="line">sqlContext = HiveContext(sc)</span><br></pre></td></tr></table></figure></p>
<h4 id="创建DataFrame"><a href="#创建DataFrame" class="headerlink" title="创建DataFrame"></a>创建DataFrame</h4><h5 id="pandas"><a href="#pandas" class="headerlink" title="pandas"></a>pandas</h5><p>在pandas中创建DataFrame常见的方式是通过<code>.csv</code>文件读取，有时候为了测试程序写得是否正确，需要自己“造”一点数据，这种情况下一般通过字典来创建DataFrame。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过文件读取</span></span><br><span class="line">pandas_df = pd.read_csv(<span class="string">'data.csv'</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过字典创建</span></span><br><span class="line">data = &#123;<span class="string">'name'</span>:[<span class="string">'Jack'</span>, <span class="string">'Tom'</span>, <span class="string">'Alice'</span>], <span class="string">'age'</span>:[<span class="number">20</span>, <span class="number">23</span>, <span class="number">21</span>], <span class="string">'weight'</span>:[<span class="number">150</span>, <span class="number">180</span>, <span class="number">98</span>]&#125;</span><br><span class="line">pandas_df = pd.DataFrame(data=data, columns=[<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>], index=[<span class="string">'a'</span>, <span class="string">'b'</span>, <span class="string">'c'</span>])</span><br></pre></td></tr></table></figure></p>
<p>创建的DataFrame对象如下表所示。<br><img src="http://markdown.moverzp.com/18-3-18/19929362.jpg" alt></p>
<h5 id="pyspark"><a href="#pyspark" class="headerlink" title="pyspark"></a>pyspark</h5><p>在pyspark中创建DataFrame常见的方式是写SQL从Hive中读取数据，偶尔也会把RDD转为DataFrame，也可以自己“造”一点数据测试用。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 通过SQL查询语句创建</span></span><br><span class="line">spark_df = sqlContext.sql(<span class="string">"SELECT name, age, weight FROM people"</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过元素为tuple的list创建</span></span><br><span class="line">data = [(<span class="string">'Jack'</span>, <span class="number">20</span>, <span class="number">150</span>), (<span class="string">'Tom'</span>, <span class="number">23</span>, <span class="number">180</span>), (<span class="string">'Alice'</span>, <span class="number">21</span>, <span class="number">98</span>)]</span><br><span class="line">spark_df = sqlContext.createDataFrame(data, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 通过RDD创建</span></span><br><span class="line">rdd = sc.parallelize(data)</span><br><span class="line">spark_df = sqlContext.createDataFrame(rdd, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'weight'</span>])</span><br><span class="line"><span class="comment"># 明确指定schema的类型，不用去从data中推断</span></span><br><span class="line">schema = StructType([StructField(<span class="string">"name"</span>, StringType(), <span class="literal">True</span>), StructField(<span class="string">"age"</span>, IntegerType(), <span class="literal">True</span>), StructField(<span class="string">"weight"</span>, IntegerType(), <span class="literal">True</span>)])</span><br><span class="line">spark_df = sqlContext.createDataFrame(data=rdd, schema=schema)</span><br></pre></td></tr></table></figure></p>
<p>创建的DataFrame对象如下表所示，显而易见spark中的DataFrame中没有索引的概念。<br><img src="http://markdown.moverzp.com/18-3-18/96330612.jpg" alt></p>
<h4 id="函数应用于列"><a href="#函数应用于列" class="headerlink" title="函数应用于列"></a>函数应用于列</h4><p>数据处理的过程中，最常见的操作之一就是处理某列的数据，然后将结果作为新的一列添加到DataFrame对象中。下面就以计算name列的长度为例子演示，先定义一个处理函数，<code>get_name_length()</code>。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_name_length</span><span class="params">(name)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> len(name)</span><br></pre></td></tr></table></figure></p>
<h5 id="pandas-1"><a href="#pandas-1" class="headerlink" title="pandas"></a>pandas</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pandas_df[<span class="string">'name_length'</span>] = pandas_df[<span class="string">'name'</span>].apply(get_name_length)</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/92151214.jpg" alt></p>
<h5 id="pyspark-1"><a href="#pyspark-1" class="headerlink" title="pyspark"></a>pyspark</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">udf_get_name_length = F.udf(get_name_length, IntegerType())</span><br><span class="line">spark_df = spark_df.withColumn(<span class="string">'name_length'</span>, udf_get_name_length(spark_df[<span class="string">'name'</span>]))</span><br><span class="line">spark_df.show()</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/59604596.jpg" alt></p>
<h4 id="过滤"><a href="#过滤" class="headerlink" title="过滤"></a>过滤</h4><h5 id="pandas-2"><a href="#pandas-2" class="headerlink" title="pandas"></a>pandas</h5><p>在pandas中常见的过滤方式有两种，一种是使用bool数组过滤，一种是使用<code>query()</code>函数过滤。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">pandas_df[(pandas_df[<span class="string">'age'</span>] &gt; <span class="number">20</span>) &amp; (pandas_df[<span class="string">'age'</span>] &lt; <span class="number">22</span>)]</span><br><span class="line">pandas_df.query(<span class="string">'age &gt; 20 &amp; age &lt; 22'</span>)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://markdown.moverzp.com/18-3-18/17576071.jpg" alt></p>
<h5 id="pyspark-2"><a href="#pyspark-2" class="headerlink" title="pyspark"></a>pyspark</h5><p><code>where()</code>函数的参数和SQL一样，对大小写不敏感。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark_df.where(<span class="string">'age &gt; 20 and AGE &lt; 22'</span>).show()</span><br></pre></td></tr></table></figure></p>
<p><img src="http://markdown.moverzp.com/18-3-18/57788362.jpg" alt></p>
<h4 id="排序"><a href="#排序" class="headerlink" title="排序"></a>排序</h4><h5 id="pandas-3"><a href="#pandas-3" class="headerlink" title="pandas"></a>pandas</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">pandas_df.sort_values(by=<span class="string">'name'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/10476834.jpg" alt></p>
<h5 id="pyspark-3"><a href="#pyspark-3" class="headerlink" title="pyspark"></a>pyspark</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">spark_df.orderBy(<span class="string">'name'</span>).show()</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/95729731.jpg" alt></p>
<h4 id="拼接"><a href="#拼接" class="headerlink" title="拼接"></a>拼接</h4><p>拼接操作是把多个DataFrame对象在行或者列方向上连在一起。</p>
<h5 id="pandas-4"><a href="#pandas-4" class="headerlink" title="pandas"></a>pandas</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 先创建两个小的DataFrame对象</span></span><br><span class="line">data1 = &#123;<span class="string">'name'</span>:[<span class="string">'Jack'</span>, <span class="string">'Tom'</span>], <span class="string">'age'</span>:[<span class="number">20</span>, <span class="number">23</span>]&#125;</span><br><span class="line">pandas_df1 = pd.DataFrame(data1)</span><br><span class="line">data2 = &#123;<span class="string">'name'</span>:[<span class="string">'Alice'</span>], <span class="string">'age'</span>:[<span class="number">21</span>]&#125;</span><br><span class="line">pandas_df2 = pd.DataFrame(data2)</span><br><span class="line"></span><br><span class="line"><span class="comment"># 行拼接</span></span><br><span class="line">pandas_df_concat1 = pd.concat([pandas_df1, pandas_df2], axis=<span class="number">0</span>)</span><br><span class="line"><span class="comment"># 列拼接</span></span><br><span class="line">pandas_df_concat2 = pd.concat([pandas_df1, pandas_df2], axis=<span class="number">1</span>)</span><br></pre></td></tr></table></figure>
<p>行拼接结果如下表所示，根据列名拼接，索引并不会重置。<br><img src="http://markdown.moverzp.com/18-3-18/34950694.jpg" alt><br>列拼接结果如下表所示，根据索引拼接，拼接不上的填充为<code>NaN</code>。<br><img src="http://markdown.moverzp.com/18-3-18/92631852.jpg" alt></p>
<h5 id="pyspark-4"><a href="#pyspark-4" class="headerlink" title="pyspark"></a>pyspark</h5><p>pyspark如果想进行列拼接，可以通过联结实现。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data1 = [(<span class="string">'Jack'</span>, <span class="number">20</span>), (<span class="string">'Tom'</span>, <span class="number">23</span>)]</span><br><span class="line">spark_df1 = sqlContext.createDataFrame(data1, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>])</span><br><span class="line">data2 = [(<span class="string">'Alice'</span>, <span class="number">21</span>)]</span><br><span class="line">spark_df2 = sqlContext.createDataFrame(data2, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>])</span><br><span class="line"></span><br><span class="line">spark_df_union = spark_df1.union(spark_df2)</span><br></pre></td></tr></table></figure></p>
<p><img src="http://markdown.moverzp.com/18-3-18/62251280.jpg" alt></p>
<h4 id="联结"><a href="#联结" class="headerlink" title="联结"></a>联结</h4><p>联结就是SQL中的JOIN操作，同样也有内联结，左联结，右联结和外联结。本节实例是通过name联结上gender.</p>
<h5 id="pandas-5"><a href="#pandas-5" class="headerlink" title="pandas"></a>pandas</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data1 = &#123;<span class="string">'name'</span>:[<span class="string">'Jack'</span>, <span class="string">'Alice'</span>], <span class="string">'age'</span>:[<span class="number">20</span>, <span class="number">23</span>]&#125;</span><br><span class="line">pandas_df1 = pd.DataFrame(data1)</span><br><span class="line">data2 = &#123;<span class="string">'name'</span>:[<span class="string">'Jack'</span>, <span class="string">'Alice'</span>], <span class="string">'gender'</span>:[<span class="string">'male'</span>, <span class="string">'female'</span>]&#125;</span><br><span class="line">pandas_df2 = pd.DataFrame(data2)</span><br><span class="line"></span><br><span class="line">pandas_df_merged = pd.merge(pandas_df1, pandas_df2)</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/87526834.jpg" alt></p>
<h5 id="pyspark-5"><a href="#pyspark-5" class="headerlink" title="pyspark"></a>pyspark</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">data1 = [(<span class="string">'Jack'</span>, <span class="number">20</span>), (<span class="string">'Alice'</span>, <span class="number">23</span>)]</span><br><span class="line">spark_df1 = sqlContext.createDataFrame(data1, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>])</span><br><span class="line">data2 = [(<span class="string">'Jack'</span>, <span class="string">'male'</span>), (<span class="string">'Alice'</span>, <span class="string">'female'</span>)]</span><br><span class="line">spark_df2 = sqlContext.createDataFrame(data2, schema=[<span class="string">'name'</span>, <span class="string">'gender'</span>])</span><br><span class="line"></span><br><span class="line">spark_df_joined1 = spark_df1.join(spark_df2, <span class="string">'name'</span>)</span><br><span class="line">spark_df_joined2 = spark_df1.join(spark_df2, spark_df1.name==spark_df2.name)</span><br></pre></td></tr></table></figure>
<p>使用列名字符串联结的结果如下表所示，自动合并了联结的列。<br><img src="http://markdown.moverzp.com/18-3-18/60490940.jpg" alt><br>使用Column表达式联结的结果如下表所示，联结的列保留。<br><img src="http://markdown.moverzp.com/18-3-18/95283347.jpg" alt></p>
<h4 id="分组聚合"><a href="#分组聚合" class="headerlink" title="分组聚合"></a>分组聚合</h4><p>分组聚合就是根据某些条件，将一个DataFrame对象分成各个小组，然后在各个小组内进行一些运算，再将每个组运算的结果拼成一个新的DataFrame对象，常常用来求最值，求平均值，组内排序等。下面的例子是求每个性别的年龄平均值。</p>
<h5 id="pandas-6"><a href="#pandas-6" class="headerlink" title="pandas"></a>pandas</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = &#123;<span class="string">'name'</span>:[<span class="string">'Jack'</span>, <span class="string">'Tom'</span>, <span class="string">'Alice'</span>], <span class="string">'age'</span>:[<span class="number">20</span>, <span class="number">23</span>, <span class="number">21</span>], <span class="string">'gender'</span>:[<span class="string">'male'</span>, <span class="string">'male'</span>, <span class="string">'female'</span>]&#125;</span><br><span class="line">pandas_df = pd.DataFrame(data)</span><br><span class="line"></span><br><span class="line">mean_age = pandas_df.groupby(<span class="string">'gender'</span>)[<span class="string">'age'</span>].mean()</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/62030336.jpg" alt></p>
<h5 id="pyspark-6"><a href="#pyspark-6" class="headerlink" title="pyspark"></a>pyspark</h5><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">data = [(<span class="string">'Jack'</span>, <span class="number">20</span>, <span class="string">'male'</span>), (<span class="string">'Tom'</span>, <span class="number">23</span>, <span class="string">'male'</span>), (<span class="string">'Alice'</span>, <span class="number">21</span>, <span class="string">'female'</span>)]</span><br><span class="line">spark_df = sqlContext.createDataFrame(data, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'gender'</span>])</span><br><span class="line"></span><br><span class="line"><span class="comment"># 以下两种求均值结果一样</span></span><br><span class="line">spark_df.groupBy(<span class="string">'gender'</span>).agg(&#123;<span class="string">'age'</span>:<span class="string">'mean'</span>&#125;)</span><br><span class="line">spark_df.groupBy(<span class="string">'gender'</span>).mean(<span class="string">'age'</span>)</span><br></pre></td></tr></table></figure>
<p><img src="http://markdown.moverzp.com/18-3-18/51957176.jpg" alt></p>
<h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><h5 id="pyspark中实现类似于hive中的row-number"><a href="#pyspark中实现类似于hive中的row-number" class="headerlink" title="pyspark中实现类似于hive中的row_number()"></a>pyspark中实现类似于hive中的row_number()</h5><p>按照性别分组，然后根据name进行降序排序，组内顺序作为新的一列添加到DataFrame对象中。pandas中这种操作比较容易实现，就不展示了。<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">data = [(<span class="string">'Jack'</span>, <span class="number">20</span>, <span class="string">'male'</span>), (<span class="string">'Tom'</span>, <span class="number">23</span>, <span class="string">'male'</span>), (<span class="string">'Alice'</span>, <span class="number">21</span>, <span class="string">'female'</span>)]</span><br><span class="line">spark_df = sqlContext.createDataFrame(data, schema=[<span class="string">'name'</span>, <span class="string">'age'</span>, <span class="string">'gender'</span>])</span><br><span class="line"></span><br><span class="line">spark_df.withColumn(<span class="string">'row_number'</span>, F.row_number().over(Window.partitionBy([<span class="string">'gender'</span>]).orderBy(F.desc(<span class="string">'name'</span>)))).show()</span><br></pre></td></tr></table></figure></p>
<p><img src="http://markdown.moverzp.com/18-3-18/51648129.jpg" alt></p>
<h2 id="小结"><a href="#小结" class="headerlink" title="小结"></a>小结</h2><ul>
<li>pandas和spark中都有DataFrame类型，一般情况下互相都有类似的操作，都是结构化数据处理的利器</li>
<li>pandas常常用于单机，小数据集和demo的应用，一般情况下数据集只要能在单机的内存中放下，就可以使用pandas</li>
<li>spark适合离线大数据集分布式应用，凡是单机内存放不下的，或者计算时间过长的，最好都用spark</li>
<li>虽然pandas和spark的DataFrame操作基本一致，但是要牢记pandas是单机处理，spark是分布式处理，spark中有driver和executer的概念，因此有时候仿照pandas中DataFrame的处理代码，直接去写spark，结果可能会和预期的不符</li>
</ul>

      

      
    </div>
    <div class="article-info article-info-index">
      
      
	<div class="article-tag tagcloud">
		<i class="icon-price-tags icon"></i>
		<ul class="article-tag-list">
			 
        		<li class="article-tag-list-item">
        			<a href="javascript:void(0)" class="js-tag article-tag-list-link color5">数据清洗</a>
        		</li>
      		
		</ul>
	</div>

      

      
        <p class="article-more-link">
          <a class="article-more-a" href="/2018/03/17/Pandas和PySpark中的DataFrame比较/">展开全文 >></a>
        </p>
      

      
      <div class="clearfix"></div>
    </div>
  </div>
</article>

<aside class="wrap-side-operation">
    <div class="mod-side-operation">
        
        <div class="jump-container" id="js-jump-container" style="display:none;">
            <a href="javascript:void(0)" class="mod-side-operation__jump-to-top">
                <i class="icon-font icon-back"></i>
            </a>
            <div id="js-jump-plan-container" class="jump-plan-container" style="top: -11px;">
                <i class="icon-font icon-plane jump-plane"></i>
            </div>
        </div>
        
        
    </div>
</aside>




  
  
    <nav id="page-nav">
      <span class="page-number current">1</span><a class="page-number" href="/page/2/">2</a><a class="extend next" rel="next" href="/page/2/">Next &raquo;</a>
    </nav>
  


          </div>
        </div>
      </div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2019 moverzp
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    <script>
	var yiliaConfig = {
		mathjax: true,
		isHome: true,
		isPost: false,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: true,
		toc_hide_index: true,
		root: "/",
		innerArchive: false,
		showTags: true
	}
</script>

<script>!function(t){function n(e){if(r[e])return r[e].exports;var i=r[e]={exports:{},id:e,loaded:!1};return t[e].call(i.exports,i,i.exports,n),i.loaded=!0,i.exports}var r={};n.m=t,n.c=r,n.p="./",n(0)}([function(t,n,r){r(195),t.exports=r(191)},function(t,n,r){var e=r(3),i=r(52),o=r(27),u=r(28),c=r(53),f="prototype",a=function(t,n,r){var s,l,h,v,p=t&a.F,d=t&a.G,y=t&a.S,g=t&a.P,b=t&a.B,m=d?e:y?e[n]||(e[n]={}):(e[n]||{})[f],x=d?i:i[n]||(i[n]={}),w=x[f]||(x[f]={});d&&(r=n);for(s in r)l=!p&&m&&void 0!==m[s],h=(l?m:r)[s],v=b&&l?c(h,e):g&&"function"==typeof h?c(Function.call,h):h,m&&u(m,s,h,t&a.U),x[s]!=h&&o(x,s,v),g&&w[s]!=h&&(w[s]=h)};e.core=i,a.F=1,a.G=2,a.S=4,a.P=8,a.B=16,a.W=32,a.U=64,a.R=128,t.exports=a},function(t,n,r){var e=r(6);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n){var r=t.exports="undefined"!=typeof window&&window.Math==Math?window:"undefined"!=typeof self&&self.Math==Math?self:Function("return this")();"number"==typeof __g&&(__g=r)},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n,r){var e=r(126)("wks"),i=r(76),o=r(3).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n,r){var e=r(94),i=r(33);t.exports=function(t){return e(i(t))}},function(t,n,r){t.exports=!r(4)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(2),i=r(167),o=r(50),u=Object.defineProperty;n.f=r(10)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){t.exports=!r(18)(function(){return 7!=Object.defineProperty({},"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(14),i=r(22);t.exports=r(12)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(20),i=r(58),o=r(42),u=Object.defineProperty;n.f=r(12)?Object.defineProperty:function(t,n,r){if(e(t),n=o(n,!0),e(r),i)try{return u(t,n,r)}catch(t){}if("get"in r||"set"in r)throw TypeError("Accessors not supported!");return"value"in r&&(t[n]=r.value),t}},function(t,n,r){var e=r(40)("wks"),i=r(23),o=r(5).Symbol,u="function"==typeof o;(t.exports=function(t){return e[t]||(e[t]=u&&o[t]||(u?o:i)("Symbol."+t))}).store=e},function(t,n,r){var e=r(67),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){var e=r(46);t.exports=function(t){return Object(e(t))}},function(t,n){t.exports=function(t){try{return!!t()}catch(t){return!0}}},function(t,n,r){var e=r(63),i=r(34);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(21);t.exports=function(t){if(!e(t))throw TypeError(t+" is not an object!");return t}},function(t,n){t.exports=function(t){return"object"==typeof t?null!==t:"function"==typeof t}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n){var r={}.hasOwnProperty;t.exports=function(t,n){return r.call(t,n)}},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n,r){var e=r(11),i=r(66);t.exports=r(10)?function(t,n,r){return e.f(t,n,i(1,r))}:function(t,n,r){return t[n]=r,t}},function(t,n,r){var e=r(3),i=r(27),o=r(24),u=r(76)("src"),c="toString",f=Function[c],a=(""+f).split(c);r(52).inspectSource=function(t){return f.call(t)},(t.exports=function(t,n,r,c){var f="function"==typeof r;f&&(o(r,"name")||i(r,"name",n)),t[n]!==r&&(f&&(o(r,u)||i(r,u,t[n]?""+t[n]:a.join(String(n)))),t===e?t[n]=r:c?t[n]?t[n]=r:i(t,n,r):(delete t[n],i(t,n,r)))})(Function.prototype,c,function(){return"function"==typeof this&&this[u]||f.call(this)})},function(t,n,r){var e=r(1),i=r(4),o=r(46),u=function(t,n,r,e){var i=String(o(t)),u="<"+n;return""!==r&&(u+=" "+r+'="'+String(e).replace(/"/g,"&quot;")+'"'),u+">"+i+"</"+n+">"};t.exports=function(t,n){var r={};r[t]=n(u),e(e.P+e.F*i(function(){var n=""[t]('"');return n!==n.toLowerCase()||n.split('"').length>3}),"String",r)}},function(t,n,r){var e=r(115),i=r(46);t.exports=function(t){return e(i(t))}},function(t,n,r){var e=r(116),i=r(66),o=r(30),u=r(50),c=r(24),f=r(167),a=Object.getOwnPropertyDescriptor;n.f=r(10)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(24),i=r(17),o=r(145)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n){t.exports={}},function(t,n){t.exports=!0},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(14).f,i=r(8),o=r(15)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(40)("keys"),i=r(23);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(5),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n,r){var e=r(21);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(36),u=r(44),c=r(14).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){n.f=r(15)},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n){t.exports=function(t){if(void 0==t)throw TypeError("Can't call method on  "+t);return t}},function(t,n,r){var e=r(4);t.exports=function(t,n){return!!t&&e(function(){n?t.call(null,function(){},1):t.call(null)})}},function(t,n,r){var e=r(53),i=r(115),o=r(17),u=r(16),c=r(203);t.exports=function(t,n){var r=1==t,f=2==t,a=3==t,s=4==t,l=6==t,h=5==t||l,v=n||c;return function(n,c,p){for(var d,y,g=o(n),b=i(g),m=e(c,p,3),x=u(b.length),w=0,S=r?v(n,x):f?v(n,0):void 0;x>w;w++)if((h||w in b)&&(d=b[w],y=m(d,w,g),t))if(r)S[w]=y;else if(y)switch(t){case 3:return!0;case 5:return d;case 6:return w;case 2:S.push(d)}else if(s)return!1;return l?-1:a||s?s:S}}},function(t,n,r){var e=r(1),i=r(52),o=r(4);t.exports=function(t,n){var r=(i.Object||{})[t]||Object[t],u={};u[t]=n(r),e(e.S+e.F*o(function(){r(1)}),"Object",u)}},function(t,n,r){var e=r(6);t.exports=function(t,n){if(!e(t))return t;var r,i;if(n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;if("function"==typeof(r=t.valueOf)&&!e(i=r.call(t)))return i;if(!n&&"function"==typeof(r=t.toString)&&!e(i=r.call(t)))return i;throw TypeError("Can't convert object to primitive value")}},function(t,n,r){var e=r(5),i=r(25),o=r(91),u=r(13),c="prototype",f=function(t,n,r){var a,s,l,h=t&f.F,v=t&f.G,p=t&f.S,d=t&f.P,y=t&f.B,g=t&f.W,b=v?i:i[n]||(i[n]={}),m=b[c],x=v?e:p?e[n]:(e[n]||{})[c];v&&(r=n);for(a in r)(s=!h&&x&&void 0!==x[a])&&a in b||(l=s?x[a]:r[a],b[a]=v&&"function"!=typeof x[a]?r[a]:y&&s?o(l,e):g&&x[a]==l?function(t){var n=function(n,r,e){if(this instanceof t){switch(arguments.length){case 0:return new t;case 1:return new t(n);case 2:return new t(n,r)}return new t(n,r,e)}return t.apply(this,arguments)};return n[c]=t[c],n}(l):d&&"function"==typeof l?o(Function.call,l):l,d&&((b.virtual||(b.virtual={}))[a]=l,t&f.R&&m&&!m[a]&&u(m,a,l)))};f.F=1,f.G=2,f.S=4,f.P=8,f.B=16,f.W=32,f.U=64,f.R=128,t.exports=f},function(t,n){var r=t.exports={version:"2.4.0"};"number"==typeof __e&&(__e=r)},function(t,n,r){var e=r(26);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(183),i=r(1),o=r(126)("metadata"),u=o.store||(o.store=new(r(186))),c=function(t,n,r){var i=u.get(t);if(!i){if(!r)return;u.set(t,i=new e)}var o=i.get(n);if(!o){if(!r)return;i.set(n,o=new e)}return o},f=function(t,n,r){var e=c(n,r,!1);return void 0!==e&&e.has(t)},a=function(t,n,r){var e=c(n,r,!1);return void 0===e?void 0:e.get(t)},s=function(t,n,r,e){c(r,e,!0).set(t,n)},l=function(t,n){var r=c(t,n,!1),e=[];return r&&r.forEach(function(t,n){e.push(n)}),e},h=function(t){return void 0===t||"symbol"==typeof t?t:String(t)},v=function(t){i(i.S,"Reflect",t)};t.exports={store:u,map:c,has:f,get:a,set:s,keys:l,key:h,exp:v}},function(t,n,r){"use strict";if(r(10)){var e=r(69),i=r(3),o=r(4),u=r(1),c=r(127),f=r(152),a=r(53),s=r(68),l=r(66),h=r(27),v=r(73),p=r(67),d=r(16),y=r(75),g=r(50),b=r(24),m=r(180),x=r(114),w=r(6),S=r(17),_=r(137),O=r(70),E=r(32),P=r(71).f,j=r(154),F=r(76),M=r(7),A=r(48),N=r(117),T=r(146),I=r(155),k=r(80),L=r(123),R=r(74),C=r(130),D=r(160),U=r(11),W=r(31),G=U.f,B=W.f,V=i.RangeError,z=i.TypeError,q=i.Uint8Array,K="ArrayBuffer",J="Shared"+K,Y="BYTES_PER_ELEMENT",H="prototype",$=Array[H],X=f.ArrayBuffer,Q=f.DataView,Z=A(0),tt=A(2),nt=A(3),rt=A(4),et=A(5),it=A(6),ot=N(!0),ut=N(!1),ct=I.values,ft=I.keys,at=I.entries,st=$.lastIndexOf,lt=$.reduce,ht=$.reduceRight,vt=$.join,pt=$.sort,dt=$.slice,yt=$.toString,gt=$.toLocaleString,bt=M("iterator"),mt=M("toStringTag"),xt=F("typed_constructor"),wt=F("def_constructor"),St=c.CONSTR,_t=c.TYPED,Ot=c.VIEW,Et="Wrong length!",Pt=A(1,function(t,n){return Tt(T(t,t[wt]),n)}),jt=o(function(){return 1===new q(new Uint16Array([1]).buffer)[0]}),Ft=!!q&&!!q[H].set&&o(function(){new q(1).set({})}),Mt=function(t,n){if(void 0===t)throw z(Et);var r=+t,e=d(t);if(n&&!m(r,e))throw V(Et);return e},At=function(t,n){var r=p(t);if(r<0||r%n)throw V("Wrong offset!");return r},Nt=function(t){if(w(t)&&_t in t)return t;throw z(t+" is not a typed array!")},Tt=function(t,n){if(!(w(t)&&xt in t))throw z("It is not a typed array constructor!");return new t(n)},It=function(t,n){return kt(T(t,t[wt]),n)},kt=function(t,n){for(var r=0,e=n.length,i=Tt(t,e);e>r;)i[r]=n[r++];return i},Lt=function(t,n,r){G(t,n,{get:function(){return this._d[r]}})},Rt=function(t){var n,r,e,i,o,u,c=S(t),f=arguments.length,s=f>1?arguments[1]:void 0,l=void 0!==s,h=j(c);if(void 0!=h&&!_(h)){for(u=h.call(c),e=[],n=0;!(o=u.next()).done;n++)e.push(o.value);c=e}for(l&&f>2&&(s=a(s,arguments[2],2)),n=0,r=d(c.length),i=Tt(this,r);r>n;n++)i[n]=l?s(c[n],n):c[n];return i},Ct=function(){for(var t=0,n=arguments.length,r=Tt(this,n);n>t;)r[t]=arguments[t++];return r},Dt=!!q&&o(function(){gt.call(new q(1))}),Ut=function(){return gt.apply(Dt?dt.call(Nt(this)):Nt(this),arguments)},Wt={copyWithin:function(t,n){return D.call(Nt(this),t,n,arguments.length>2?arguments[2]:void 0)},every:function(t){return rt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},fill:function(t){return C.apply(Nt(this),arguments)},filter:function(t){return It(this,tt(Nt(this),t,arguments.length>1?arguments[1]:void 0))},find:function(t){return et(Nt(this),t,arguments.length>1?arguments[1]:void 0)},findIndex:function(t){return it(Nt(this),t,arguments.length>1?arguments[1]:void 0)},forEach:function(t){Z(Nt(this),t,arguments.length>1?arguments[1]:void 0)},indexOf:function(t){return ut(Nt(this),t,arguments.length>1?arguments[1]:void 0)},includes:function(t){return ot(Nt(this),t,arguments.length>1?arguments[1]:void 0)},join:function(t){return vt.apply(Nt(this),arguments)},lastIndexOf:function(t){return st.apply(Nt(this),arguments)},map:function(t){return Pt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},reduce:function(t){return lt.apply(Nt(this),arguments)},reduceRight:function(t){return ht.apply(Nt(this),arguments)},reverse:function(){for(var t,n=this,r=Nt(n).length,e=Math.floor(r/2),i=0;i<e;)t=n[i],n[i++]=n[--r],n[r]=t;return n},some:function(t){return nt(Nt(this),t,arguments.length>1?arguments[1]:void 0)},sort:function(t){return pt.call(Nt(this),t)},subarray:function(t,n){var r=Nt(this),e=r.length,i=y(t,e);return new(T(r,r[wt]))(r.buffer,r.byteOffset+i*r.BYTES_PER_ELEMENT,d((void 0===n?e:y(n,e))-i))}},Gt=function(t,n){return It(this,dt.call(Nt(this),t,n))},Bt=function(t){Nt(this);var n=At(arguments[1],1),r=this.length,e=S(t),i=d(e.length),o=0;if(i+n>r)throw V(Et);for(;o<i;)this[n+o]=e[o++]},Vt={entries:function(){return at.call(Nt(this))},keys:function(){return ft.call(Nt(this))},values:function(){return ct.call(Nt(this))}},zt=function(t,n){return w(t)&&t[_t]&&"symbol"!=typeof n&&n in t&&String(+n)==String(n)},qt=function(t,n){return zt(t,n=g(n,!0))?l(2,t[n]):B(t,n)},Kt=function(t,n,r){return!(zt(t,n=g(n,!0))&&w(r)&&b(r,"value"))||b(r,"get")||b(r,"set")||r.configurable||b(r,"writable")&&!r.writable||b(r,"enumerable")&&!r.enumerable?G(t,n,r):(t[n]=r.value,t)};St||(W.f=qt,U.f=Kt),u(u.S+u.F*!St,"Object",{getOwnPropertyDescriptor:qt,defineProperty:Kt}),o(function(){yt.call({})})&&(yt=gt=function(){return vt.call(this)});var Jt=v({},Wt);v(Jt,Vt),h(Jt,bt,Vt.values),v(Jt,{slice:Gt,set:Bt,constructor:function(){},toString:yt,toLocaleString:Ut}),Lt(Jt,"buffer","b"),Lt(Jt,"byteOffset","o"),Lt(Jt,"byteLength","l"),Lt(Jt,"length","e"),G(Jt,mt,{get:function(){return this[_t]}}),t.exports=function(t,n,r,f){f=!!f;var a=t+(f?"Clamped":"")+"Array",l="Uint8Array"!=a,v="get"+t,p="set"+t,y=i[a],g=y||{},b=y&&E(y),m=!y||!c.ABV,S={},_=y&&y[H],j=function(t,r){var e=t._d;return e.v[v](r*n+e.o,jt)},F=function(t,r,e){var i=t._d;f&&(e=(e=Math.round(e))<0?0:e>255?255:255&e),i.v[p](r*n+i.o,e,jt)},M=function(t,n){G(t,n,{get:function(){return j(this,n)},set:function(t){return F(this,n,t)},enumerable:!0})};m?(y=r(function(t,r,e,i){s(t,y,a,"_d");var o,u,c,f,l=0,v=0;if(w(r)){if(!(r instanceof X||(f=x(r))==K||f==J))return _t in r?kt(y,r):Rt.call(y,r);o=r,v=At(e,n);var p=r.byteLength;if(void 0===i){if(p%n)throw V(Et);if((u=p-v)<0)throw V(Et)}else if((u=d(i)*n)+v>p)throw V(Et);c=u/n}else c=Mt(r,!0),u=c*n,o=new X(u);for(h(t,"_d",{b:o,o:v,l:u,e:c,v:new Q(o)});l<c;)M(t,l++)}),_=y[H]=O(Jt),h(_,"constructor",y)):L(function(t){new y(null),new y(t)},!0)||(y=r(function(t,r,e,i){s(t,y,a);var o;return w(r)?r instanceof X||(o=x(r))==K||o==J?void 0!==i?new g(r,At(e,n),i):void 0!==e?new g(r,At(e,n)):new g(r):_t in r?kt(y,r):Rt.call(y,r):new g(Mt(r,l))}),Z(b!==Function.prototype?P(g).concat(P(b)):P(g),function(t){t in y||h(y,t,g[t])}),y[H]=_,e||(_.constructor=y));var A=_[bt],N=!!A&&("values"==A.name||void 0==A.name),T=Vt.values;h(y,xt,!0),h(_,_t,a),h(_,Ot,!0),h(_,wt,y),(f?new y(1)[mt]==a:mt in _)||G(_,mt,{get:function(){return a}}),S[a]=y,u(u.G+u.W+u.F*(y!=g),S),u(u.S,a,{BYTES_PER_ELEMENT:n,from:Rt,of:Ct}),Y in _||h(_,Y,n),u(u.P,a,Wt),R(a),u(u.P+u.F*Ft,a,{set:Bt}),u(u.P+u.F*!N,a,Vt),u(u.P+u.F*(_.toString!=yt),a,{toString:yt}),u(u.P+u.F*o(function(){new y(1).slice()}),a,{slice:Gt}),u(u.P+u.F*(o(function(){return[1,2].toLocaleString()!=new y([1,2]).toLocaleString()})||!o(function(){_.toLocaleString.call([1,2])})),a,{toLocaleString:Ut}),k[a]=N?A:T,e||N||h(_,bt,T)}}else t.exports=function(){}},function(t,n){var r={}.toString;t.exports=function(t){return r.call(t).slice(8,-1)}},function(t,n,r){var e=r(21),i=r(5).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n,r){t.exports=!r(12)&&!r(18)(function(){return 7!=Object.defineProperty(r(57)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){"use strict";var e=r(36),i=r(51),o=r(64),u=r(13),c=r(8),f=r(35),a=r(96),s=r(38),l=r(103),h=r(15)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n,r){var e=r(20),i=r(100),o=r(34),u=r(39)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(57)("iframe"),e=o.length;for(n.style.display="none",r(93).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(63),i=r(34).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(8),i=r(9),o=r(90)(!1),u=r(39)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){t.exports=r(13)},function(t,n,r){var e=r(76)("meta"),i=r(6),o=r(24),u=r(11).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(4)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n){t.exports=function(t,n){return{enumerable:!(1&t),configurable:!(2&t),writable:!(4&t),value:n}}},function(t,n){var r=Math.ceil,e=Math.floor;t.exports=function(t){return isNaN(t=+t)?0:(t>0?e:r)(t)}},function(t,n){t.exports=function(t,n,r,e){if(!(t instanceof n)||void 0!==e&&e in t)throw TypeError(r+": incorrect invocation!");return t}},function(t,n){t.exports=!1},function(t,n,r){var e=r(2),i=r(173),o=r(133),u=r(145)("IE_PROTO"),c=function(){},f="prototype",a=function(){var t,n=r(132)("iframe"),e=o.length;for(n.style.display="none",r(135).appendChild(n),n.src="javascript:",t=n.contentWindow.document,t.open(),t.write("<script>document.F=Object<\/script>"),t.close(),a=t.F;e--;)delete a[f][o[e]];return a()};t.exports=Object.create||function(t,n){var r;return null!==t?(c[f]=e(t),r=new c,c[f]=null,r[u]=t):r=a(),void 0===n?r:i(r,n)}},function(t,n,r){var e=r(175),i=r(133).concat("length","prototype");n.f=Object.getOwnPropertyNames||function(t){return e(t,i)}},function(t,n,r){var e=r(175),i=r(133);t.exports=Object.keys||function(t){return e(t,i)}},function(t,n,r){var e=r(28);t.exports=function(t,n,r){for(var i in n)e(t,i,n[i],r);return t}},function(t,n,r){"use strict";var e=r(3),i=r(11),o=r(10),u=r(7)("species");t.exports=function(t){var n=e[t];o&&n&&!n[u]&&i.f(n,u,{configurable:!0,get:function(){return this}})}},function(t,n,r){var e=r(67),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n){var r=0,e=Math.random();t.exports=function(t){return"Symbol(".concat(void 0===t?"":t,")_",(++r+e).toString(36))}},function(t,n,r){var e=r(33);t.exports=function(t){return Object(e(t))}},function(t,n,r){var e=r(7)("unscopables"),i=Array.prototype;void 0==i[e]&&r(27)(i,e,{}),t.exports=function(t){i[e][t]=!0}},function(t,n,r){var e=r(53),i=r(169),o=r(137),u=r(2),c=r(16),f=r(154),a={},s={},n=t.exports=function(t,n,r,l,h){var v,p,d,y,g=h?function(){return t}:f(t),b=e(r,l,n?2:1),m=0;if("function"!=typeof g)throw TypeError(t+" is not iterable!");if(o(g)){for(v=c(t.length);v>m;m++)if((y=n?b(u(p=t[m])[0],p[1]):b(t[m]))===a||y===s)return y}else for(d=g.call(t);!(p=d.next()).done;)if((y=i(d,b,p.value,n))===a||y===s)return y};n.BREAK=a,n.RETURN=s},function(t,n){t.exports={}},function(t,n,r){var e=r(11).f,i=r(24),o=r(7)("toStringTag");t.exports=function(t,n,r){t&&!i(t=r?t:t.prototype,o)&&e(t,o,{configurable:!0,value:n})}},function(t,n,r){var e=r(1),i=r(46),o=r(4),u=r(150),c="["+u+"]",f="​",a=RegExp("^"+c+c+"*"),s=RegExp(c+c+"*$"),l=function(t,n,r){var i={},c=o(function(){return!!u[t]()||f[t]()!=f}),a=i[t]=c?n(h):u[t];r&&(i[r]=a),e(e.P+e.F*c,"String",i)},h=l.trim=function(t,n){return t=String(i(t)),1&n&&(t=t.replace(a,"")),2&n&&(t=t.replace(s,"")),t};t.exports=l},function(t,n,r){t.exports={default:r(86),__esModule:!0}},function(t,n,r){t.exports={default:r(87),__esModule:!0}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}n.__esModule=!0;var i=r(84),o=e(i),u=r(83),c=e(u),f="function"==typeof c.default&&"symbol"==typeof o.default?function(t){return typeof t}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":typeof t};n.default="function"==typeof c.default&&"symbol"===f(o.default)?function(t){return void 0===t?"undefined":f(t)}:function(t){return t&&"function"==typeof c.default&&t.constructor===c.default&&t!==c.default.prototype?"symbol":void 0===t?"undefined":f(t)}},function(t,n,r){r(110),r(108),r(111),r(112),t.exports=r(25).Symbol},function(t,n,r){r(109),r(113),t.exports=r(44).f("iterator")},function(t,n){t.exports=function(t){if("function"!=typeof t)throw TypeError(t+" is not a function!");return t}},function(t,n){t.exports=function(){}},function(t,n,r){var e=r(9),i=r(106),o=r(105);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){var e=r(88);t.exports=function(t,n,r){if(e(t),void 0===n)return t;switch(r){case 1:return function(r){return t.call(n,r)};case 2:return function(r,e){return t.call(n,r,e)};case 3:return function(r,e,i){return t.call(n,r,e,i)}}return function(){return t.apply(n,arguments)}}},function(t,n,r){var e=r(19),i=r(62),o=r(37);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){t.exports=r(5).document&&document.documentElement},function(t,n,r){var e=r(56);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n,r){var e=r(56);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(60),i=r(22),o=r(38),u={};r(13)(u,r(15)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n,r){var e=r(19),i=r(9);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){var e=r(23)("meta"),i=r(21),o=r(8),u=r(14).f,c=0,f=Object.isExtensible||function(){return!0},a=!r(18)(function(){return f(Object.preventExtensions({}))}),s=function(t){u(t,e,{value:{i:"O"+ ++c,w:{}}})},l=function(t,n){if(!i(t))return"symbol"==typeof t?t:("string"==typeof t?"S":"P")+t;if(!o(t,e)){if(!f(t))return"F";if(!n)return"E";s(t)}return t[e].i},h=function(t,n){if(!o(t,e)){if(!f(t))return!0;if(!n)return!1;s(t)}return t[e].w},v=function(t){return a&&p.NEED&&f(t)&&!o(t,e)&&s(t),t},p=t.exports={KEY:e,NEED:!1,fastKey:l,getWeak:h,onFreeze:v}},function(t,n,r){var e=r(14),i=r(20),o=r(19);t.exports=r(12)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(37),i=r(22),o=r(9),u=r(42),c=r(8),f=r(58),a=Object.getOwnPropertyDescriptor;n.f=r(12)?a:function(t,n){if(t=o(t),n=u(n,!0),f)try{return a(t,n)}catch(t){}if(c(t,n))return i(!e.f.call(t,n),t[n])}},function(t,n,r){var e=r(9),i=r(61).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(8),i=r(77),o=r(39)("IE_PROTO"),u=Object.prototype;t.exports=Object.getPrototypeOf||function(t){return t=i(t),e(t,o)?t[o]:"function"==typeof t.constructor&&t instanceof t.constructor?t.constructor.prototype:t instanceof Object?u:null}},function(t,n,r){var e=r(41),i=r(33);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(41),i=Math.max,o=Math.min;t.exports=function(t,n){return t=e(t),t<0?i(t+n,0):o(t,n)}},function(t,n,r){var e=r(41),i=Math.min;t.exports=function(t){return t>0?i(e(t),9007199254740991):0}},function(t,n,r){"use strict";var e=r(89),i=r(97),o=r(35),u=r(9);t.exports=r(59)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){},function(t,n,r){"use strict";var e=r(104)(!0);r(59)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";var e=r(5),i=r(8),o=r(12),u=r(51),c=r(64),f=r(99).KEY,a=r(18),s=r(40),l=r(38),h=r(23),v=r(15),p=r(44),d=r(43),y=r(98),g=r(92),b=r(95),m=r(20),x=r(9),w=r(42),S=r(22),_=r(60),O=r(102),E=r(101),P=r(14),j=r(19),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(61).f=O.f=Z,r(37).f=X,r(62).f=tt,o&&!r(36)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(13)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){r(43)("asyncIterator")},function(t,n,r){r(43)("observable")},function(t,n,r){r(107);for(var e=r(5),i=r(13),o=r(35),u=r(15)("toStringTag"),c=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],f=0;f<5;f++){var a=c[f],s=e[a],l=s&&s.prototype;l&&!l[u]&&i(l,u,a),o[a]=o.Array}},function(t,n,r){var e=r(45),i=r(7)("toStringTag"),o="Arguments"==e(function(){return arguments}()),u=function(t,n){try{return t[n]}catch(t){}};t.exports=function(t){var n,r,c;return void 0===t?"Undefined":null===t?"Null":"string"==typeof(r=u(n=Object(t),i))?r:o?e(n):"Object"==(c=e(n))&&"function"==typeof n.callee?"Arguments":c}},function(t,n,r){var e=r(45);t.exports=Object("z").propertyIsEnumerable(0)?Object:function(t){return"String"==e(t)?t.split(""):Object(t)}},function(t,n){n.f={}.propertyIsEnumerable},function(t,n,r){var e=r(30),i=r(16),o=r(75);t.exports=function(t){return function(n,r,u){var c,f=e(n),a=i(f.length),s=o(u,a);if(t&&r!=r){for(;a>s;)if((c=f[s++])!=c)return!0}else for(;a>s;s++)if((t||s in f)&&f[s]===r)return t||s||0;return!t&&-1}}},function(t,n,r){"use strict";var e=r(3),i=r(1),o=r(28),u=r(73),c=r(65),f=r(79),a=r(68),s=r(6),l=r(4),h=r(123),v=r(81),p=r(136);t.exports=function(t,n,r,d,y,g){var b=e[t],m=b,x=y?"set":"add",w=m&&m.prototype,S={},_=function(t){var n=w[t];o(w,t,"delete"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"has"==t?function(t){return!(g&&!s(t))&&n.call(this,0===t?0:t)}:"get"==t?function(t){return g&&!s(t)?void 0:n.call(this,0===t?0:t)}:"add"==t?function(t){return n.call(this,0===t?0:t),this}:function(t,r){return n.call(this,0===t?0:t,r),this})};if("function"==typeof m&&(g||w.forEach&&!l(function(){(new m).entries().next()}))){var O=new m,E=O[x](g?{}:-0,1)!=O,P=l(function(){O.has(1)}),j=h(function(t){new m(t)}),F=!g&&l(function(){for(var t=new m,n=5;n--;)t[x](n,n);return!t.has(-0)});j||(m=n(function(n,r){a(n,m,t);var e=p(new b,n,m);return void 0!=r&&f(r,y,e[x],e),e}),m.prototype=w,w.constructor=m),(P||F)&&(_("delete"),_("has"),y&&_("get")),(F||E)&&_(x),g&&w.clear&&delete w.clear}else m=d.getConstructor(n,t,y,x),u(m.prototype,r),c.NEED=!0;return v(m,t),S[t]=m,i(i.G+i.W+i.F*(m!=b),S),g||d.setStrong(m,t,y),m}},function(t,n,r){"use strict";var e=r(27),i=r(28),o=r(4),u=r(46),c=r(7);t.exports=function(t,n,r){var f=c(t),a=r(u,f,""[t]),s=a[0],l=a[1];o(function(){var n={};return n[f]=function(){return 7},7!=""[t](n)})&&(i(String.prototype,t,s),e(RegExp.prototype,f,2==n?function(t,n){return l.call(t,this,n)}:function(t){return l.call(t,this)}))}
},function(t,n,r){"use strict";var e=r(2);t.exports=function(){var t=e(this),n="";return t.global&&(n+="g"),t.ignoreCase&&(n+="i"),t.multiline&&(n+="m"),t.unicode&&(n+="u"),t.sticky&&(n+="y"),n}},function(t,n){t.exports=function(t,n,r){var e=void 0===r;switch(n.length){case 0:return e?t():t.call(r);case 1:return e?t(n[0]):t.call(r,n[0]);case 2:return e?t(n[0],n[1]):t.call(r,n[0],n[1]);case 3:return e?t(n[0],n[1],n[2]):t.call(r,n[0],n[1],n[2]);case 4:return e?t(n[0],n[1],n[2],n[3]):t.call(r,n[0],n[1],n[2],n[3])}return t.apply(r,n)}},function(t,n,r){var e=r(6),i=r(45),o=r(7)("match");t.exports=function(t){var n;return e(t)&&(void 0!==(n=t[o])?!!n:"RegExp"==i(t))}},function(t,n,r){var e=r(7)("iterator"),i=!1;try{var o=[7][e]();o.return=function(){i=!0},Array.from(o,function(){throw 2})}catch(t){}t.exports=function(t,n){if(!n&&!i)return!1;var r=!1;try{var o=[7],u=o[e]();u.next=function(){return{done:r=!0}},o[e]=function(){return u},t(o)}catch(t){}return r}},function(t,n,r){t.exports=r(69)||!r(4)(function(){var t=Math.random();__defineSetter__.call(null,t,function(){}),delete r(3)[t]})},function(t,n){n.f=Object.getOwnPropertySymbols},function(t,n,r){var e=r(3),i="__core-js_shared__",o=e[i]||(e[i]={});t.exports=function(t){return o[t]||(o[t]={})}},function(t,n,r){for(var e,i=r(3),o=r(27),u=r(76),c=u("typed_array"),f=u("view"),a=!(!i.ArrayBuffer||!i.DataView),s=a,l=0,h="Int8Array,Uint8Array,Uint8ClampedArray,Int16Array,Uint16Array,Int32Array,Uint32Array,Float32Array,Float64Array".split(",");l<9;)(e=i[h[l++]])?(o(e.prototype,c,!0),o(e.prototype,f,!0)):s=!1;t.exports={ABV:a,CONSTR:s,TYPED:c,VIEW:f}},function(t,n){"use strict";var r={versions:function(){var t=window.navigator.userAgent;return{trident:t.indexOf("Trident")>-1,presto:t.indexOf("Presto")>-1,webKit:t.indexOf("AppleWebKit")>-1,gecko:t.indexOf("Gecko")>-1&&-1==t.indexOf("KHTML"),mobile:!!t.match(/AppleWebKit.*Mobile.*/),ios:!!t.match(/\(i[^;]+;( U;)? CPU.+Mac OS X/),android:t.indexOf("Android")>-1||t.indexOf("Linux")>-1,iPhone:t.indexOf("iPhone")>-1||t.indexOf("Mac")>-1,iPad:t.indexOf("iPad")>-1,webApp:-1==t.indexOf("Safari"),weixin:-1==t.indexOf("MicroMessenger")}}()};t.exports=r},function(t,n,r){"use strict";var e=r(85),i=function(t){return t&&t.__esModule?t:{default:t}}(e),o=function(){function t(t,n,e){return n||e?String.fromCharCode(n||e):r[t]||t}function n(t){return e[t]}var r={"&quot;":'"',"&lt;":"<","&gt;":">","&amp;":"&","&nbsp;":" "},e={};for(var u in r)e[r[u]]=u;return r["&apos;"]="'",e["'"]="&#39;",{encode:function(t){return t?(""+t).replace(/['<> "&]/g,n).replace(/\r?\n/g,"<br/>").replace(/\s/g,"&nbsp;"):""},decode:function(n){return n?(""+n).replace(/<br\s*\/?>/gi,"\n").replace(/&quot;|&lt;|&gt;|&amp;|&nbsp;|&apos;|&#(\d+);|&#(\d+)/g,t).replace(/\u00a0/g," "):""},encodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},encodeBase16forJSON:function(t){if(!t)return t;t=t.replace(/[\u4E00-\u9FBF]/gi,function(t){return escape(t).replace("%u","\\u")});for(var n=[],r=0,e=t.length;e>r;r++)n.push(t.charCodeAt(r).toString(16).toUpperCase());return n.join("")},decodeBase16:function(t){if(!t)return t;t+="";for(var n=[],r=0,e=t.length;e>r;r+=2)n.push(String.fromCharCode("0x"+t.slice(r,r+2)));return n.join("")},encodeObject:function(t){if(t instanceof Array)for(var n=0,r=t.length;r>n;n++)t[n]=o.encodeObject(t[n]);else if("object"==(void 0===t?"undefined":(0,i.default)(t)))for(var e in t)t[e]=o.encodeObject(t[e]);else if("string"==typeof t)return o.encode(t);return t},loadScript:function(t){var n=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(n),n.setAttribute("src",t)},addLoadEvent:function(t){var n=window.onload;"function"!=typeof window.onload?window.onload=t:window.onload=function(){n(),t()}}}}();t.exports=o},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=function(t){for(var n=e(this),r=o(n.length),u=arguments.length,c=i(u>1?arguments[1]:void 0,r),f=u>2?arguments[2]:void 0,a=void 0===f?r:i(f,r);a>c;)n[c++]=t;return n}},function(t,n,r){"use strict";var e=r(11),i=r(66);t.exports=function(t,n,r){n in t?e.f(t,n,i(0,r)):t[n]=r}},function(t,n,r){var e=r(6),i=r(3).document,o=e(i)&&e(i.createElement);t.exports=function(t){return o?i.createElement(t):{}}},function(t,n){t.exports="constructor,hasOwnProperty,isPrototypeOf,propertyIsEnumerable,toLocaleString,toString,valueOf".split(",")},function(t,n,r){var e=r(7)("match");t.exports=function(t){var n=/./;try{"/./"[t](n)}catch(r){try{return n[e]=!1,!"/./"[t](n)}catch(t){}}return!0}},function(t,n,r){t.exports=r(3).document&&document.documentElement},function(t,n,r){var e=r(6),i=r(144).set;t.exports=function(t,n,r){var o,u=n.constructor;return u!==r&&"function"==typeof u&&(o=u.prototype)!==r.prototype&&e(o)&&i&&i(t,o),t}},function(t,n,r){var e=r(80),i=r(7)("iterator"),o=Array.prototype;t.exports=function(t){return void 0!==t&&(e.Array===t||o[i]===t)}},function(t,n,r){var e=r(45);t.exports=Array.isArray||function(t){return"Array"==e(t)}},function(t,n,r){"use strict";var e=r(70),i=r(66),o=r(81),u={};r(27)(u,r(7)("iterator"),function(){return this}),t.exports=function(t,n,r){t.prototype=e(u,{next:i(1,r)}),o(t,n+" Iterator")}},function(t,n,r){"use strict";var e=r(69),i=r(1),o=r(28),u=r(27),c=r(24),f=r(80),a=r(139),s=r(81),l=r(32),h=r(7)("iterator"),v=!([].keys&&"next"in[].keys()),p="keys",d="values",y=function(){return this};t.exports=function(t,n,r,g,b,m,x){a(r,n,g);var w,S,_,O=function(t){if(!v&&t in F)return F[t];switch(t){case p:case d:return function(){return new r(this,t)}}return function(){return new r(this,t)}},E=n+" Iterator",P=b==d,j=!1,F=t.prototype,M=F[h]||F["@@iterator"]||b&&F[b],A=M||O(b),N=b?P?O("entries"):A:void 0,T="Array"==n?F.entries||M:M;if(T&&(_=l(T.call(new t)))!==Object.prototype&&(s(_,E,!0),e||c(_,h)||u(_,h,y)),P&&M&&M.name!==d&&(j=!0,A=function(){return M.call(this)}),e&&!x||!v&&!j&&F[h]||u(F,h,A),f[n]=A,f[E]=y,b)if(w={values:P?A:O(d),keys:m?A:O(p),entries:N},x)for(S in w)S in F||o(F,S,w[S]);else i(i.P+i.F*(v||j),n,w);return w}},function(t,n){var r=Math.expm1;t.exports=!r||r(10)>22025.465794806718||r(10)<22025.465794806718||-2e-17!=r(-2e-17)?function(t){return 0==(t=+t)?t:t>-1e-6&&t<1e-6?t+t*t/2:Math.exp(t)-1}:r},function(t,n){t.exports=Math.sign||function(t){return 0==(t=+t)||t!=t?t:t<0?-1:1}},function(t,n,r){var e=r(3),i=r(151).set,o=e.MutationObserver||e.WebKitMutationObserver,u=e.process,c=e.Promise,f="process"==r(45)(u);t.exports=function(){var t,n,r,a=function(){var e,i;for(f&&(e=u.domain)&&e.exit();t;){i=t.fn,t=t.next;try{i()}catch(e){throw t?r():n=void 0,e}}n=void 0,e&&e.enter()};if(f)r=function(){u.nextTick(a)};else if(o){var s=!0,l=document.createTextNode("");new o(a).observe(l,{characterData:!0}),r=function(){l.data=s=!s}}else if(c&&c.resolve){var h=c.resolve();r=function(){h.then(a)}}else r=function(){i.call(e,a)};return function(e){var i={fn:e,next:void 0};n&&(n.next=i),t||(t=i,r()),n=i}}},function(t,n,r){var e=r(6),i=r(2),o=function(t,n){if(i(t),!e(n)&&null!==n)throw TypeError(n+": can't set as prototype!")};t.exports={set:Object.setPrototypeOf||("__proto__"in{}?function(t,n,e){try{e=r(53)(Function.call,r(31).f(Object.prototype,"__proto__").set,2),e(t,[]),n=!(t instanceof Array)}catch(t){n=!0}return function(t,r){return o(t,r),n?t.__proto__=r:e(t,r),t}}({},!1):void 0),check:o}},function(t,n,r){var e=r(126)("keys"),i=r(76);t.exports=function(t){return e[t]||(e[t]=i(t))}},function(t,n,r){var e=r(2),i=r(26),o=r(7)("species");t.exports=function(t,n){var r,u=e(t).constructor;return void 0===u||void 0==(r=e(u)[o])?n:i(r)}},function(t,n,r){var e=r(67),i=r(46);t.exports=function(t){return function(n,r){var o,u,c=String(i(n)),f=e(r),a=c.length;return f<0||f>=a?t?"":void 0:(o=c.charCodeAt(f),o<55296||o>56319||f+1===a||(u=c.charCodeAt(f+1))<56320||u>57343?t?c.charAt(f):o:t?c.slice(f,f+2):u-56320+(o-55296<<10)+65536)}}},function(t,n,r){var e=r(122),i=r(46);t.exports=function(t,n,r){if(e(n))throw TypeError("String#"+r+" doesn't accept regex!");return String(i(t))}},function(t,n,r){"use strict";var e=r(67),i=r(46);t.exports=function(t){var n=String(i(this)),r="",o=e(t);if(o<0||o==1/0)throw RangeError("Count can't be negative");for(;o>0;(o>>>=1)&&(n+=n))1&o&&(r+=n);return r}},function(t,n){t.exports="\t\n\v\f\r   ᠎             　\u2028\u2029\ufeff"},function(t,n,r){var e,i,o,u=r(53),c=r(121),f=r(135),a=r(132),s=r(3),l=s.process,h=s.setImmediate,v=s.clearImmediate,p=s.MessageChannel,d=0,y={},g="onreadystatechange",b=function(){var t=+this;if(y.hasOwnProperty(t)){var n=y[t];delete y[t],n()}},m=function(t){b.call(t.data)};h&&v||(h=function(t){for(var n=[],r=1;arguments.length>r;)n.push(arguments[r++]);return y[++d]=function(){c("function"==typeof t?t:Function(t),n)},e(d),d},v=function(t){delete y[t]},"process"==r(45)(l)?e=function(t){l.nextTick(u(b,t,1))}:p?(i=new p,o=i.port2,i.port1.onmessage=m,e=u(o.postMessage,o,1)):s.addEventListener&&"function"==typeof postMessage&&!s.importScripts?(e=function(t){s.postMessage(t+"","*")},s.addEventListener("message",m,!1)):e=g in a("script")?function(t){f.appendChild(a("script"))[g]=function(){f.removeChild(this),b.call(t)}}:function(t){setTimeout(u(b,t,1),0)}),t.exports={set:h,clear:v}},function(t,n,r){"use strict";var e=r(3),i=r(10),o=r(69),u=r(127),c=r(27),f=r(73),a=r(4),s=r(68),l=r(67),h=r(16),v=r(71).f,p=r(11).f,d=r(130),y=r(81),g="ArrayBuffer",b="DataView",m="prototype",x="Wrong length!",w="Wrong index!",S=e[g],_=e[b],O=e.Math,E=e.RangeError,P=e.Infinity,j=S,F=O.abs,M=O.pow,A=O.floor,N=O.log,T=O.LN2,I="buffer",k="byteLength",L="byteOffset",R=i?"_b":I,C=i?"_l":k,D=i?"_o":L,U=function(t,n,r){var e,i,o,u=Array(r),c=8*r-n-1,f=(1<<c)-1,a=f>>1,s=23===n?M(2,-24)-M(2,-77):0,l=0,h=t<0||0===t&&1/t<0?1:0;for(t=F(t),t!=t||t===P?(i=t!=t?1:0,e=f):(e=A(N(t)/T),t*(o=M(2,-e))<1&&(e--,o*=2),t+=e+a>=1?s/o:s*M(2,1-a),t*o>=2&&(e++,o/=2),e+a>=f?(i=0,e=f):e+a>=1?(i=(t*o-1)*M(2,n),e+=a):(i=t*M(2,a-1)*M(2,n),e=0));n>=8;u[l++]=255&i,i/=256,n-=8);for(e=e<<n|i,c+=n;c>0;u[l++]=255&e,e/=256,c-=8);return u[--l]|=128*h,u},W=function(t,n,r){var e,i=8*r-n-1,o=(1<<i)-1,u=o>>1,c=i-7,f=r-1,a=t[f--],s=127&a;for(a>>=7;c>0;s=256*s+t[f],f--,c-=8);for(e=s&(1<<-c)-1,s>>=-c,c+=n;c>0;e=256*e+t[f],f--,c-=8);if(0===s)s=1-u;else{if(s===o)return e?NaN:a?-P:P;e+=M(2,n),s-=u}return(a?-1:1)*e*M(2,s-n)},G=function(t){return t[3]<<24|t[2]<<16|t[1]<<8|t[0]},B=function(t){return[255&t]},V=function(t){return[255&t,t>>8&255]},z=function(t){return[255&t,t>>8&255,t>>16&255,t>>24&255]},q=function(t){return U(t,52,8)},K=function(t){return U(t,23,4)},J=function(t,n,r){p(t[m],n,{get:function(){return this[r]}})},Y=function(t,n,r,e){var i=+r,o=l(i);if(i!=o||o<0||o+n>t[C])throw E(w);var u=t[R]._b,c=o+t[D],f=u.slice(c,c+n);return e?f:f.reverse()},H=function(t,n,r,e,i,o){var u=+r,c=l(u);if(u!=c||c<0||c+n>t[C])throw E(w);for(var f=t[R]._b,a=c+t[D],s=e(+i),h=0;h<n;h++)f[a+h]=s[o?h:n-h-1]},$=function(t,n){s(t,S,g);var r=+n,e=h(r);if(r!=e)throw E(x);return e};if(u.ABV){if(!a(function(){new S})||!a(function(){new S(.5)})){S=function(t){return new j($(this,t))};for(var X,Q=S[m]=j[m],Z=v(j),tt=0;Z.length>tt;)(X=Z[tt++])in S||c(S,X,j[X]);o||(Q.constructor=S)}var nt=new _(new S(2)),rt=_[m].setInt8;nt.setInt8(0,2147483648),nt.setInt8(1,2147483649),!nt.getInt8(0)&&nt.getInt8(1)||f(_[m],{setInt8:function(t,n){rt.call(this,t,n<<24>>24)},setUint8:function(t,n){rt.call(this,t,n<<24>>24)}},!0)}else S=function(t){var n=$(this,t);this._b=d.call(Array(n),0),this[C]=n},_=function(t,n,r){s(this,_,b),s(t,S,b);var e=t[C],i=l(n);if(i<0||i>e)throw E("Wrong offset!");if(r=void 0===r?e-i:h(r),i+r>e)throw E(x);this[R]=t,this[D]=i,this[C]=r},i&&(J(S,k,"_l"),J(_,I,"_b"),J(_,k,"_l"),J(_,L,"_o")),f(_[m],{getInt8:function(t){return Y(this,1,t)[0]<<24>>24},getUint8:function(t){return Y(this,1,t)[0]},getInt16:function(t){var n=Y(this,2,t,arguments[1]);return(n[1]<<8|n[0])<<16>>16},getUint16:function(t){var n=Y(this,2,t,arguments[1]);return n[1]<<8|n[0]},getInt32:function(t){return G(Y(this,4,t,arguments[1]))},getUint32:function(t){return G(Y(this,4,t,arguments[1]))>>>0},getFloat32:function(t){return W(Y(this,4,t,arguments[1]),23,4)},getFloat64:function(t){return W(Y(this,8,t,arguments[1]),52,8)},setInt8:function(t,n){H(this,1,t,B,n)},setUint8:function(t,n){H(this,1,t,B,n)},setInt16:function(t,n){H(this,2,t,V,n,arguments[2])},setUint16:function(t,n){H(this,2,t,V,n,arguments[2])},setInt32:function(t,n){H(this,4,t,z,n,arguments[2])},setUint32:function(t,n){H(this,4,t,z,n,arguments[2])},setFloat32:function(t,n){H(this,4,t,K,n,arguments[2])},setFloat64:function(t,n){H(this,8,t,q,n,arguments[2])}});y(S,g),y(_,b),c(_[m],u.VIEW,!0),n[g]=S,n[b]=_},function(t,n,r){var e=r(3),i=r(52),o=r(69),u=r(182),c=r(11).f;t.exports=function(t){var n=i.Symbol||(i.Symbol=o?{}:e.Symbol||{});"_"==t.charAt(0)||t in n||c(n,t,{value:u.f(t)})}},function(t,n,r){var e=r(114),i=r(7)("iterator"),o=r(80);t.exports=r(52).getIteratorMethod=function(t){if(void 0!=t)return t[i]||t["@@iterator"]||o[e(t)]}},function(t,n,r){"use strict";var e=r(78),i=r(170),o=r(80),u=r(30);t.exports=r(140)(Array,"Array",function(t,n){this._t=u(t),this._i=0,this._k=n},function(){var t=this._t,n=this._k,r=this._i++;return!t||r>=t.length?(this._t=void 0,i(1)):"keys"==n?i(0,r):"values"==n?i(0,t[r]):i(0,[r,t[r]])},"values"),o.Arguments=o.Array,e("keys"),e("values"),e("entries")},function(t,n){function r(t,n){t.classList?t.classList.add(n):t.className+=" "+n}t.exports=r},function(t,n){function r(t,n){if(t.classList)t.classList.remove(n);else{var r=new RegExp("(^|\\b)"+n.split(" ").join("|")+"(\\b|$)","gi");t.className=t.className.replace(r," ")}}t.exports=r},function(t,n){function r(){throw new Error("setTimeout has not been defined")}function e(){throw new Error("clearTimeout has not been defined")}function i(t){if(s===setTimeout)return setTimeout(t,0);if((s===r||!s)&&setTimeout)return s=setTimeout,setTimeout(t,0);try{return s(t,0)}catch(n){try{return s.call(null,t,0)}catch(n){return s.call(this,t,0)}}}function o(t){if(l===clearTimeout)return clearTimeout(t);if((l===e||!l)&&clearTimeout)return l=clearTimeout,clearTimeout(t);try{return l(t)}catch(n){try{return l.call(null,t)}catch(n){return l.call(this,t)}}}function u(){d&&v&&(d=!1,v.length?p=v.concat(p):y=-1,p.length&&c())}function c(){if(!d){var t=i(u);d=!0;for(var n=p.length;n;){for(v=p,p=[];++y<n;)v&&v[y].run();y=-1,n=p.length}v=null,d=!1,o(t)}}function f(t,n){this.fun=t,this.array=n}function a(){}var s,l,h=t.exports={};!function(){try{s="function"==typeof setTimeout?setTimeout:r}catch(t){s=r}try{l="function"==typeof clearTimeout?clearTimeout:e}catch(t){l=e}}();var v,p=[],d=!1,y=-1;h.nextTick=function(t){var n=new Array(arguments.length-1);if(arguments.length>1)for(var r=1;r<arguments.length;r++)n[r-1]=arguments[r];p.push(new f(t,n)),1!==p.length||d||i(c)},f.prototype.run=function(){this.fun.apply(null,this.array)},h.title="browser",h.browser=!0,h.env={},h.argv=[],h.version="",h.versions={},h.on=a,h.addListener=a,h.once=a,h.off=a,h.removeListener=a,h.removeAllListeners=a,h.emit=a,h.prependListener=a,h.prependOnceListener=a,h.listeners=function(t){return[]},h.binding=function(t){throw new Error("process.binding is not supported")},h.cwd=function(){return"/"},h.chdir=function(t){throw new Error("process.chdir is not supported")},h.umask=function(){return 0}},function(t,n,r){var e=r(45);t.exports=function(t,n){if("number"!=typeof t&&"Number"!=e(t))throw TypeError(n);return+t}},function(t,n,r){"use strict";var e=r(17),i=r(75),o=r(16);t.exports=[].copyWithin||function(t,n){var r=e(this),u=o(r.length),c=i(t,u),f=i(n,u),a=arguments.length>2?arguments[2]:void 0,s=Math.min((void 0===a?u:i(a,u))-f,u-c),l=1;for(f<c&&c<f+s&&(l=-1,f+=s-1,c+=s-1);s-- >0;)f in r?r[c]=r[f]:delete r[c],c+=l,f+=l;return r}},function(t,n,r){var e=r(79);t.exports=function(t,n){var r=[];return e(t,!1,r.push,r,n),r}},function(t,n,r){var e=r(26),i=r(17),o=r(115),u=r(16);t.exports=function(t,n,r,c,f){e(n);var a=i(t),s=o(a),l=u(a.length),h=f?l-1:0,v=f?-1:1;if(r<2)for(;;){if(h in s){c=s[h],h+=v;break}if(h+=v,f?h<0:l<=h)throw TypeError("Reduce of empty array with no initial value")}for(;f?h>=0:l>h;h+=v)h in s&&(c=n(c,s[h],h,a));return c}},function(t,n,r){"use strict";var e=r(26),i=r(6),o=r(121),u=[].slice,c={},f=function(t,n,r){if(!(n in c)){for(var e=[],i=0;i<n;i++)e[i]="a["+i+"]";c[n]=Function("F,a","return new F("+e.join(",")+")")}return c[n](t,r)};t.exports=Function.bind||function(t){var n=e(this),r=u.call(arguments,1),c=function(){var e=r.concat(u.call(arguments));return this instanceof c?f(n,e.length,e):o(n,e,t)};return i(n.prototype)&&(c.prototype=n.prototype),c}},function(t,n,r){"use strict";var e=r(11).f,i=r(70),o=r(73),u=r(53),c=r(68),f=r(46),a=r(79),s=r(140),l=r(170),h=r(74),v=r(10),p=r(65).fastKey,d=v?"_s":"size",y=function(t,n){var r,e=p(n);if("F"!==e)return t._i[e];for(r=t._f;r;r=r.n)if(r.k==n)return r};t.exports={getConstructor:function(t,n,r,s){var l=t(function(t,e){c(t,l,n,"_i"),t._i=i(null),t._f=void 0,t._l=void 0,t[d]=0,void 0!=e&&a(e,r,t[s],t)});return o(l.prototype,{clear:function(){for(var t=this,n=t._i,r=t._f;r;r=r.n)r.r=!0,r.p&&(r.p=r.p.n=void 0),delete n[r.i];t._f=t._l=void 0,t[d]=0},delete:function(t){var n=this,r=y(n,t);if(r){var e=r.n,i=r.p;delete n._i[r.i],r.r=!0,i&&(i.n=e),e&&(e.p=i),n._f==r&&(n._f=e),n._l==r&&(n._l=i),n[d]--}return!!r},forEach:function(t){c(this,l,"forEach");for(var n,r=u(t,arguments.length>1?arguments[1]:void 0,3);n=n?n.n:this._f;)for(r(n.v,n.k,this);n&&n.r;)n=n.p},has:function(t){return!!y(this,t)}}),v&&e(l.prototype,"size",{get:function(){return f(this[d])}}),l},def:function(t,n,r){var e,i,o=y(t,n);return o?o.v=r:(t._l=o={i:i=p(n,!0),k:n,v:r,p:e=t._l,n:void 0,r:!1},t._f||(t._f=o),e&&(e.n=o),t[d]++,"F"!==i&&(t._i[i]=o)),t},getEntry:y,setStrong:function(t,n,r){s(t,n,function(t,n){this._t=t,this._k=n,this._l=void 0},function(){for(var t=this,n=t._k,r=t._l;r&&r.r;)r=r.p;return t._t&&(t._l=r=r?r.n:t._t._f)?"keys"==n?l(0,r.k):"values"==n?l(0,r.v):l(0,[r.k,r.v]):(t._t=void 0,l(1))},r?"entries":"values",!r,!0),h(n)}}},function(t,n,r){var e=r(114),i=r(161);t.exports=function(t){return function(){if(e(this)!=t)throw TypeError(t+"#toJSON isn't generic");return i(this)}}},function(t,n,r){"use strict";var e=r(73),i=r(65).getWeak,o=r(2),u=r(6),c=r(68),f=r(79),a=r(48),s=r(24),l=a(5),h=a(6),v=0,p=function(t){return t._l||(t._l=new d)},d=function(){this.a=[]},y=function(t,n){return l(t.a,function(t){return t[0]===n})};d.prototype={get:function(t){var n=y(this,t);if(n)return n[1]},has:function(t){return!!y(this,t)},set:function(t,n){var r=y(this,t);r?r[1]=n:this.a.push([t,n])},delete:function(t){var n=h(this.a,function(n){return n[0]===t});return~n&&this.a.splice(n,1),!!~n}},t.exports={getConstructor:function(t,n,r,o){var a=t(function(t,e){c(t,a,n,"_i"),t._i=v++,t._l=void 0,void 0!=e&&f(e,r,t[o],t)});return e(a.prototype,{delete:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).delete(t):n&&s(n,this._i)&&delete n[this._i]},has:function(t){if(!u(t))return!1;var n=i(t);return!0===n?p(this).has(t):n&&s(n,this._i)}}),a},def:function(t,n,r){var e=i(o(n),!0);return!0===e?p(t).set(n,r):e[t._i]=r,t},ufstore:p}},function(t,n,r){t.exports=!r(10)&&!r(4)(function(){return 7!=Object.defineProperty(r(132)("div"),"a",{get:function(){return 7}}).a})},function(t,n,r){var e=r(6),i=Math.floor;t.exports=function(t){return!e(t)&&isFinite(t)&&i(t)===t}},function(t,n,r){var e=r(2);t.exports=function(t,n,r,i){try{return i?n(e(r)[0],r[1]):n(r)}catch(n){var o=t.return;throw void 0!==o&&e(o.call(t)),n}}},function(t,n){t.exports=function(t,n){return{value:n,done:!!t}}},function(t,n){t.exports=Math.log1p||function(t){return(t=+t)>-1e-8&&t<1e-8?t-t*t/2:Math.log(1+t)}},function(t,n,r){"use strict";var e=r(72),i=r(125),o=r(116),u=r(17),c=r(115),f=Object.assign;t.exports=!f||r(4)(function(){var t={},n={},r=Symbol(),e="abcdefghijklmnopqrst";return t[r]=7,e.split("").forEach(function(t){n[t]=t}),7!=f({},t)[r]||Object.keys(f({},n)).join("")!=e})?function(t,n){for(var r=u(t),f=arguments.length,a=1,s=i.f,l=o.f;f>a;)for(var h,v=c(arguments[a++]),p=s?e(v).concat(s(v)):e(v),d=p.length,y=0;d>y;)l.call(v,h=p[y++])&&(r[h]=v[h]);return r}:f},function(t,n,r){var e=r(11),i=r(2),o=r(72);t.exports=r(10)?Object.defineProperties:function(t,n){i(t);for(var r,u=o(n),c=u.length,f=0;c>f;)e.f(t,r=u[f++],n[r]);return t}},function(t,n,r){var e=r(30),i=r(71).f,o={}.toString,u="object"==typeof window&&window&&Object.getOwnPropertyNames?Object.getOwnPropertyNames(window):[],c=function(t){try{return i(t)}catch(t){return u.slice()}};t.exports.f=function(t){return u&&"[object Window]"==o.call(t)?c(t):i(e(t))}},function(t,n,r){var e=r(24),i=r(30),o=r(117)(!1),u=r(145)("IE_PROTO");t.exports=function(t,n){var r,c=i(t),f=0,a=[];for(r in c)r!=u&&e(c,r)&&a.push(r);for(;n.length>f;)e(c,r=n[f++])&&(~o(a,r)||a.push(r));return a}},function(t,n,r){var e=r(72),i=r(30),o=r(116).f;t.exports=function(t){return function(n){for(var r,u=i(n),c=e(u),f=c.length,a=0,s=[];f>a;)o.call(u,r=c[a++])&&s.push(t?[r,u[r]]:u[r]);return s}}},function(t,n,r){var e=r(71),i=r(125),o=r(2),u=r(3).Reflect;t.exports=u&&u.ownKeys||function(t){var n=e.f(o(t)),r=i.f;return r?n.concat(r(t)):n}},function(t,n,r){var e=r(3).parseFloat,i=r(82).trim;t.exports=1/e(r(150)+"-0")!=-1/0?function(t){var n=i(String(t),3),r=e(n);return 0===r&&"-"==n.charAt(0)?-0:r}:e},function(t,n,r){var e=r(3).parseInt,i=r(82).trim,o=r(150),u=/^[\-+]?0[xX]/;t.exports=8!==e(o+"08")||22!==e(o+"0x16")?function(t,n){var r=i(String(t),3);return e(r,n>>>0||(u.test(r)?16:10))}:e},function(t,n){t.exports=Object.is||function(t,n){return t===n?0!==t||1/t==1/n:t!=t&&n!=n}},function(t,n,r){var e=r(16),i=r(149),o=r(46);t.exports=function(t,n,r,u){var c=String(o(t)),f=c.length,a=void 0===r?" ":String(r),s=e(n);if(s<=f||""==a)return c;var l=s-f,h=i.call(a,Math.ceil(l/a.length));return h.length>l&&(h=h.slice(0,l)),u?h+c:c+h}},function(t,n,r){n.f=r(7)},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Map",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{get:function(t){var n=e.getEntry(this,t);return n&&n.v},set:function(t,n){return e.def(this,0===t?0:t,n)}},e,!0)},function(t,n,r){r(10)&&"g"!=/./g.flags&&r(11).f(RegExp.prototype,"flags",{configurable:!0,get:r(120)})},function(t,n,r){"use strict";var e=r(164);t.exports=r(118)("Set",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t=0===t?0:t,t)}},e)},function(t,n,r){"use strict";var e,i=r(48)(0),o=r(28),u=r(65),c=r(172),f=r(166),a=r(6),s=u.getWeak,l=Object.isExtensible,h=f.ufstore,v={},p=function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},d={get:function(t){if(a(t)){var n=s(t);return!0===n?h(this).get(t):n?n[this._i]:void 0}},set:function(t,n){return f.def(this,t,n)}},y=t.exports=r(118)("WeakMap",p,d,f,!0,!0);7!=(new y).set((Object.freeze||Object)(v),7).get(v)&&(e=f.getConstructor(p),c(e.prototype,d),u.NEED=!0,i(["delete","has","get","set"],function(t){var n=y.prototype,r=n[t];o(n,t,function(n,i){if(a(n)&&!l(n)){this._f||(this._f=new e);var o=this._f[t](n,i);return"set"==t?this:o}return r.call(this,n,i)})}))},,,,function(t,n){"use strict";function r(){var t=document.querySelector("#page-nav");if(t&&!document.querySelector("#page-nav .extend.prev")&&(t.innerHTML='<a class="extend prev disabled" rel="prev">&laquo; Prev</a>'+t.innerHTML),t&&!document.querySelector("#page-nav .extend.next")&&(t.innerHTML=t.innerHTML+'<a class="extend next disabled" rel="next">Next &raquo;</a>'),yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".article-entry a:not(.article-more-a)").forEach(function(t){var n=t.getAttribute("target");n&&""!==n||t.setAttribute("target","_blank")})}if(yiliaConfig&&yiliaConfig.open_in_new){document.querySelectorAll(".toc-number").forEach(function(t){t.style.display="none"})}var n=document.querySelector("#js-aboutme");n&&0!==n.length&&(n.innerHTML=n.innerText)}t.exports={init:r}},function(t,n,r){"use strict";function e(t){return t&&t.__esModule?t:{default:t}}function i(t,n){var r=/\/|index.html/g;return t.replace(r,"")===n.replace(r,"")}function o(){for(var t=document.querySelectorAll(".js-header-menu li a"),n=window.location.pathname,r=0,e=t.length;r<e;r++){var o=t[r];i(n,o.getAttribute("href"))&&(0,h.default)(o,"active")}}function u(t){for(var n=t.offsetLeft,r=t.offsetParent;null!==r;)n+=r.offsetLeft,r=r.offsetParent;return n}function c(t){for(var n=t.offsetTop,r=t.offsetParent;null!==r;)n+=r.offsetTop,r=r.offsetParent;return n}function f(t,n,r,e,i){var o=u(t),f=c(t)-n;if(f-r<=i){var a=t.$newDom;a||(a=t.cloneNode(!0),(0,d.default)(t,a),t.$newDom=a,a.style.position="fixed",a.style.top=(r||f)+"px",a.style.left=o+"px",a.style.zIndex=e||2,a.style.width="100%",a.style.color="#fff"),a.style.visibility="visible",t.style.visibility="hidden"}else{t.style.visibility="visible";var s=t.$newDom;s&&(s.style.visibility="hidden")}}function a(){var t=document.querySelector(".js-overlay"),n=document.querySelector(".js-header-menu");f(t,document.body.scrollTop,-63,2,0),f(n,document.body.scrollTop,1,3,0)}function s(){document.querySelector("#container").addEventListener("scroll",function(t){a()}),window.addEventListener("scroll",function(t){a()}),a()}var l=r(156),h=e(l),v=r(157),p=(e(v),r(382)),d=e(p),y=r(128),g=e(y),b=r(190),m=e(b),x=r(129);(function(){g.default.versions.mobile&&window.screen.width<800&&(o(),s())})(),(0,x.addLoadEvent)(function(){m.default.init()}),t.exports={}},,,,function(t,n,r){(function(t){"use strict";function n(t,n,r){t[n]||Object[e](t,n,{writable:!0,configurable:!0,value:r})}if(r(381),r(391),r(198),t._babelPolyfill)throw new Error("only one instance of babel-polyfill is allowed");t._babelPolyfill=!0;var e="defineProperty";n(String.prototype,"padLeft","".padStart),n(String.prototype,"padRight","".padEnd),"pop,reverse,shift,keys,values,entries,indexOf,every,some,forEach,map,filter,find,findIndex,includes,join,slice,concat,push,splice,unshift,sort,lastIndexOf,reduce,reduceRight,copyWithin,fill".split(",").forEach(function(t){[][t]&&n(Array,t,Function.call.bind([][t]))})}).call(n,function(){return this}())},,,function(t,n,r){r(210),t.exports=r(52).RegExp.escape},,,,function(t,n,r){var e=r(6),i=r(138),o=r(7)("species");t.exports=function(t){var n;return i(t)&&(n=t.constructor,"function"!=typeof n||n!==Array&&!i(n.prototype)||(n=void 0),e(n)&&null===(n=n[o])&&(n=void 0)),void 0===n?Array:n}},function(t,n,r){var e=r(202);t.exports=function(t,n){return new(e(t))(n)}},function(t,n,r){"use strict";var e=r(2),i=r(50),o="number";t.exports=function(t){if("string"!==t&&t!==o&&"default"!==t)throw TypeError("Incorrect hint");return i(e(this),t!=o)}},function(t,n,r){var e=r(72),i=r(125),o=r(116);t.exports=function(t){var n=e(t),r=i.f;if(r)for(var u,c=r(t),f=o.f,a=0;c.length>a;)f.call(t,u=c[a++])&&n.push(u);return n}},function(t,n,r){var e=r(72),i=r(30);t.exports=function(t,n){for(var r,o=i(t),u=e(o),c=u.length,f=0;c>f;)if(o[r=u[f++]]===n)return r}},function(t,n,r){"use strict";var e=r(208),i=r(121),o=r(26);t.exports=function(){for(var t=o(this),n=arguments.length,r=Array(n),u=0,c=e._,f=!1;n>u;)(r[u]=arguments[u++])===c&&(f=!0);return function(){var e,o=this,u=arguments.length,a=0,s=0;if(!f&&!u)return i(t,r,o);if(e=r.slice(),f)for(;n>a;a++)e[a]===c&&(e[a]=arguments[s++]);for(;u>s;)e.push(arguments[s++]);return i(t,e,o)}}},function(t,n,r){t.exports=r(3)},function(t,n){t.exports=function(t,n){var r=n===Object(n)?function(t){return n[t]}:n;return function(n){return String(n).replace(t,r)}}},function(t,n,r){var e=r(1),i=r(209)(/[\\^$*+?.()|[\]{}]/g,"\\$&");e(e.S,"RegExp",{escape:function(t){return i(t)}})},function(t,n,r){var e=r(1);e(e.P,"Array",{copyWithin:r(160)}),r(78)("copyWithin")},function(t,n,r){"use strict";var e=r(1),i=r(48)(4);e(e.P+e.F*!r(47)([].every,!0),"Array",{every:function(t){return i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.P,"Array",{fill:r(130)}),r(78)("fill")},function(t,n,r){"use strict";var e=r(1),i=r(48)(2);e(e.P+e.F*!r(47)([].filter,!0),"Array",{filter:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(6),o="findIndex",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{findIndex:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(5),o="find",u=!0;o in[]&&Array(1)[o](function(){u=!1}),e(e.P+e.F*u,"Array",{find:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)(o)},function(t,n,r){"use strict";var e=r(1),i=r(48)(0),o=r(47)([].forEach,!0);e(e.P+e.F*!o,"Array",{forEach:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(53),i=r(1),o=r(17),u=r(169),c=r(137),f=r(16),a=r(131),s=r(154);i(i.S+i.F*!r(123)(function(t){Array.from(t)}),"Array",{from:function(t){var n,r,i,l,h=o(t),v="function"==typeof this?this:Array,p=arguments.length,d=p>1?arguments[1]:void 0,y=void 0!==d,g=0,b=s(h);if(y&&(d=e(d,p>2?arguments[2]:void 0,2)),void 0==b||v==Array&&c(b))for(n=f(h.length),r=new v(n);n>g;g++)a(r,g,y?d(h[g],g):h[g]);else for(l=b.call(h),r=new v;!(i=l.next()).done;g++)a(r,g,y?u(l,d,[i.value,g],!0):i.value);return r.length=g,r}})},function(t,n,r){"use strict";var e=r(1),i=r(117)(!1),o=[].indexOf,u=!!o&&1/[1].indexOf(1,-0)<0;e(e.P+e.F*(u||!r(47)(o)),"Array",{indexOf:function(t){return u?o.apply(this,arguments)||0:i(this,t,arguments[1])}})},function(t,n,r){var e=r(1);e(e.S,"Array",{isArray:r(138)})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=[].join;e(e.P+e.F*(r(115)!=Object||!r(47)(o)),"Array",{join:function(t){return o.call(i(this),void 0===t?",":t)}})},function(t,n,r){"use strict";var e=r(1),i=r(30),o=r(67),u=r(16),c=[].lastIndexOf,f=!!c&&1/[1].lastIndexOf(1,-0)<0;e(e.P+e.F*(f||!r(47)(c)),"Array",{lastIndexOf:function(t){if(f)return c.apply(this,arguments)||0;var n=i(this),r=u(n.length),e=r-1;for(arguments.length>1&&(e=Math.min(e,o(arguments[1]))),e<0&&(e=r+e);e>=0;e--)if(e in n&&n[e]===t)return e||0;return-1}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(1);e(e.P+e.F*!r(47)([].map,!0),"Array",{map:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(131);e(e.S+e.F*r(4)(function(){function t(){}return!(Array.of.call(t)instanceof t)}),"Array",{of:function(){for(var t=0,n=arguments.length,r=new("function"==typeof this?this:Array)(n);n>t;)i(r,t,arguments[t++]);return r.length=n,r}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduceRight,!0),"Array",{reduceRight:function(t){return i(this,t,arguments.length,arguments[1],!0)}})},function(t,n,r){"use strict";var e=r(1),i=r(162);e(e.P+e.F*!r(47)([].reduce,!0),"Array",{reduce:function(t){return i(this,t,arguments.length,arguments[1],!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(135),o=r(45),u=r(75),c=r(16),f=[].slice;e(e.P+e.F*r(4)(function(){i&&f.call(i)}),"Array",{slice:function(t,n){var r=c(this.length),e=o(this);if(n=void 0===n?r:n,"Array"==e)return f.call(this,t,n);for(var i=u(t,r),a=u(n,r),s=c(a-i),l=Array(s),h=0;h<s;h++)l[h]="String"==e?this.charAt(i+h):this[i+h];return l}})},function(t,n,r){"use strict";var e=r(1),i=r(48)(3);e(e.P+e.F*!r(47)([].some,!0),"Array",{some:function(t){return i(this,t,arguments[1])}})},function(t,n,r){"use strict";var e=r(1),i=r(26),o=r(17),u=r(4),c=[].sort,f=[1,2,3];e(e.P+e.F*(u(function(){f.sort(void 0)})||!u(function(){f.sort(null)})||!r(47)(c)),"Array",{sort:function(t){return void 0===t?c.call(o(this)):c.call(o(this),i(t))}})},function(t,n,r){r(74)("Array")},function(t,n,r){var e=r(1);e(e.S,"Date",{now:function(){return(new Date).getTime()}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=Date.prototype.getTime,u=function(t){return t>9?t:"0"+t};e(e.P+e.F*(i(function(){return"0385-07-25T07:06:39.999Z"!=new Date(-5e13-1).toISOString()})||!i(function(){new Date(NaN).toISOString()})),"Date",{toISOString:function(){
if(!isFinite(o.call(this)))throw RangeError("Invalid time value");var t=this,n=t.getUTCFullYear(),r=t.getUTCMilliseconds(),e=n<0?"-":n>9999?"+":"";return e+("00000"+Math.abs(n)).slice(e?-6:-4)+"-"+u(t.getUTCMonth()+1)+"-"+u(t.getUTCDate())+"T"+u(t.getUTCHours())+":"+u(t.getUTCMinutes())+":"+u(t.getUTCSeconds())+"."+(r>99?r:"0"+u(r))+"Z"}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50);e(e.P+e.F*r(4)(function(){return null!==new Date(NaN).toJSON()||1!==Date.prototype.toJSON.call({toISOString:function(){return 1}})}),"Date",{toJSON:function(t){var n=i(this),r=o(n);return"number"!=typeof r||isFinite(r)?n.toISOString():null}})},function(t,n,r){var e=r(7)("toPrimitive"),i=Date.prototype;e in i||r(27)(i,e,r(204))},function(t,n,r){var e=Date.prototype,i="Invalid Date",o="toString",u=e[o],c=e.getTime;new Date(NaN)+""!=i&&r(28)(e,o,function(){var t=c.call(this);return t===t?u.call(this):i})},function(t,n,r){var e=r(1);e(e.P,"Function",{bind:r(163)})},function(t,n,r){"use strict";var e=r(6),i=r(32),o=r(7)("hasInstance"),u=Function.prototype;o in u||r(11).f(u,o,{value:function(t){if("function"!=typeof this||!e(t))return!1;if(!e(this.prototype))return t instanceof this;for(;t=i(t);)if(this.prototype===t)return!0;return!1}})},function(t,n,r){var e=r(11).f,i=r(66),o=r(24),u=Function.prototype,c="name",f=Object.isExtensible||function(){return!0};c in u||r(10)&&e(u,c,{configurable:!0,get:function(){try{var t=this,n=(""+t).match(/^\s*function ([^ (]*)/)[1];return o(t,c)||!f(t)||e(t,c,i(5,n)),n}catch(t){return""}}})},function(t,n,r){var e=r(1),i=r(171),o=Math.sqrt,u=Math.acosh;e(e.S+e.F*!(u&&710==Math.floor(u(Number.MAX_VALUE))&&u(1/0)==1/0),"Math",{acosh:function(t){return(t=+t)<1?NaN:t>94906265.62425156?Math.log(t)+Math.LN2:i(t-1+o(t-1)*o(t+1))}})},function(t,n,r){function e(t){return isFinite(t=+t)&&0!=t?t<0?-e(-t):Math.log(t+Math.sqrt(t*t+1)):t}var i=r(1),o=Math.asinh;i(i.S+i.F*!(o&&1/o(0)>0),"Math",{asinh:e})},function(t,n,r){var e=r(1),i=Math.atanh;e(e.S+e.F*!(i&&1/i(-0)<0),"Math",{atanh:function(t){return 0==(t=+t)?t:Math.log((1+t)/(1-t))/2}})},function(t,n,r){var e=r(1),i=r(142);e(e.S,"Math",{cbrt:function(t){return i(t=+t)*Math.pow(Math.abs(t),1/3)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{clz32:function(t){return(t>>>=0)?31-Math.floor(Math.log(t+.5)*Math.LOG2E):32}})},function(t,n,r){var e=r(1),i=Math.exp;e(e.S,"Math",{cosh:function(t){return(i(t=+t)+i(-t))/2}})},function(t,n,r){var e=r(1),i=r(141);e(e.S+e.F*(i!=Math.expm1),"Math",{expm1:i})},function(t,n,r){var e=r(1),i=r(142),o=Math.pow,u=o(2,-52),c=o(2,-23),f=o(2,127)*(2-c),a=o(2,-126),s=function(t){return t+1/u-1/u};e(e.S,"Math",{fround:function(t){var n,r,e=Math.abs(t),o=i(t);return e<a?o*s(e/a/c)*a*c:(n=(1+c/u)*e,r=n-(n-e),r>f||r!=r?o*(1/0):o*r)}})},function(t,n,r){var e=r(1),i=Math.abs;e(e.S,"Math",{hypot:function(t,n){for(var r,e,o=0,u=0,c=arguments.length,f=0;u<c;)r=i(arguments[u++]),f<r?(e=f/r,o=o*e*e+1,f=r):r>0?(e=r/f,o+=e*e):o+=r;return f===1/0?1/0:f*Math.sqrt(o)}})},function(t,n,r){var e=r(1),i=Math.imul;e(e.S+e.F*r(4)(function(){return-5!=i(4294967295,5)||2!=i.length}),"Math",{imul:function(t,n){var r=65535,e=+t,i=+n,o=r&e,u=r&i;return 0|o*u+((r&e>>>16)*u+o*(r&i>>>16)<<16>>>0)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log10:function(t){return Math.log(t)/Math.LN10}})},function(t,n,r){var e=r(1);e(e.S,"Math",{log1p:r(171)})},function(t,n,r){var e=r(1);e(e.S,"Math",{log2:function(t){return Math.log(t)/Math.LN2}})},function(t,n,r){var e=r(1);e(e.S,"Math",{sign:r(142)})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S+e.F*r(4)(function(){return-2e-17!=!Math.sinh(-2e-17)}),"Math",{sinh:function(t){return Math.abs(t=+t)<1?(i(t)-i(-t))/2:(o(t-1)-o(-t-1))*(Math.E/2)}})},function(t,n,r){var e=r(1),i=r(141),o=Math.exp;e(e.S,"Math",{tanh:function(t){var n=i(t=+t),r=i(-t);return n==1/0?1:r==1/0?-1:(n-r)/(o(t)+o(-t))}})},function(t,n,r){var e=r(1);e(e.S,"Math",{trunc:function(t){return(t>0?Math.floor:Math.ceil)(t)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(45),u=r(136),c=r(50),f=r(4),a=r(71).f,s=r(31).f,l=r(11).f,h=r(82).trim,v="Number",p=e[v],d=p,y=p.prototype,g=o(r(70)(y))==v,b="trim"in String.prototype,m=function(t){var n=c(t,!1);if("string"==typeof n&&n.length>2){n=b?n.trim():h(n,3);var r,e,i,o=n.charCodeAt(0);if(43===o||45===o){if(88===(r=n.charCodeAt(2))||120===r)return NaN}else if(48===o){switch(n.charCodeAt(1)){case 66:case 98:e=2,i=49;break;case 79:case 111:e=8,i=55;break;default:return+n}for(var u,f=n.slice(2),a=0,s=f.length;a<s;a++)if((u=f.charCodeAt(a))<48||u>i)return NaN;return parseInt(f,e)}}return+n};if(!p(" 0o1")||!p("0b1")||p("+0x1")){p=function(t){var n=arguments.length<1?0:t,r=this;return r instanceof p&&(g?f(function(){y.valueOf.call(r)}):o(r)!=v)?u(new d(m(n)),r,p):m(n)};for(var x,w=r(10)?a(d):"MAX_VALUE,MIN_VALUE,NaN,NEGATIVE_INFINITY,POSITIVE_INFINITY,EPSILON,isFinite,isInteger,isNaN,isSafeInteger,MAX_SAFE_INTEGER,MIN_SAFE_INTEGER,parseFloat,parseInt,isInteger".split(","),S=0;w.length>S;S++)i(d,x=w[S])&&!i(p,x)&&l(p,x,s(d,x));p.prototype=y,y.constructor=p,r(28)(e,v,p)}},function(t,n,r){var e=r(1);e(e.S,"Number",{EPSILON:Math.pow(2,-52)})},function(t,n,r){var e=r(1),i=r(3).isFinite;e(e.S,"Number",{isFinite:function(t){return"number"==typeof t&&i(t)}})},function(t,n,r){var e=r(1);e(e.S,"Number",{isInteger:r(168)})},function(t,n,r){var e=r(1);e(e.S,"Number",{isNaN:function(t){return t!=t}})},function(t,n,r){var e=r(1),i=r(168),o=Math.abs;e(e.S,"Number",{isSafeInteger:function(t){return i(t)&&o(t)<=9007199254740991}})},function(t,n,r){var e=r(1);e(e.S,"Number",{MAX_SAFE_INTEGER:9007199254740991})},function(t,n,r){var e=r(1);e(e.S,"Number",{MIN_SAFE_INTEGER:-9007199254740991})},function(t,n,r){var e=r(1),i=r(178);e(e.S+e.F*(Number.parseFloat!=i),"Number",{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.S+e.F*(Number.parseInt!=i),"Number",{parseInt:i})},function(t,n,r){"use strict";var e=r(1),i=r(67),o=r(159),u=r(149),c=1..toFixed,f=Math.floor,a=[0,0,0,0,0,0],s="Number.toFixed: incorrect invocation!",l="0",h=function(t,n){for(var r=-1,e=n;++r<6;)e+=t*a[r],a[r]=e%1e7,e=f(e/1e7)},v=function(t){for(var n=6,r=0;--n>=0;)r+=a[n],a[n]=f(r/t),r=r%t*1e7},p=function(){for(var t=6,n="";--t>=0;)if(""!==n||0===t||0!==a[t]){var r=String(a[t]);n=""===n?r:n+u.call(l,7-r.length)+r}return n},d=function(t,n,r){return 0===n?r:n%2==1?d(t,n-1,r*t):d(t*t,n/2,r)},y=function(t){for(var n=0,r=t;r>=4096;)n+=12,r/=4096;for(;r>=2;)n+=1,r/=2;return n};e(e.P+e.F*(!!c&&("0.000"!==8e-5.toFixed(3)||"1"!==.9.toFixed(0)||"1.25"!==1.255.toFixed(2)||"1000000000000000128"!==(0xde0b6b3a7640080).toFixed(0))||!r(4)(function(){c.call({})})),"Number",{toFixed:function(t){var n,r,e,c,f=o(this,s),a=i(t),g="",b=l;if(a<0||a>20)throw RangeError(s);if(f!=f)return"NaN";if(f<=-1e21||f>=1e21)return String(f);if(f<0&&(g="-",f=-f),f>1e-21)if(n=y(f*d(2,69,1))-69,r=n<0?f*d(2,-n,1):f/d(2,n,1),r*=4503599627370496,(n=52-n)>0){for(h(0,r),e=a;e>=7;)h(1e7,0),e-=7;for(h(d(10,e,1),0),e=n-1;e>=23;)v(1<<23),e-=23;v(1<<e),h(1,1),v(2),b=p()}else h(0,r),h(1<<-n,0),b=p()+u.call(l,a);return a>0?(c=b.length,b=g+(c<=a?"0."+u.call(l,a-c)+b:b.slice(0,c-a)+"."+b.slice(c-a))):b=g+b,b}})},function(t,n,r){"use strict";var e=r(1),i=r(4),o=r(159),u=1..toPrecision;e(e.P+e.F*(i(function(){return"1"!==u.call(1,void 0)})||!i(function(){u.call({})})),"Number",{toPrecision:function(t){var n=o(this,"Number#toPrecision: incorrect invocation!");return void 0===t?u.call(n):u.call(n,t)}})},function(t,n,r){var e=r(1);e(e.S+e.F,"Object",{assign:r(172)})},function(t,n,r){var e=r(1);e(e.S,"Object",{create:r(70)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperties:r(173)})},function(t,n,r){var e=r(1);e(e.S+e.F*!r(10),"Object",{defineProperty:r(11).f})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("freeze",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(30),i=r(31).f;r(49)("getOwnPropertyDescriptor",function(){return function(t,n){return i(e(t),n)}})},function(t,n,r){r(49)("getOwnPropertyNames",function(){return r(174).f})},function(t,n,r){var e=r(17),i=r(32);r(49)("getPrototypeOf",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6);r(49)("isExtensible",function(t){return function(n){return!!e(n)&&(!t||t(n))}})},function(t,n,r){var e=r(6);r(49)("isFrozen",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(6);r(49)("isSealed",function(t){return function(n){return!e(n)||!!t&&t(n)}})},function(t,n,r){var e=r(1);e(e.S,"Object",{is:r(180)})},function(t,n,r){var e=r(17),i=r(72);r(49)("keys",function(){return function(t){return i(e(t))}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("preventExtensions",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(6),i=r(65).onFreeze;r(49)("seal",function(t){return function(n){return t&&e(n)?t(i(n)):n}})},function(t,n,r){var e=r(1);e(e.S,"Object",{setPrototypeOf:r(144).set})},function(t,n,r){"use strict";var e=r(114),i={};i[r(7)("toStringTag")]="z",i+""!="[object z]"&&r(28)(Object.prototype,"toString",function(){return"[object "+e(this)+"]"},!0)},function(t,n,r){var e=r(1),i=r(178);e(e.G+e.F*(parseFloat!=i),{parseFloat:i})},function(t,n,r){var e=r(1),i=r(179);e(e.G+e.F*(parseInt!=i),{parseInt:i})},function(t,n,r){"use strict";var e,i,o,u=r(69),c=r(3),f=r(53),a=r(114),s=r(1),l=r(6),h=r(26),v=r(68),p=r(79),d=r(146),y=r(151).set,g=r(143)(),b="Promise",m=c.TypeError,x=c.process,w=c[b],x=c.process,S="process"==a(x),_=function(){},O=!!function(){try{var t=w.resolve(1),n=(t.constructor={})[r(7)("species")]=function(t){t(_,_)};return(S||"function"==typeof PromiseRejectionEvent)&&t.then(_)instanceof n}catch(t){}}(),E=function(t,n){return t===n||t===w&&n===o},P=function(t){var n;return!(!l(t)||"function"!=typeof(n=t.then))&&n},j=function(t){return E(w,t)?new F(t):new i(t)},F=i=function(t){var n,r;this.promise=new t(function(t,e){if(void 0!==n||void 0!==r)throw m("Bad Promise constructor");n=t,r=e}),this.resolve=h(n),this.reject=h(r)},M=function(t){try{t()}catch(t){return{error:t}}},A=function(t,n){if(!t._n){t._n=!0;var r=t._c;g(function(){for(var e=t._v,i=1==t._s,o=0;r.length>o;)!function(n){var r,o,u=i?n.ok:n.fail,c=n.resolve,f=n.reject,a=n.domain;try{u?(i||(2==t._h&&I(t),t._h=1),!0===u?r=e:(a&&a.enter(),r=u(e),a&&a.exit()),r===n.promise?f(m("Promise-chain cycle")):(o=P(r))?o.call(r,c,f):c(r)):f(e)}catch(t){f(t)}}(r[o++]);t._c=[],t._n=!1,n&&!t._h&&N(t)})}},N=function(t){y.call(c,function(){var n,r,e,i=t._v;if(T(t)&&(n=M(function(){S?x.emit("unhandledRejection",i,t):(r=c.onunhandledrejection)?r({promise:t,reason:i}):(e=c.console)&&e.error&&e.error("Unhandled promise rejection",i)}),t._h=S||T(t)?2:1),t._a=void 0,n)throw n.error})},T=function(t){if(1==t._h)return!1;for(var n,r=t._a||t._c,e=0;r.length>e;)if(n=r[e++],n.fail||!T(n.promise))return!1;return!0},I=function(t){y.call(c,function(){var n;S?x.emit("rejectionHandled",t):(n=c.onrejectionhandled)&&n({promise:t,reason:t._v})})},k=function(t){var n=this;n._d||(n._d=!0,n=n._w||n,n._v=t,n._s=2,n._a||(n._a=n._c.slice()),A(n,!0))},L=function(t){var n,r=this;if(!r._d){r._d=!0,r=r._w||r;try{if(r===t)throw m("Promise can't be resolved itself");(n=P(t))?g(function(){var e={_w:r,_d:!1};try{n.call(t,f(L,e,1),f(k,e,1))}catch(t){k.call(e,t)}}):(r._v=t,r._s=1,A(r,!1))}catch(t){k.call({_w:r,_d:!1},t)}}};O||(w=function(t){v(this,w,b,"_h"),h(t),e.call(this);try{t(f(L,this,1),f(k,this,1))}catch(t){k.call(this,t)}},e=function(t){this._c=[],this._a=void 0,this._s=0,this._d=!1,this._v=void 0,this._h=0,this._n=!1},e.prototype=r(73)(w.prototype,{then:function(t,n){var r=j(d(this,w));return r.ok="function"!=typeof t||t,r.fail="function"==typeof n&&n,r.domain=S?x.domain:void 0,this._c.push(r),this._a&&this._a.push(r),this._s&&A(this,!1),r.promise},catch:function(t){return this.then(void 0,t)}}),F=function(){var t=new e;this.promise=t,this.resolve=f(L,t,1),this.reject=f(k,t,1)}),s(s.G+s.W+s.F*!O,{Promise:w}),r(81)(w,b),r(74)(b),o=r(52)[b],s(s.S+s.F*!O,b,{reject:function(t){var n=j(this);return(0,n.reject)(t),n.promise}}),s(s.S+s.F*(u||!O),b,{resolve:function(t){if(t instanceof w&&E(t.constructor,this))return t;var n=j(this);return(0,n.resolve)(t),n.promise}}),s(s.S+s.F*!(O&&r(123)(function(t){w.all(t).catch(_)})),b,{all:function(t){var n=this,r=j(n),e=r.resolve,i=r.reject,o=M(function(){var r=[],o=0,u=1;p(t,!1,function(t){var c=o++,f=!1;r.push(void 0),u++,n.resolve(t).then(function(t){f||(f=!0,r[c]=t,--u||e(r))},i)}),--u||e(r)});return o&&i(o.error),r.promise},race:function(t){var n=this,r=j(n),e=r.reject,i=M(function(){p(t,!1,function(t){n.resolve(t).then(r.resolve,e)})});return i&&e(i.error),r.promise}})},function(t,n,r){var e=r(1),i=r(26),o=r(2),u=(r(3).Reflect||{}).apply,c=Function.apply;e(e.S+e.F*!r(4)(function(){u(function(){})}),"Reflect",{apply:function(t,n,r){var e=i(t),f=o(r);return u?u(e,n,f):c.call(e,n,f)}})},function(t,n,r){var e=r(1),i=r(70),o=r(26),u=r(2),c=r(6),f=r(4),a=r(163),s=(r(3).Reflect||{}).construct,l=f(function(){function t(){}return!(s(function(){},[],t)instanceof t)}),h=!f(function(){s(function(){})});e(e.S+e.F*(l||h),"Reflect",{construct:function(t,n){o(t),u(n);var r=arguments.length<3?t:o(arguments[2]);if(h&&!l)return s(t,n,r);if(t==r){switch(n.length){case 0:return new t;case 1:return new t(n[0]);case 2:return new t(n[0],n[1]);case 3:return new t(n[0],n[1],n[2]);case 4:return new t(n[0],n[1],n[2],n[3])}var e=[null];return e.push.apply(e,n),new(a.apply(t,e))}var f=r.prototype,v=i(c(f)?f:Object.prototype),p=Function.apply.call(t,v,n);return c(p)?p:v}})},function(t,n,r){var e=r(11),i=r(1),o=r(2),u=r(50);i(i.S+i.F*r(4)(function(){Reflect.defineProperty(e.f({},1,{value:1}),1,{value:2})}),"Reflect",{defineProperty:function(t,n,r){o(t),n=u(n,!0),o(r);try{return e.f(t,n,r),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(31).f,o=r(2);e(e.S,"Reflect",{deleteProperty:function(t,n){var r=i(o(t),n);return!(r&&!r.configurable)&&delete t[n]}})},function(t,n,r){"use strict";var e=r(1),i=r(2),o=function(t){this._t=i(t),this._i=0;var n,r=this._k=[];for(n in t)r.push(n)};r(139)(o,"Object",function(){var t,n=this,r=n._k;do{if(n._i>=r.length)return{value:void 0,done:!0}}while(!((t=r[n._i++])in n._t));return{value:t,done:!1}}),e(e.S,"Reflect",{enumerate:function(t){return new o(t)}})},function(t,n,r){var e=r(31),i=r(1),o=r(2);i(i.S,"Reflect",{getOwnPropertyDescriptor:function(t,n){return e.f(o(t),n)}})},function(t,n,r){var e=r(1),i=r(32),o=r(2);e(e.S,"Reflect",{getPrototypeOf:function(t){return i(o(t))}})},function(t,n,r){function e(t,n){var r,c,s=arguments.length<3?t:arguments[2];return a(t)===s?t[n]:(r=i.f(t,n))?u(r,"value")?r.value:void 0!==r.get?r.get.call(s):void 0:f(c=o(t))?e(c,n,s):void 0}var i=r(31),o=r(32),u=r(24),c=r(1),f=r(6),a=r(2);c(c.S,"Reflect",{get:e})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{has:function(t,n){return n in t}})},function(t,n,r){var e=r(1),i=r(2),o=Object.isExtensible;e(e.S,"Reflect",{isExtensible:function(t){return i(t),!o||o(t)}})},function(t,n,r){var e=r(1);e(e.S,"Reflect",{ownKeys:r(177)})},function(t,n,r){var e=r(1),i=r(2),o=Object.preventExtensions;e(e.S,"Reflect",{preventExtensions:function(t){i(t);try{return o&&o(t),!0}catch(t){return!1}}})},function(t,n,r){var e=r(1),i=r(144);i&&e(e.S,"Reflect",{setPrototypeOf:function(t,n){i.check(t,n);try{return i.set(t,n),!0}catch(t){return!1}}})},function(t,n,r){function e(t,n,r){var f,h,v=arguments.length<4?t:arguments[3],p=o.f(s(t),n);if(!p){if(l(h=u(t)))return e(h,n,r,v);p=a(0)}return c(p,"value")?!(!1===p.writable||!l(v)||(f=o.f(v,n)||a(0),f.value=r,i.f(v,n,f),0)):void 0!==p.set&&(p.set.call(v,r),!0)}var i=r(11),o=r(31),u=r(32),c=r(24),f=r(1),a=r(66),s=r(2),l=r(6);f(f.S,"Reflect",{set:e})},function(t,n,r){var e=r(3),i=r(136),o=r(11).f,u=r(71).f,c=r(122),f=r(120),a=e.RegExp,s=a,l=a.prototype,h=/a/g,v=/a/g,p=new a(h)!==h;if(r(10)&&(!p||r(4)(function(){return v[r(7)("match")]=!1,a(h)!=h||a(v)==v||"/a/i"!=a(h,"i")}))){a=function(t,n){var r=this instanceof a,e=c(t),o=void 0===n;return!r&&e&&t.constructor===a&&o?t:i(p?new s(e&&!o?t.source:t,n):s((e=t instanceof a)?t.source:t,e&&o?f.call(t):n),r?this:l,a)};for(var d=u(s),y=0;d.length>y;)!function(t){t in a||o(a,t,{configurable:!0,get:function(){return s[t]},set:function(n){s[t]=n}})}(d[y++]);l.constructor=a,a.prototype=l,r(28)(e,"RegExp",a)}r(74)("RegExp")},function(t,n,r){r(119)("match",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("replace",2,function(t,n,r){return[function(e,i){"use strict";var o=t(this),u=void 0==e?void 0:e[n];return void 0!==u?u.call(e,o,i):r.call(String(o),e,i)},r]})},function(t,n,r){r(119)("search",1,function(t,n,r){return[function(r){"use strict";var e=t(this),i=void 0==r?void 0:r[n];return void 0!==i?i.call(r,e):new RegExp(r)[n](String(e))},r]})},function(t,n,r){r(119)("split",2,function(t,n,e){"use strict";var i=r(122),o=e,u=[].push,c="split",f="length",a="lastIndex";if("c"=="abbc"[c](/(b)*/)[1]||4!="test"[c](/(?:)/,-1)[f]||2!="ab"[c](/(?:ab)*/)[f]||4!="."[c](/(.?)(.?)/)[f]||"."[c](/()()/)[f]>1||""[c](/.?/)[f]){var s=void 0===/()??/.exec("")[1];e=function(t,n){var r=String(this);if(void 0===t&&0===n)return[];if(!i(t))return o.call(r,t,n);var e,c,l,h,v,p=[],d=(t.ignoreCase?"i":"")+(t.multiline?"m":"")+(t.unicode?"u":"")+(t.sticky?"y":""),y=0,g=void 0===n?4294967295:n>>>0,b=new RegExp(t.source,d+"g");for(s||(e=new RegExp("^"+b.source+"$(?!\\s)",d));(c=b.exec(r))&&!((l=c.index+c[0][f])>y&&(p.push(r.slice(y,c.index)),!s&&c[f]>1&&c[0].replace(e,function(){for(v=1;v<arguments[f]-2;v++)void 0===arguments[v]&&(c[v]=void 0)}),c[f]>1&&c.index<r[f]&&u.apply(p,c.slice(1)),h=c[0][f],y=l,p[f]>=g));)b[a]===c.index&&b[a]++;return y===r[f]?!h&&b.test("")||p.push(""):p.push(r.slice(y)),p[f]>g?p.slice(0,g):p}}else"0"[c](void 0,0)[f]&&(e=function(t,n){return void 0===t&&0===n?[]:o.call(this,t,n)});return[function(r,i){var o=t(this),u=void 0==r?void 0:r[n];return void 0!==u?u.call(r,o,i):e.call(String(o),r,i)},e]})},function(t,n,r){"use strict";r(184);var e=r(2),i=r(120),o=r(10),u="toString",c=/./[u],f=function(t){r(28)(RegExp.prototype,u,t,!0)};r(4)(function(){return"/a/b"!=c.call({source:"a",flags:"b"})})?f(function(){var t=e(this);return"/".concat(t.source,"/","flags"in t?t.flags:!o&&t instanceof RegExp?i.call(t):void 0)}):c.name!=u&&f(function(){return c.call(this)})},function(t,n,r){"use strict";r(29)("anchor",function(t){return function(n){return t(this,"a","name",n)}})},function(t,n,r){"use strict";r(29)("big",function(t){return function(){return t(this,"big","","")}})},function(t,n,r){"use strict";r(29)("blink",function(t){return function(){return t(this,"blink","","")}})},function(t,n,r){"use strict";r(29)("bold",function(t){return function(){return t(this,"b","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!1);e(e.P,"String",{codePointAt:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="endsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{endsWith:function(t){var n=o(this,t,u),r=arguments.length>1?arguments[1]:void 0,e=i(n.length),f=void 0===r?e:Math.min(i(r),e),a=String(t);return c?c.call(n,a,f):n.slice(f-a.length,f)===a}})},function(t,n,r){"use strict";r(29)("fixed",function(t){return function(){return t(this,"tt","","")}})},function(t,n,r){"use strict";r(29)("fontcolor",function(t){return function(n){return t(this,"font","color",n)}})},function(t,n,r){"use strict";r(29)("fontsize",function(t){return function(n){return t(this,"font","size",n)}})},function(t,n,r){var e=r(1),i=r(75),o=String.fromCharCode,u=String.fromCodePoint;e(e.S+e.F*(!!u&&1!=u.length),"String",{fromCodePoint:function(t){for(var n,r=[],e=arguments.length,u=0;e>u;){if(n=+arguments[u++],i(n,1114111)!==n)throw RangeError(n+" is not a valid code point");r.push(n<65536?o(n):o(55296+((n-=65536)>>10),n%1024+56320))}return r.join("")}})},function(t,n,r){"use strict";var e=r(1),i=r(148),o="includes";e(e.P+e.F*r(134)(o),"String",{includes:function(t){return!!~i(this,t,o).indexOf(t,arguments.length>1?arguments[1]:void 0)}})},function(t,n,r){"use strict";r(29)("italics",function(t){return function(){return t(this,"i","","")}})},function(t,n,r){"use strict";var e=r(147)(!0);r(140)(String,"String",function(t){this._t=String(t),this._i=0},function(){var t,n=this._t,r=this._i;return r>=n.length?{value:void 0,done:!0}:(t=e(n,r),this._i+=t.length,{value:t,done:!1})})},function(t,n,r){"use strict";r(29)("link",function(t){return function(n){return t(this,"a","href",n)}})},function(t,n,r){var e=r(1),i=r(30),o=r(16);e(e.S,"String",{raw:function(t){for(var n=i(t.raw),r=o(n.length),e=arguments.length,u=[],c=0;r>c;)u.push(String(n[c++])),c<e&&u.push(String(arguments[c]));return u.join("")}})},function(t,n,r){var e=r(1);e(e.P,"String",{repeat:r(149)})},function(t,n,r){"use strict";r(29)("small",function(t){return function(){return t(this,"small","","")}})},function(t,n,r){"use strict";var e=r(1),i=r(16),o=r(148),u="startsWith",c=""[u];e(e.P+e.F*r(134)(u),"String",{startsWith:function(t){var n=o(this,t,u),r=i(Math.min(arguments.length>1?arguments[1]:void 0,n.length)),e=String(t);return c?c.call(n,e,r):n.slice(r,r+e.length)===e}})},function(t,n,r){"use strict";r(29)("strike",function(t){return function(){return t(this,"strike","","")}})},function(t,n,r){"use strict";r(29)("sub",function(t){return function(){return t(this,"sub","","")}})},function(t,n,r){"use strict";r(29)("sup",function(t){return function(){return t(this,"sup","","")}})},function(t,n,r){"use strict";r(82)("trim",function(t){return function(){return t(this,3)}})},function(t,n,r){"use strict";var e=r(3),i=r(24),o=r(10),u=r(1),c=r(28),f=r(65).KEY,a=r(4),s=r(126),l=r(81),h=r(76),v=r(7),p=r(182),d=r(153),y=r(206),g=r(205),b=r(138),m=r(2),x=r(30),w=r(50),S=r(66),_=r(70),O=r(174),E=r(31),P=r(11),j=r(72),F=E.f,M=P.f,A=O.f,N=e.Symbol,T=e.JSON,I=T&&T.stringify,k="prototype",L=v("_hidden"),R=v("toPrimitive"),C={}.propertyIsEnumerable,D=s("symbol-registry"),U=s("symbols"),W=s("op-symbols"),G=Object[k],B="function"==typeof N,V=e.QObject,z=!V||!V[k]||!V[k].findChild,q=o&&a(function(){return 7!=_(M({},"a",{get:function(){return M(this,"a",{value:7}).a}})).a})?function(t,n,r){var e=F(G,n);e&&delete G[n],M(t,n,r),e&&t!==G&&M(G,n,e)}:M,K=function(t){var n=U[t]=_(N[k]);return n._k=t,n},J=B&&"symbol"==typeof N.iterator?function(t){return"symbol"==typeof t}:function(t){return t instanceof N},Y=function(t,n,r){return t===G&&Y(W,n,r),m(t),n=w(n,!0),m(r),i(U,n)?(r.enumerable?(i(t,L)&&t[L][n]&&(t[L][n]=!1),r=_(r,{enumerable:S(0,!1)})):(i(t,L)||M(t,L,S(1,{})),t[L][n]=!0),q(t,n,r)):M(t,n,r)},H=function(t,n){m(t);for(var r,e=g(n=x(n)),i=0,o=e.length;o>i;)Y(t,r=e[i++],n[r]);return t},$=function(t,n){return void 0===n?_(t):H(_(t),n)},X=function(t){var n=C.call(this,t=w(t,!0));return!(this===G&&i(U,t)&&!i(W,t))&&(!(n||!i(this,t)||!i(U,t)||i(this,L)&&this[L][t])||n)},Q=function(t,n){if(t=x(t),n=w(n,!0),t!==G||!i(U,n)||i(W,n)){var r=F(t,n);return!r||!i(U,n)||i(t,L)&&t[L][n]||(r.enumerable=!0),r}},Z=function(t){for(var n,r=A(x(t)),e=[],o=0;r.length>o;)i(U,n=r[o++])||n==L||n==f||e.push(n);return e},tt=function(t){for(var n,r=t===G,e=A(r?W:x(t)),o=[],u=0;e.length>u;)!i(U,n=e[u++])||r&&!i(G,n)||o.push(U[n]);return o};B||(N=function(){if(this instanceof N)throw TypeError("Symbol is not a constructor!");var t=h(arguments.length>0?arguments[0]:void 0),n=function(r){this===G&&n.call(W,r),i(this,L)&&i(this[L],t)&&(this[L][t]=!1),q(this,t,S(1,r))};return o&&z&&q(G,t,{configurable:!0,set:n}),K(t)},c(N[k],"toString",function(){return this._k}),E.f=Q,P.f=Y,r(71).f=O.f=Z,r(116).f=X,r(125).f=tt,o&&!r(69)&&c(G,"propertyIsEnumerable",X,!0),p.f=function(t){return K(v(t))}),u(u.G+u.W+u.F*!B,{Symbol:N});for(var nt="hasInstance,isConcatSpreadable,iterator,match,replace,search,species,split,toPrimitive,toStringTag,unscopables".split(","),rt=0;nt.length>rt;)v(nt[rt++]);for(var nt=j(v.store),rt=0;nt.length>rt;)d(nt[rt++]);u(u.S+u.F*!B,"Symbol",{for:function(t){return i(D,t+="")?D[t]:D[t]=N(t)},keyFor:function(t){if(J(t))return y(D,t);throw TypeError(t+" is not a symbol!")},useSetter:function(){z=!0},useSimple:function(){z=!1}}),u(u.S+u.F*!B,"Object",{create:$,defineProperty:Y,defineProperties:H,getOwnPropertyDescriptor:Q,getOwnPropertyNames:Z,getOwnPropertySymbols:tt}),T&&u(u.S+u.F*(!B||a(function(){var t=N();return"[null]"!=I([t])||"{}"!=I({a:t})||"{}"!=I(Object(t))})),"JSON",{stringify:function(t){if(void 0!==t&&!J(t)){for(var n,r,e=[t],i=1;arguments.length>i;)e.push(arguments[i++]);return n=e[1],"function"==typeof n&&(r=n),!r&&b(n)||(n=function(t,n){if(r&&(n=r.call(this,t,n)),!J(n))return n}),e[1]=n,I.apply(T,e)}}}),N[k][R]||r(27)(N[k],R,N[k].valueOf),l(N,"Symbol"),l(Math,"Math",!0),l(e.JSON,"JSON",!0)},function(t,n,r){"use strict";var e=r(1),i=r(127),o=r(152),u=r(2),c=r(75),f=r(16),a=r(6),s=r(3).ArrayBuffer,l=r(146),h=o.ArrayBuffer,v=o.DataView,p=i.ABV&&s.isView,d=h.prototype.slice,y=i.VIEW,g="ArrayBuffer";e(e.G+e.W+e.F*(s!==h),{ArrayBuffer:h}),e(e.S+e.F*!i.CONSTR,g,{isView:function(t){return p&&p(t)||a(t)&&y in t}}),e(e.P+e.U+e.F*r(4)(function(){return!new h(2).slice(1,void 0).byteLength}),g,{slice:function(t,n){if(void 0!==d&&void 0===n)return d.call(u(this),t);for(var r=u(this).byteLength,e=c(t,r),i=c(void 0===n?r:n,r),o=new(l(this,h))(f(i-e)),a=new v(this),s=new v(o),p=0;e<i;)s.setUint8(p++,a.getUint8(e++));return o}}),r(74)(g)},function(t,n,r){var e=r(1);e(e.G+e.W+e.F*!r(127).ABV,{DataView:r(152).DataView})},function(t,n,r){r(55)("Float32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Float64",8,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Int8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint16",2,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint32",4,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}})},function(t,n,r){r(55)("Uint8",1,function(t){return function(n,r,e){return t(this,n,r,e)}},!0)},function(t,n,r){"use strict";var e=r(166);r(118)("WeakSet",function(t){return function(){return t(this,arguments.length>0?arguments[0]:void 0)}},{add:function(t){return e.def(this,t,!0)}},e,!1,!0)},function(t,n,r){"use strict";var e=r(1),i=r(117)(!0);e(e.P,"Array",{includes:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0)}}),r(78)("includes")},function(t,n,r){var e=r(1),i=r(143)(),o=r(3).process,u="process"==r(45)(o);e(e.G,{asap:function(t){var n=u&&o.domain;i(n?n.bind(t):t)}})},function(t,n,r){var e=r(1),i=r(45);e(e.S,"Error",{isError:function(t){return"Error"===i(t)}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Map",{toJSON:r(165)("Map")})},function(t,n,r){var e=r(1);e(e.S,"Math",{iaddh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o+(e>>>0)+((i&u|(i|u)&~(i+u>>>0))>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{imulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>16,f=i>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>16)+((o*f>>>0)+(a&r)>>16)}})},function(t,n,r){var e=r(1);e(e.S,"Math",{isubh:function(t,n,r,e){var i=t>>>0,o=n>>>0,u=r>>>0;return o-(e>>>0)-((~i&u|~(i^u)&i-u>>>0)>>>31)|0}})},function(t,n,r){var e=r(1);e(e.S,"Math",{umulh:function(t,n){var r=65535,e=+t,i=+n,o=e&r,u=i&r,c=e>>>16,f=i>>>16,a=(c*u>>>0)+(o*u>>>16);return c*f+(a>>>16)+((o*f>>>0)+(a&r)>>>16)}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineGetter__:function(t,n){u.f(i(this),t,{get:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(26),u=r(11);r(10)&&e(e.P+r(124),"Object",{__defineSetter__:function(t,n){u.f(i(this),t,{set:o(n),enumerable:!0,configurable:!0})}})},function(t,n,r){var e=r(1),i=r(176)(!0);e(e.S,"Object",{entries:function(t){return i(t)}})},function(t,n,r){var e=r(1),i=r(177),o=r(30),u=r(31),c=r(131);e(e.S,"Object",{getOwnPropertyDescriptors:function(t){for(var n,r=o(t),e=u.f,f=i(r),a={},s=0;f.length>s;)c(a,n=f[s++],e(r,n));return a}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupGetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.get}while(r=u(r))}})},function(t,n,r){"use strict";var e=r(1),i=r(17),o=r(50),u=r(32),c=r(31).f;r(10)&&e(e.P+r(124),"Object",{__lookupSetter__:function(t){var n,r=i(this),e=o(t,!0);do{if(n=c(r,e))return n.set}while(r=u(r))}})},function(t,n,r){var e=r(1),i=r(176)(!1);e(e.S,"Object",{values:function(t){return i(t)}})},function(t,n,r){"use strict";var e=r(1),i=r(3),o=r(52),u=r(143)(),c=r(7)("observable"),f=r(26),a=r(2),s=r(68),l=r(73),h=r(27),v=r(79),p=v.RETURN,d=function(t){return null==t?void 0:f(t)},y=function(t){var n=t._c;n&&(t._c=void 0,n())},g=function(t){return void 0===t._o},b=function(t){g(t)||(t._o=void 0,y(t))},m=function(t,n){a(t),this._c=void 0,this._o=t,t=new x(this);try{var r=n(t),e=r;null!=r&&("function"==typeof r.unsubscribe?r=function(){e.unsubscribe()}:f(r),this._c=r)}catch(n){return void t.error(n)}g(this)&&y(this)};m.prototype=l({},{unsubscribe:function(){b(this)}});var x=function(t){this._s=t};x.prototype=l({},{next:function(t){var n=this._s;if(!g(n)){var r=n._o;try{var e=d(r.next);if(e)return e.call(r,t)}catch(t){try{b(n)}finally{throw t}}}},error:function(t){var n=this._s;if(g(n))throw t;var r=n._o;n._o=void 0;try{var e=d(r.error);if(!e)throw t;t=e.call(r,t)}catch(t){try{y(n)}finally{throw t}}return y(n),t},complete:function(t){var n=this._s;if(!g(n)){var r=n._o;n._o=void 0;try{var e=d(r.complete);t=e?e.call(r,t):void 0}catch(t){try{y(n)}finally{throw t}}return y(n),t}}});var w=function(t){s(this,w,"Observable","_f")._f=f(t)};l(w.prototype,{subscribe:function(t){return new m(t,this._f)},forEach:function(t){var n=this;return new(o.Promise||i.Promise)(function(r,e){f(t);var i=n.subscribe({next:function(n){try{return t(n)}catch(t){e(t),i.unsubscribe()}},error:e,complete:r})})}}),l(w,{from:function(t){var n="function"==typeof this?this:w,r=d(a(t)[c]);if(r){var e=a(r.call(t));return e.constructor===n?e:new n(function(t){return e.subscribe(t)})}return new n(function(n){var r=!1;return u(function(){if(!r){try{if(v(t,!1,function(t){if(n.next(t),r)return p})===p)return}catch(t){if(r)throw t;return void n.error(t)}n.complete()}}),function(){r=!0}})},of:function(){for(var t=0,n=arguments.length,r=Array(n);t<n;)r[t]=arguments[t++];return new("function"==typeof this?this:w)(function(t){var n=!1;return u(function(){if(!n){for(var e=0;e<r.length;++e)if(t.next(r[e]),n)return;t.complete()}}),function(){n=!0}})}}),h(w.prototype,c,function(){return this}),e(e.G,{Observable:w}),r(74)("Observable")},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.set;e.exp({defineMetadata:function(t,n,r,e){u(t,n,i(r),o(e))}})},function(t,n,r){var e=r(54),i=r(2),o=e.key,u=e.map,c=e.store;e.exp({deleteMetadata:function(t,n){var r=arguments.length<3?void 0:o(arguments[2]),e=u(i(n),r,!1);if(void 0===e||!e.delete(t))return!1;if(e.size)return!0;var f=c.get(n);return f.delete(r),!!f.size||c.delete(n)}})},function(t,n,r){var e=r(185),i=r(161),o=r(54),u=r(2),c=r(32),f=o.keys,a=o.key,s=function(t,n){var r=f(t,n),o=c(t);if(null===o)return r;var u=s(o,n);return u.length?r.length?i(new e(r.concat(u))):u:r};o.exp({getMetadataKeys:function(t){return s(u(t),arguments.length<2?void 0:a(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.get,f=e.key,a=function(t,n,r){if(u(t,n,r))return c(t,n,r);var e=o(n);return null!==e?a(t,e,r):void 0};e.exp({getMetadata:function(t,n){return a(t,i(n),arguments.length<3?void 0:f(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.keys,u=e.key;e.exp({getOwnMetadataKeys:function(t){
return o(i(t),arguments.length<2?void 0:u(arguments[1]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.get,u=e.key;e.exp({getOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(32),u=e.has,c=e.key,f=function(t,n,r){if(u(t,n,r))return!0;var e=o(n);return null!==e&&f(t,e,r)};e.exp({hasMetadata:function(t,n){return f(t,i(n),arguments.length<3?void 0:c(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=e.has,u=e.key;e.exp({hasOwnMetadata:function(t,n){return o(t,i(n),arguments.length<3?void 0:u(arguments[2]))}})},function(t,n,r){var e=r(54),i=r(2),o=r(26),u=e.key,c=e.set;e.exp({metadata:function(t,n){return function(r,e){c(t,n,(void 0!==e?i:o)(r),u(e))}}})},function(t,n,r){var e=r(1);e(e.P+e.R,"Set",{toJSON:r(165)("Set")})},function(t,n,r){"use strict";var e=r(1),i=r(147)(!0);e(e.P,"String",{at:function(t){return i(this,t)}})},function(t,n,r){"use strict";var e=r(1),i=r(46),o=r(16),u=r(122),c=r(120),f=RegExp.prototype,a=function(t,n){this._r=t,this._s=n};r(139)(a,"RegExp String",function(){var t=this._r.exec(this._s);return{value:t,done:null===t}}),e(e.P,"String",{matchAll:function(t){if(i(this),!u(t))throw TypeError(t+" is not a regexp!");var n=String(this),r="flags"in f?String(t.flags):c.call(t),e=new RegExp(t.source,~r.indexOf("g")?r:"g"+r);return e.lastIndex=o(t.lastIndex),new a(e,n)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padEnd:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!1)}})},function(t,n,r){"use strict";var e=r(1),i=r(181);e(e.P,"String",{padStart:function(t){return i(this,t,arguments.length>1?arguments[1]:void 0,!0)}})},function(t,n,r){"use strict";r(82)("trimLeft",function(t){return function(){return t(this,1)}},"trimStart")},function(t,n,r){"use strict";r(82)("trimRight",function(t){return function(){return t(this,2)}},"trimEnd")},function(t,n,r){r(153)("asyncIterator")},function(t,n,r){r(153)("observable")},function(t,n,r){var e=r(1);e(e.S,"System",{global:r(3)})},function(t,n,r){for(var e=r(155),i=r(28),o=r(3),u=r(27),c=r(80),f=r(7),a=f("iterator"),s=f("toStringTag"),l=c.Array,h=["NodeList","DOMTokenList","MediaList","StyleSheetList","CSSRuleList"],v=0;v<5;v++){var p,d=h[v],y=o[d],g=y&&y.prototype;if(g){g[a]||u(g,a,l),g[s]||u(g,s,d),c[d]=l;for(p in e)g[p]||i(g,p,e[p],!0)}}},function(t,n,r){var e=r(1),i=r(151);e(e.G+e.B,{setImmediate:i.set,clearImmediate:i.clear})},function(t,n,r){var e=r(3),i=r(1),o=r(121),u=r(207),c=e.navigator,f=!!c&&/MSIE .\./.test(c.userAgent),a=function(t){return f?function(n,r){return t(o(u,[].slice.call(arguments,2),"function"==typeof n?n:Function(n)),r)}:t};i(i.G+i.B+i.F*f,{setTimeout:a(e.setTimeout),setInterval:a(e.setInterval)})},function(t,n,r){r(330),r(269),r(271),r(270),r(273),r(275),r(280),r(274),r(272),r(282),r(281),r(277),r(278),r(276),r(268),r(279),r(283),r(284),r(236),r(238),r(237),r(286),r(285),r(256),r(266),r(267),r(257),r(258),r(259),r(260),r(261),r(262),r(263),r(264),r(265),r(239),r(240),r(241),r(242),r(243),r(244),r(245),r(246),r(247),r(248),r(249),r(250),r(251),r(252),r(253),r(254),r(255),r(317),r(322),r(329),r(320),r(312),r(313),r(318),r(323),r(325),r(308),r(309),r(310),r(311),r(314),r(315),r(316),r(319),r(321),r(324),r(326),r(327),r(328),r(231),r(233),r(232),r(235),r(234),r(220),r(218),r(224),r(221),r(227),r(229),r(217),r(223),r(214),r(228),r(212),r(226),r(225),r(219),r(222),r(211),r(213),r(216),r(215),r(230),r(155),r(302),r(307),r(184),r(303),r(304),r(305),r(306),r(287),r(183),r(185),r(186),r(342),r(331),r(332),r(337),r(340),r(341),r(335),r(338),r(336),r(339),r(333),r(334),r(288),r(289),r(290),r(291),r(292),r(295),r(293),r(294),r(296),r(297),r(298),r(299),r(301),r(300),r(343),r(369),r(372),r(371),r(373),r(374),r(370),r(375),r(376),r(354),r(357),r(353),r(351),r(352),r(355),r(356),r(346),r(368),r(377),r(345),r(347),r(349),r(348),r(350),r(359),r(360),r(362),r(361),r(364),r(363),r(365),r(366),r(367),r(344),r(358),r(380),r(379),r(378),t.exports=r(52)},function(t,n){function r(t,n){if("string"==typeof n)return t.insertAdjacentHTML("afterend",n);var r=t.nextSibling;return r?t.parentNode.insertBefore(n,r):t.parentNode.appendChild(n)}t.exports=r},,,,,,,,,function(t,n,r){(function(n,r){!function(n){"use strict";function e(t,n,r,e){var i=n&&n.prototype instanceof o?n:o,u=Object.create(i.prototype),c=new p(e||[]);return u._invoke=s(t,r,c),u}function i(t,n,r){try{return{type:"normal",arg:t.call(n,r)}}catch(t){return{type:"throw",arg:t}}}function o(){}function u(){}function c(){}function f(t){["next","throw","return"].forEach(function(n){t[n]=function(t){return this._invoke(n,t)}})}function a(t){function n(r,e,o,u){var c=i(t[r],t,e);if("throw"!==c.type){var f=c.arg,a=f.value;return a&&"object"==typeof a&&m.call(a,"__await")?Promise.resolve(a.__await).then(function(t){n("next",t,o,u)},function(t){n("throw",t,o,u)}):Promise.resolve(a).then(function(t){f.value=t,o(f)},u)}u(c.arg)}function e(t,r){function e(){return new Promise(function(e,i){n(t,r,e,i)})}return o=o?o.then(e,e):e()}"object"==typeof r&&r.domain&&(n=r.domain.bind(n));var o;this._invoke=e}function s(t,n,r){var e=P;return function(o,u){if(e===F)throw new Error("Generator is already running");if(e===M){if("throw"===o)throw u;return y()}for(r.method=o,r.arg=u;;){var c=r.delegate;if(c){var f=l(c,r);if(f){if(f===A)continue;return f}}if("next"===r.method)r.sent=r._sent=r.arg;else if("throw"===r.method){if(e===P)throw e=M,r.arg;r.dispatchException(r.arg)}else"return"===r.method&&r.abrupt("return",r.arg);e=F;var a=i(t,n,r);if("normal"===a.type){if(e=r.done?M:j,a.arg===A)continue;return{value:a.arg,done:r.done}}"throw"===a.type&&(e=M,r.method="throw",r.arg=a.arg)}}}function l(t,n){var r=t.iterator[n.method];if(r===g){if(n.delegate=null,"throw"===n.method){if(t.iterator.return&&(n.method="return",n.arg=g,l(t,n),"throw"===n.method))return A;n.method="throw",n.arg=new TypeError("The iterator does not provide a 'throw' method")}return A}var e=i(r,t.iterator,n.arg);if("throw"===e.type)return n.method="throw",n.arg=e.arg,n.delegate=null,A;var o=e.arg;return o?o.done?(n[t.resultName]=o.value,n.next=t.nextLoc,"return"!==n.method&&(n.method="next",n.arg=g),n.delegate=null,A):o:(n.method="throw",n.arg=new TypeError("iterator result is not an object"),n.delegate=null,A)}function h(t){var n={tryLoc:t[0]};1 in t&&(n.catchLoc=t[1]),2 in t&&(n.finallyLoc=t[2],n.afterLoc=t[3]),this.tryEntries.push(n)}function v(t){var n=t.completion||{};n.type="normal",delete n.arg,t.completion=n}function p(t){this.tryEntries=[{tryLoc:"root"}],t.forEach(h,this),this.reset(!0)}function d(t){if(t){var n=t[w];if(n)return n.call(t);if("function"==typeof t.next)return t;if(!isNaN(t.length)){var r=-1,e=function n(){for(;++r<t.length;)if(m.call(t,r))return n.value=t[r],n.done=!1,n;return n.value=g,n.done=!0,n};return e.next=e}}return{next:y}}function y(){return{value:g,done:!0}}var g,b=Object.prototype,m=b.hasOwnProperty,x="function"==typeof Symbol?Symbol:{},w=x.iterator||"@@iterator",S=x.asyncIterator||"@@asyncIterator",_=x.toStringTag||"@@toStringTag",O="object"==typeof t,E=n.regeneratorRuntime;if(E)return void(O&&(t.exports=E));E=n.regeneratorRuntime=O?t.exports:{},E.wrap=e;var P="suspendedStart",j="suspendedYield",F="executing",M="completed",A={},N={};N[w]=function(){return this};var T=Object.getPrototypeOf,I=T&&T(T(d([])));I&&I!==b&&m.call(I,w)&&(N=I);var k=c.prototype=o.prototype=Object.create(N);u.prototype=k.constructor=c,c.constructor=u,c[_]=u.displayName="GeneratorFunction",E.isGeneratorFunction=function(t){var n="function"==typeof t&&t.constructor;return!!n&&(n===u||"GeneratorFunction"===(n.displayName||n.name))},E.mark=function(t){return Object.setPrototypeOf?Object.setPrototypeOf(t,c):(t.__proto__=c,_ in t||(t[_]="GeneratorFunction")),t.prototype=Object.create(k),t},E.awrap=function(t){return{__await:t}},f(a.prototype),a.prototype[S]=function(){return this},E.AsyncIterator=a,E.async=function(t,n,r,i){var o=new a(e(t,n,r,i));return E.isGeneratorFunction(n)?o:o.next().then(function(t){return t.done?t.value:o.next()})},f(k),k[_]="Generator",k.toString=function(){return"[object Generator]"},E.keys=function(t){var n=[];for(var r in t)n.push(r);return n.reverse(),function r(){for(;n.length;){var e=n.pop();if(e in t)return r.value=e,r.done=!1,r}return r.done=!0,r}},E.values=d,p.prototype={constructor:p,reset:function(t){if(this.prev=0,this.next=0,this.sent=this._sent=g,this.done=!1,this.delegate=null,this.method="next",this.arg=g,this.tryEntries.forEach(v),!t)for(var n in this)"t"===n.charAt(0)&&m.call(this,n)&&!isNaN(+n.slice(1))&&(this[n]=g)},stop:function(){this.done=!0;var t=this.tryEntries[0],n=t.completion;if("throw"===n.type)throw n.arg;return this.rval},dispatchException:function(t){function n(n,e){return o.type="throw",o.arg=t,r.next=n,e&&(r.method="next",r.arg=g),!!e}if(this.done)throw t;for(var r=this,e=this.tryEntries.length-1;e>=0;--e){var i=this.tryEntries[e],o=i.completion;if("root"===i.tryLoc)return n("end");if(i.tryLoc<=this.prev){var u=m.call(i,"catchLoc"),c=m.call(i,"finallyLoc");if(u&&c){if(this.prev<i.catchLoc)return n(i.catchLoc,!0);if(this.prev<i.finallyLoc)return n(i.finallyLoc)}else if(u){if(this.prev<i.catchLoc)return n(i.catchLoc,!0)}else{if(!c)throw new Error("try statement without catch or finally");if(this.prev<i.finallyLoc)return n(i.finallyLoc)}}}},abrupt:function(t,n){for(var r=this.tryEntries.length-1;r>=0;--r){var e=this.tryEntries[r];if(e.tryLoc<=this.prev&&m.call(e,"finallyLoc")&&this.prev<e.finallyLoc){var i=e;break}}i&&("break"===t||"continue"===t)&&i.tryLoc<=n&&n<=i.finallyLoc&&(i=null);var o=i?i.completion:{};return o.type=t,o.arg=n,i?(this.method="next",this.next=i.finallyLoc,A):this.complete(o)},complete:function(t,n){if("throw"===t.type)throw t.arg;return"break"===t.type||"continue"===t.type?this.next=t.arg:"return"===t.type?(this.rval=this.arg=t.arg,this.method="return",this.next="end"):"normal"===t.type&&n&&(this.next=n),A},finish:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.finallyLoc===t)return this.complete(r.completion,r.afterLoc),v(r),A}},catch:function(t){for(var n=this.tryEntries.length-1;n>=0;--n){var r=this.tryEntries[n];if(r.tryLoc===t){var e=r.completion;if("throw"===e.type){var i=e.arg;v(r)}return i}}throw new Error("illegal catch attempt")},delegateYield:function(t,n,r){return this.delegate={iterator:d(t),resultName:n,nextLoc:r},"next"===this.method&&(this.arg=g),A}}}("object"==typeof n?n:"object"==typeof window?window:"object"==typeof self?self:this)}).call(n,function(){return this}(),r(158))}])</script><script src="/./main.266c1c.js"></script><script>!function(){!function(e){var t=document.createElement("script");document.getElementsByTagName("body")[0].appendChild(t),t.setAttribute("src",e)}("/slider.096dc6.js")}()</script>


<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script src="//cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


    
<div class="tools-col" q-class="show:isShow,hide:isShow|isFalse" q-on="click:stop(e)">
  <div class="tools-nav header-menu">
    
    
      
      
      
    
      
      
      
    
    

    <ul style="width: 70%">
    
    
      
      <li style="width: 50%" q-on="click: openSlider(e, 'friends')"><a href="javascript:void(0)" q-class="active:friends">友链</a></li>
      
        
      
      <li style="width: 50%" q-on="click: openSlider(e, 'aboutme')"><a href="javascript:void(0)" q-class="active:aboutme">关于我</a></li>
      
        
    </ul>
  </div>
  <div class="tools-wrap">
    

    
    	<section class="tools-section tools-section-friends" q-show="friends">
  		
        <ul class="search-ul">
          
            <li class="search-li">
              <a href="http://localhost:4000/" target="_blank" class="search-title"><i class="icon-quo-left icon"></i>友情链接1</a>
            </li>
          
        </ul>
  		
    	</section>
    

    
    	<section class="tools-section tools-section-me" q-show="aboutme">
  	  	
  	  		<div class="aboutme-wrap" id="js-aboutme">非典型&lt;br&gt;非科班&lt;br&gt;算法工程师&lt;br&gt; &lt;br&gt;希望这个世界能够因为我有一点不一样&lt;br&gt;</div>
  	  	
    	</section>
    
  </div>
  
</div>
    <!-- Root element of PhotoSwipe. Must have class pswp. -->
<div class="pswp" tabindex="-1" role="dialog" aria-hidden="true">

    <!-- Background of PhotoSwipe. 
         It's a separate element as animating opacity is faster than rgba(). -->
    <div class="pswp__bg"></div>

    <!-- Slides wrapper with overflow:hidden. -->
    <div class="pswp__scroll-wrap">

        <!-- Container that holds slides. 
            PhotoSwipe keeps only 3 of them in the DOM to save memory.
            Don't modify these 3 pswp__item elements, data is added later on. -->
        <div class="pswp__container">
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
            <div class="pswp__item"></div>
        </div>

        <!-- Default (PhotoSwipeUI_Default) interface on top of sliding area. Can be changed. -->
        <div class="pswp__ui pswp__ui--hidden">

            <div class="pswp__top-bar">

                <!--  Controls are self-explanatory. Order can be changed. -->

                <div class="pswp__counter"></div>

                <button class="pswp__button pswp__button--close" title="Close (Esc)"></button>

                <button class="pswp__button pswp__button--share" style="display:none" title="Share"></button>

                <button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>

                <button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button>

                <!-- Preloader demo http://codepen.io/dimsemenov/pen/yyBWoR -->
                <!-- element will get class pswp__preloader--active when preloader is running -->
                <div class="pswp__preloader">
                    <div class="pswp__preloader__icn">
                      <div class="pswp__preloader__cut">
                        <div class="pswp__preloader__donut"></div>
                      </div>
                    </div>
                </div>
            </div>

            <div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap">
                <div class="pswp__share-tooltip"></div> 
            </div>

            <button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
            </button>

            <button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)">
            </button>

            <div class="pswp__caption">
                <div class="pswp__caption__center"></div>
            </div>

        </div>

    </div>

</div>
  </div>
</body>
</html>